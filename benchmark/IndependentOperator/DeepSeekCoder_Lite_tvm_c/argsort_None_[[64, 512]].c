void default_function_kernel(float* data, int32_t* argsort_gpu) {
    int64_t first[1];
    int64_t last[1];
    int64_t first_1[1];
    int64_t last_1[1];
    int64_t cse_var_1 = 2;

    #pragma omp parallel for
    for (int64_t i_0 = 0; i_0 < 512; ++i_0) {
        for (int64_t blockIdx_z = 0; blockIdx_z < 64; ++blockIdx_z) {
            if ((((int64_t)2 << cse_var_1) * ((int64_t)blockIdx_z)) < (int64_t)512) {
                int64_t threadIdx_x = (int64_t)omp_get_thread_num();
                int64_t first_0 = max((int64_t)0, ((((((int64_t)2 << cse_var_1) >> (int64_t)1) + (((int64_t)2 << cse_var_1) * ((int64_t)blockIdx_z)))) + ((threadIdx_x * (((((((int64_t)2 << cse_var_1)) >= (int64_t)0) && (((((int64_t)2 << cse_var_1) - (int64_t)1) % ((int64_t)2 << cse_var_1)) >= (int64_t)0)) || ((((int64_t)2 << cse_var_1) < (int64_t)0) && (((((int64_t)2 << cse_var_1) - (int64_t)1) % ((int64_t)2 << cse_var_1)) <= (int64_t)0))) ? ((((int64_t)2 << cse_var_1) - (int64_t)1) / ((int64_t)2 << cse_var_1)) : (((((int64_t)2 << cse_var_1) - (int64_t)1) / ((int64_t)2 << cse_var_1)) - (int64_t)1)) + (int64_t)1))) - (((int64_t)2 << cse_var_1) * (((int64_t)blockIdx_z + (int64_t)1))));
                int64_t last_0 = min((threadIdx_x * (((((((int64_t)2 << cse_var_1)) >= (int64_t)0) && (((((int64_t)2 << cse_var_1) - (int64_t)1) % ((int64_t)2 << cse_var_1)) >= (int64_t)0)) || ((((int64_t)2 << cse_var_1) < (int64_t)0) && (((((int64_t)2 << cse_var_1) - (int64_t)1) % ((int64_t)2 << cse_var_1)) <= (int64_t)0))) ? ((((int64_t)2 << cse_var_1) - (int64_t)1) / ((int64_t)2 << cse_var_1)) : (((((int64_t)2 << cse_var_1) - (int64_t)1) / ((int64_t)2 << cse_var_1)) - (int64_t)1)) + (int64_t)1), (((int64_t)2 << cse_var_1) >> (int64_t)1));
                while (first_0 < last_0) {
                    int64_t mid = (first_0 + last_0) / 2;
                    if (data[(((((int64_t)blockIdx_y * (int64_t)512) + (((int64_t)2 << cse_var_1) * ((int64_t)blockIdx_z))) + mid * (((((((int64_t)2 << cse_var_1)) >= (int64_t)0) && (((((int64_t)2 << cse_var_1) - (int64_t)1) % ((int64_t)2 << cse_var_1)) >= (int64_t)0)) || ((((int64_t)2 << cse_var_1) < (int64_t)0) && (((((int64_t)2 << cse_var_1) - (int64_t)1) % ((int64_t)2 << cse_var_1)) <= (int64_t)0))) ? ((((int64_t)2 << cse_var_1) - (int64_t)1) / ((int64_t)2 << cse_var_1)) : (((((int64_t)2 << cse_var_1) - (int64_t)1) / ((int64_t)2 << cse_var_1)) - (int64_t)1)) + (int64_t)1))) <= data[(((((int64_t)blockIdx_y * (int64_t)512) + (((int64_t)2 << cse_var_1) >> (int64_t)1) + (((int64_t)2 << cse_var_1) * ((int64_t)blockIdx_z))) + mid * (((((((int64_t)2 << cse_var_1)) >= (int64_t)0) && (((((int64_t)2 << cse_var_1) - (int64_t)1) % ((int64_t)2 << cse_var_1)) >= (int64_t)0)) || ((((int64_t)2 << cse_var_1) < (int64_t)0) && (((((int64_t)2 << cse_var_1) - (int64_t)1) % ((int64_t)2 << cse_var_1)) <= (int64_t)0))) ? ((((int64_t)2 << cse_var_1) - (int64_t)1) / ((int64_t)2 << cse_var_1)) : (((((int64_t)2 << cse_var_1) - (int64_t)1) / ((int64_t)2 << cse_var_1)) - (int64_t)1)) + (int64_t)1) - 1)])) {
                        first_0 = mid + 1;
                    } else {
                        last_0 = mid;
                    }
                }
                first_0 = (((int64_t)2 << cse_var_1) * ((int64_t)blockIdx_z)) + first_0);
                last_0 = (((((int64_t)2 << cse_var_1) >> (int64_t)1) + (((int64_t)2 << cse_var_1) * ((int64_t)blockIdx_z))) + ((threadIdx_x * (((((((int64_t)2 << cse_var_1)) >= (int64_t)0) && (((((int64_t)2 << cse_var_1) - (int64_t)1) % ((int64_t)2 << cse_var_1)) >= (int64_t)0)) || ((((int64_t)2 << cse_var_1) < (int64_t)0) && (((((int64_t)2 << cse_var_1) - (int64_t)1) % ((int64_t)2 << cse_var_1)) <= (int64_t)0))) ? ((((int64_t)2 << cse_var_1) - (int64_t)1) / ((int64_t)2 << cse_var_1)) : (((((int64_t)2 << cse_var_1) - (int64_t)1) / ((int64_t)2 << cse_var_1)) - (int64_t)1)) + (int64_t)1)) - last_0);
                for (int i_1 = 0; i_1 < ((int64_t)2 << cse_var_1) - ((threadIdx_x * (((((((int64_t)2 << cse_var_1)) >= (int64_t)0) && (((((int64_t)2 << cse_var_1) - (int64_t)1) % ((int64_t)2 << cse_var_1)) >= (int64_t)0)) || ((((int64_t)2 << cse_var_1) < (int64_t)0) && (((((int64_t)2 << cse_var_1) - (int64_t)1) % ((int64_t)2 << cse_var_1)) <= (int64_t)0))) ? ((((int64_t)2 << cse_var_1) - (int64_t)1) / ((int64_t)2 << cse_var_1)) : (((((int64_t)2 << cse_var_1) - (int64_t)1) / ((int64_t)2 << cse_var_1)) - (int64_t)1)) + (int64_t)1))); ++i_1) {
                    if (((first_0 < (((int64_t)2 << cse_var_1) >> (int64_t)1) + (((int64_t)2 << cse_var_1) * ((int64_t)blockIdx_z))) && (first_0 < (int64_t)512)) && (last_0 < (((int64_t)2 << cse_var_1) * (((int64_t)blockIdx_z + (int64_t)1)))) && (last_0 < (int64_t)512))) {
                        if (data[(((((int64_t)blockIdx_y * (int64_t)512) + first_0) * (((((((int64_t)2 << cse_var_1)) >= (int64_t)0) && (((((int64_t)2 << cse_var_1) - (int64_t)1) % ((int64_t)2 << cse_var_1)) >= (int64_t)0)) || ((((int64_t)2 << cse_var_1) < (int64_t)0) && (((((int64_t)2 << cse_var_1) - (int64_t)1) % ((int64_t)2 << cse_var_1)) <= (int64_t)0))) ? ((((int64_t)2 << cse_var_1) - (int64_t)1) / ((int64_t)2 << cse_var_1)) : (((((int64_t)2 << cse_var_1) - (int64_t)1) / ((int64_t)2 << cse_var_1)) - (int64_t)1)) + (int64_t)1))) <= data[(((((int64_t)blockIdx_y * (int64_t)512) + last_0) * (((((((int64_t)2 << cse_var_1)) >= (int64_t)0) && (((((int64_t)2 << cse_var_1) - (int64_t)1) % ((int64_t)2 << cse_var_1)) >= (int64_t)0)) || ((((int64_t)2 << cse_var_1) < (int64_t)0) && (((((int64_t)2 << cse_var_1) - (int64_t)1) % ((int64_t)2 << cse_var_1)) <= (int64_t)0))) ? ((((int64_t)2 << cse_var_1) - (int64_t)1) / ((int64_t)2 << cse_var_1)) : (((((int64_t)2 << cse_var_1) - (int64_t)1) / ((int64_t)2 << cse_var_1)) - (int64_t)1)) + (int64_t)1)))]) {
                            argsort_gpu[(((((int64_t)blockIdx_y * (int64_t)512) + first_0) * (((((((int64_t)2 << cse_var_1)) >= (int64_t)0) && (((((int64_t)2 << cse_var_1) - (int64_t)1) % ((int64_t)2 << cse_var_1)) >= (int64_t)0)) || ((((int64_t)2 << cse_var_1) < (int64_t)0) && (((((int64_t)2 << cse_var_1) - (int64_t)1) % ((int64_t)2 << cse_var_1)) <= (int64_t)0))) ? ((((int64_t)2 << cse_var_1) - (int64_t)1) / ((int64_t)2 << cse_var_1)) : (((((int64_t)2 << cse_var_1) - (int64_t)1) / ((int64_t)2 << cse_var_1)) - (int64_t)1)) + (int64_t)1))) = data[(((((int64_t)blockIdx_y * (int64_t)512) + first_0) * (((((((int64_t)2 << cse_var_1)) >= (int64_t)0) && (((((int64_t)2 << cse_var_1) - (int64_t)1) % ((int64_t)2 << cse_var_1)) >= (int64_t)0)) || ((((int64_t)2 << cse_var_1) < (int64_t)0) && (((((int64_t)2 << cse_var_1) - (int64_t)1) % ((int64_t)2 << cse_var_1)) <= (int64_t)0))) ? ((((int64_t)2 << cse_var_1) - (int64_t)1) / ((int64_t)2 << cse_var_1)) : (((((int64_t)2 << cse_var_1) - (int64_t)1) / ((int64_t)2 << cse_var_1)) - (int64_t)1)) + (int64_t)1)))];
                            argsort_gpu_v0[(((((int64_t)blockIdx_y * (int64_t)512) + first_0) * (((((((int64_t)2 << cse_var_1)) >= (int64_t)0) && (((((int64_t)2 << cse_var_1) - (int64_t)1) % ((int64_t)2 << cse_var_1)) >= (int64_t)0)) || ((((int64_t)2 << cse_var_1) < (int64_t)0) && (((((int64_t)2 << cse_var_1) - (int64_t)1) % ((int64_t)2 << cse_var_1)) <= (int64_t)0))) ? ((((int64_t)2 << cse_var_1) - (int64_t)1) / ((int64_t)2 << cse_var_1)) : (((((int64_t)2 << cse_var_1) - (int64_t)1) / ((int64_t)2 << cse_var_1)) - (int64_t)1)) + (int64_t)1))) = (float)first_0;
                            first_0++;
                        } else {
                            argsort_gpu[(((((int64_t)blockIdx_y * (int64_t)512) + last_0) * (((((((int64_t)2 << cse_var_1)) >= (int64_t)0) && (((((int64_t)2 << cse_var_1) - (int64_t)1) % ((int64_t)2 << cse_var_1)) >= (int64_t)0)) || ((((int64_t)2 << cse_var_1) < (int64_t)0) && (((((int64_t)2 << cse_var_1) - (int64_t)1) % ((int64_t)2 << cse_var_1)) <= (int64_t)0))) ? ((((int64_t)2 << cse_var_1) - (int64_t)1) / ((int64_t)2 << cse_var_1)) : (((((int64_t)2 << cse_var_1) - (int64_t)1) / ((int64_t)2 << cse_var_1)) - (int64_t)1)) + (int64_t)1))) = data[(((((int64_t)blockIdx_y * (int64_t)512) + last_0) * (((((((int64_t)2 << cse_var_1)) >= (int64_t)0) && (((((int64_t)2 << cse_var_1) - (int64_t)1) % ((int64_t)2 << cse_var_1)) >= (int64_t)0)) || ((((int64_t)2 << cse_var_1) < (int64_t)0) && (((((int64_t)2 << cse_var_1) - (int64_t)1) % ((int64_t)2 << cse_var_1)) <= (int64_t)0))) ? ((((int64_t)2 << cse_var_1) - (int64_t)1) / ((int64_t)2 << cse_var_1)) : (((((int64_t)2 << cse_var_1) - (int64_t)1) / ((int64_t)2 << cse_var_1)) - (int64_t)1)) + (int64_t)1)))];
                            argsort_gpu_v0[(((((int64_t)blockIdx_y * (int64_t)512) + last_0) * (((((((int64_t)2 << cse_var_1)) >= (int64_t)0) && (((((int64_t)2 << cse_var_1) - (int64_t)1) % ((int64_t)2 << cse_var_1)) >= (int64_t)0)) || ((((int64_t)2 << cse_var_1) < (int64_t)0) && (((((int64_t)2 << cse_var_1) - (int64_t)1) % ((int64_t)2 << cse_var_1)) <= (int64_t)0))) ? ((((int64_t)2 << cse_var_1) - (int64_t)1) / ((int64_t)2 << cse_var_1)) : (((((int64_t)2 << cse_var_1) - (int64_t)1) / ((int64_t)2 << cse_var_1)) - (int64_t)1)) + (int64_t)1))) = (float)last_0;
                            last_0++;
                        }
                    }
                }
            }
        }
    }
}