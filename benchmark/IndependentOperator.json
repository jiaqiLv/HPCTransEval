[
    {
        "op_name": "reorg",
        "c_code": "void default_function_kernel(float* A, float* T_reshape) {\n  float tensor[16777216];\n  for (int32_t ax0 = 0; ax0 < 16; ++ax0) {\n    for (int32_t ax1 = 0; ax1 < 64; ++ax1) {\n      for (int32_t ax2 = 0; ax2 < 128; ++ax2) {\n        for (int32_t ax3 = 0; ax3 < 128; ++ax3) {\n          tensor[((((ax0 * 1048576) + (ax1 * 16384)) + (ax2 * 128)) + ax3)] = A[((((((ax0 * 4194304) + ((ax1 & 15) * 65536)) + (ax2 * 512)) + ((ax1 >> 5) * 256)) + (ax3 * 2)) + ((ax1 & 31) >> 4))];\n        }\n      }\n    }\n  }\n  for (int32_t ax0_1 = 0; ax0_1 < 16; ++ax0_1) {\n    for (int32_t ax1_1 = 0; ax1_1 < 256; ++ax1_1) {\n      for (int32_t ax2_1 = 0; ax2_1 < 64; ++ax2_1) {\n        for (int32_t ax3_1 = 0; ax3_1 < 64; ++ax3_1) {\n          T_reshape[((((ax0_1 * 1048576) + (ax1_1 * 4096)) + (ax2_1 * 64)) + ax3_1)] = tensor[((((ax0_1 * 1048576) + (ax1_1 * 4096)) + (ax2_1 * 64)) + ax3_1)];\n        }\n      }\n    }\n  }\n}\n\n",
        "cuda_code": "extern \"C\" __global__ void __launch_bounds__(1024) default_function_kernel(float* __restrict__ A, float* __restrict__ T_reshape) {\n  T_reshape[((((int)blockIdx.x) * 1024) + ((int)threadIdx.x))] = A[(((((((((int)blockIdx.x) >> 10) * 4194304) + ((((int)blockIdx.x) & 255) * 4096)) + ((((int)threadIdx.x) >> 7) * 512)) + (((((int)blockIdx.x) & 1023) >> 9) * 256)) + ((((int)threadIdx.x) & 127) * 2)) + ((((int)blockIdx.x) & 511) >> 8))];\n}\n\n",
        "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(A: T.Buffer((16, 64, 128, 128), \"float32\"), T_reshape: T.Buffer((16, 256, 64, 64), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        tensor = T.allocate([16777216], \"float32\", \"global\")\n        tensor_1 = T.Buffer((16777216,), data=tensor)\n        for ax0, ax1, ax2, ax3 in T.grid(16, 64, 128, 128):\n            A_1 = T.Buffer((16777216,), data=A.data)\n            tensor_1[ax0 * 1048576 + ax1 * 16384 + ax2 * 128 + ax3] = A_1[ax0 * 4194304 + ax1 % 16 * 65536 + ax2 * 512 + ax1 // 32 * 256 + ax3 * 2 + ax1 % 32 // 16]\n        for ax0, ax1, ax2, ax3 in T.grid(16, 256, 64, 64):\n            cse_var_1: T.int32 = ax0 * 1048576 + ax1 * 4096 + ax2 * 64 + ax3\n            T_reshape_1 = T.Buffer((16777216,), data=T_reshape.data)\n            T_reshape_1[cse_var_1] = tensor_1[cse_var_1]",
        "op_args": "None",
        "input_shape": [
            [
                16,
                64,
                128,
                128
            ]
        ],
        "output_shape": [
            [
                16,
                256,
                64,
                64
            ]
        ],
        "input_name": [
            "A"
        ],
        "output_name": [
            "T_reshape"
        ]
    },
    {
        "op_name": "scatter_nd",
        "c_code": "void default_function_kernel(float* data, int32_t* indices, float* scatter_nd_generic, float* updates) {\n  for (int32_t i = 0; i < 3120; ++i) {\n    scatter_nd_generic[i] = data[i];\n  }\n  for (int32_t j = 0; j < 3; ++j) {\n    #pragma omp parallel for\n    for (int32_t k = 0; k < 1560; ++k) {\n      scatter_nd_generic[((indices[j] * 1560) + k)] = (scatter_nd_generic[((indices[j] * 1560) + k)] + updates[((j * 1560) + k)]);\n    }\n  }\n}\n\n",
        "cuda_code": "extern \"C\" __global__ void __launch_bounds__(1024) default_function_kernel_1(float* __restrict__ atomic_add_return, int* __restrict__ indices, float* __restrict__ scatter_nd_cuda, float* __restrict__ updates) {\n  if (((((int)blockIdx.y) * 128) + (((int)threadIdx.x) >> 3)) < 195) {\n    atomic_add_return[0] = atomicAdd((&(scatter_nd_cuda[(((indices[((int)blockIdx.x)] * 1560) + (((int)blockIdx.y) * 1024)) + ((int)threadIdx.x))])), updates[(((((int)blockIdx.x) * 1560) + (((int)blockIdx.y) * 1024)) + ((int)threadIdx.x))]);\n  }\n}\n\nextern \"C\" __global__ void __launch_bounds__(1024) default_function_kernel(float* __restrict__ data, float* __restrict__ scatter_nd_cuda) {\n  if (((((int)blockIdx.x) * 64) + (((int)threadIdx.x) >> 4)) < 195) {\n    scatter_nd_cuda[((((int)blockIdx.x) * 1024) + ((int)threadIdx.x))] = data[((((int)blockIdx.x) * 1024) + ((int)threadIdx.x))];\n  }\n}\n\n",
        "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((2, 1560), \"float32\"), indices: T.Buffer((1, 3), \"int32\"), updates: T.Buffer((3, 1560), \"float32\"), scatter_nd_generic: T.Buffer((2, 1560), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        T.attr(0, \"extern_scope\", 0)\n        scatter_nd_generic_1 = T.Buffer((3120,), data=scatter_nd_generic.data)\n        for i in range(3120):\n            data_1 = T.Buffer((3120,), data=data.data)\n            scatter_nd_generic_1[i] = data_1[i]\n        for j in range(3):\n            for k in T.parallel(1560):\n                indices_1 = T.Buffer((3,), \"int32\", data=indices.data)\n                updates_1 = T.Buffer((4680,), data=updates.data)\n                scatter_nd_generic_1[indices_1[j] * 1560 + k] = scatter_nd_generic_1[indices_1[j] * 1560 + k] + updates_1[j * 1560 + k]",
        "op_args": "None",
        "input_shape": [
            [
                2,
                1560
            ],
            [
                1,
                3
            ],
            [
                3,
                1560
            ]
        ],
        "output_shape": [
            [
                2,
                1560
            ]
        ],
        "input_name": [
            "data",
            "indices",
            "updates"
        ],
        "output_name": [
            "scatter_nd.generic"
        ]
    },
    {
        "op_name": "gather_nd",
        "c_code": "void default_function_kernel(float* A, float* T_gather_nd, float* indices) {\n  #pragma omp parallel for\n  for (int32_t ax0_ax1_fused_ax2_fused = 0; ax0_ax1_fused_ax2_fused < 8; ++ax0_ax1_fused_ax2_fused) {\n    for (int32_t ax3 = 0; ax3 < 64; ++ax3) {\n      for (int32_t ax4_outer = 0; ax4_outer < 4; ++ax4_outer) {\n        for (int32_t ax4_inner = 0; ax4_inner < 16; ++ax4_inner) {\n          if (((ax4_outer * 8) + (ax4_inner >> 1)) < 25) {\n            T_gather_nd[((((ax0_ax1_fused_ax2_fused * 3200) + (ax3 * 50)) + (ax4_outer * 16)) + ax4_inner)] = A[(((((((int32_t)indices[ax0_ax1_fused_ax2_fused]) * 204800) + (((int32_t)indices[(ax0_ax1_fused_ax2_fused + 8)]) * 3200)) + (ax3 * 50)) + (ax4_outer * 16)) + ax4_inner)];\n          }\n        }\n      }\n    }\n  }\n}\n\n",
        "cuda_code": "extern \"C\" __global__ void __launch_bounds__(1024) default_function_kernel(float* __restrict__ A, float* __restrict__ T_gather_nd, float* __restrict__ indices) {\n  T_gather_nd[((((int)blockIdx.x) * 1024) + ((int)threadIdx.x))] = A[(((((int)indices[(((((int)blockIdx.x) * 8) + (((int)threadIdx.x) >> 7)) / 25)]) * 204800) + (((int)indices[((((((int)blockIdx.x) * 8) + (((int)threadIdx.x) >> 7)) / 25) + 8)]) * 3200)) + (((((int)blockIdx.x) * 1024) + ((int)threadIdx.x)) % 3200))];\n}\n\n",
        "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(A: T.Buffer((32, 64, 64, 50), \"float32\"), indices: T.Buffer((2, 2, 2, 2), \"float32\"), T_gather_nd: T.Buffer((2, 2, 2, 64, 50), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0_ax1_fused_ax2_fused in T.parallel(8):\n            for ax3, ax4_outer, ax4_inner in T.grid(64, 4, 16):\n                if T.likely(ax4_outer * 8 + ax4_inner // 2 < 25):\n                    cse_var_2: T.int32 = ax4_outer * 16\n                    cse_var_1: T.int32 = ax3 * 50\n                    T_gather_nd_1 = T.Buffer((25600,), data=T_gather_nd.data)\n                    A_1 = T.Buffer((6553600,), data=A.data)\n                    indices_1 = T.Buffer((16,), data=indices.data)\n                    T_gather_nd_1[ax0_ax1_fused_ax2_fused * 3200 + cse_var_1 + cse_var_2 + ax4_inner] = A_1[T.Cast(\"int32\", indices_1[ax0_ax1_fused_ax2_fused]) * 204800 + T.Cast(\"int32\", indices_1[ax0_ax1_fused_ax2_fused + 8]) * 3200 + cse_var_1 + cse_var_2 + ax4_inner]",
        "op_args": "None",
        "input_shape": [
            [
                32,
                64,
                64,
                50
            ],
            [
                2,
                2,
                2,
                2
            ]
        ],
        "output_shape": [
            [
                2,
                2,
                2,
                64,
                50
            ]
        ],
        "input_name": [
            "A",
            "indices"
        ],
        "output_name": [
            "T_gather_nd"
        ]
    },
    {
        "op_name": "reshape",
        "c_code": "void default_function_kernel(float* A, float* T_reshape) {\n  #pragma omp parallel for\n  for (int32_t ax0 = 0; ax0 < 128; ++ax0) {\n    for (int32_t ax1_outer = 0; ax1_outer < 20; ++ax1_outer) {\n      for (int32_t ax1_inner = 0; ax1_inner < 16; ++ax1_inner) {\n        T_reshape[(((ax0 * 320) + (ax1_outer * 16)) + ax1_inner)] = A[(((ax0 * 320) + (ax1_outer * 16)) + ax1_inner)];\n      }\n    }\n  }\n}\n\n",
        "cuda_code": "extern \"C\" __global__ void __launch_bounds__(1024) default_function_kernel(float* __restrict__ A, float* __restrict__ T_reshape) {\n  T_reshape[((((int)blockIdx.x) * 1024) + ((int)threadIdx.x))] = A[((((((((int)blockIdx.x) * 16) + (((int)threadIdx.x) >> 6)) / 5) * 320) + (((((((int)blockIdx.x) * 32) + (((int)threadIdx.x) >> 1)) % 160) / 5) * 10)) + (((((int)blockIdx.x) * 4) + ((int)threadIdx.x)) % 10))];\n}\n\n",
        "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(A: T.Buffer((2, 64, 32, 10), \"float32\"), T_reshape: T.Buffer((128, 320), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0 in T.parallel(128):\n            for ax1_outer, ax1_inner in T.grid(20, 16):\n                cse_var_1: T.int32 = ax0 * 320 + ax1_outer * 16 + ax1_inner\n                T_reshape_1 = T.Buffer((40960,), data=T_reshape.data)\n                A_1 = T.Buffer((40960,), data=A.data)\n                T_reshape_1[cse_var_1] = A_1[cse_var_1]",
        "op_args": "None",
        "input_shape": [
            [
                2,
                64,
                32,
                10
            ]
        ],
        "output_shape": [
            [
                128,
                320
            ]
        ],
        "input_name": [
            "A"
        ],
        "output_name": [
            "T_reshape"
        ]
    },
    {
        "op_name": "transpose",
        "c_code": "void default_function_kernel(float* A, float* T_transpose) {\n  #pragma omp parallel for\n  for (int32_t ax0_ax1_fused = 0; ax0_ax1_fused < 64; ++ax0_ax1_fused) {\n    for (int32_t ax2 = 0; ax2 < 10; ++ax2) {\n      for (int32_t ax3_outer = 0; ax3_outer < 4; ++ax3_outer) {\n        for (int32_t ax3_inner = 0; ax3_inner < 16; ++ax3_inner) {\n          T_transpose[((((ax0_ax1_fused * 640) + (ax2 * 64)) + (ax3_outer * 16)) + ax3_inner)] = A[((((((ax0_ax1_fused >> 5) * 20480) + (ax3_outer * 5120)) + (ax3_inner * 320)) + ((ax0_ax1_fused & 31) * 10)) + ax2)];\n        }\n      }\n    }\n  }\n}\n\n",
        "cuda_code": "extern \"C\" __global__ void __launch_bounds__(1024) default_function_kernel(float* __restrict__ A, float* __restrict__ T_transpose) {\n  T_transpose[((((int)blockIdx.x) * 1024) + ((int)threadIdx.x))] = A[(((((((int)blockIdx.x) / 20) * 20480) + ((((int)threadIdx.x) & 63) * 320)) + ((((int)blockIdx.x) % 20) * 16)) + (((int)threadIdx.x) >> 6))];\n}\n\n",
        "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(A: T.Buffer((2, 64, 32, 10), \"float32\"), T_transpose: T.Buffer((2, 32, 10, 64), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0_ax1_fused in T.parallel(64):\n            for ax2, ax3_outer, ax3_inner in T.grid(10, 4, 16):\n                T_transpose_1 = T.Buffer((40960,), data=T_transpose.data)\n                A_1 = T.Buffer((40960,), data=A.data)\n                T_transpose_1[ax0_ax1_fused * 640 + ax2 * 64 + ax3_outer * 16 + ax3_inner] = A_1[ax0_ax1_fused // 32 * 20480 + ax3_outer * 5120 + ax3_inner * 320 + ax0_ax1_fused % 32 * 10 + ax2]",
        "op_args": "None",
        "input_shape": [
            [
                2,
                64,
                32,
                10
            ]
        ],
        "output_shape": [
            [
                2,
                32,
                10,
                64
            ]
        ],
        "input_name": [
            "A"
        ],
        "output_name": [
            "T_transpose"
        ]
    },
    {
        "op_name": "resize2d",
        "c_code": "void default_function_kernel(float* A, float* resize) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused = 0; i0_i1_fused < 64; ++i0_i1_fused) {\n    for (int32_t i2 = 0; i2 < 50; ++i2) {\n      for (int32_t i3_outer = 0; i3_outer < 4; ++i3_outer) {\n        for (int32_t i3_inner = 0; i3_inner < 16; ++i3_inner) {\n          if (((i3_outer * 8) + (i3_inner >> 1)) < 25) {\n            float cse_var_2 = (((((float)i2) + 5.000000e-01f) * 6.400000e-01f) - 5.000000e-01f);\n            float cse_var_1 = (((((float)((i3_outer * 16) + i3_inner)) + 5.000000e-01f) * 6.400000e-01f) - 5.000000e-01f);\n            resize[((((i0_i1_fused * 2500) + (i2 * 50)) + (i3_outer * 16)) + i3_inner)] = ((((A[(((i0_i1_fused * 1024) + (max(min(((int32_t)floorf(cse_var_2)), 31), 0) * 32)) + max(min(((int32_t)floorf(cse_var_1)), 31), 0))] * (1.000000e+00f - (cse_var_1 - ((float)((int32_t)floorf(cse_var_1)))))) + (A[(((i0_i1_fused * 1024) + (max(min(((int32_t)floorf(cse_var_2)), 31), 0) * 32)) + max(min((((int32_t)floorf(cse_var_1)) + 1), 31), 0))] * (cse_var_1 - ((float)((int32_t)floorf(cse_var_1)))))) * (1.000000e+00f - (cse_var_2 - ((float)((int32_t)floorf(cse_var_2)))))) + (((A[(((i0_i1_fused * 1024) + (max(min((((int32_t)floorf(cse_var_2)) + 1), 31), 0) * 32)) + max(min(((int32_t)floorf(cse_var_1)), 31), 0))] * (1.000000e+00f - (cse_var_1 - ((float)((int32_t)floorf(cse_var_1)))))) + (A[(((i0_i1_fused * 1024) + (max(min((((int32_t)floorf(cse_var_2)) + 1), 31), 0) * 32)) + max(min((((int32_t)floorf(cse_var_1)) + 1), 31), 0))] * (cse_var_1 - ((float)((int32_t)floorf(cse_var_1)))))) * (cse_var_2 - ((float)((int32_t)floorf(cse_var_2))))));\n          }\n        }\n      }\n    }\n  }\n}\n\n",
        "cuda_code": "extern \"C\" __global__ void __launch_bounds__(1024) default_function_kernel(float* __restrict__ A, float* __restrict__ resize) {\n  if (((((int)blockIdx.x) * 4) + (((int)threadIdx.x) >> 8)) < 625) {\n    resize[((((int)blockIdx.x) * 1024) + ((int)threadIdx.x))] = ((((A[((((((((int)blockIdx.x) * 256) + (((int)threadIdx.x) >> 2)) / 625) * 1024) + (max(min(((int)floorf((((((float)((((((int)blockIdx.x) * 512) + (((int)threadIdx.x) >> 1)) % 1250) / 25)) + 5.000000e-01f) * 6.400000e-01f) - 5.000000e-01f))), 31), 0) * 32)) + max(min(((int)floorf((((((float)(((((int)blockIdx.x) * 24) + ((int)threadIdx.x)) % 50)) + 5.000000e-01f) * 6.400000e-01f) - 5.000000e-01f))), 31), 0))] * (1.000000e+00f - ((((((float)(((((int)blockIdx.x) * 24) + ((int)threadIdx.x)) % 50)) + 5.000000e-01f) * 6.400000e-01f) - 5.000000e-01f) - ((float)((int)floorf((((((float)(((((int)blockIdx.x) * 24) + ((int)threadIdx.x)) % 50)) + 5.000000e-01f) * 6.400000e-01f) - 5.000000e-01f))))))) + (A[((((((((int)blockIdx.x) * 256) + (((int)threadIdx.x) >> 2)) / 625) * 1024) + (max(min(((int)floorf((((((float)((((((int)blockIdx.x) * 512) + (((int)threadIdx.x) >> 1)) % 1250) / 25)) + 5.000000e-01f) * 6.400000e-01f) - 5.000000e-01f))), 31), 0) * 32)) + max(min((((int)floorf((((((float)(((((int)blockIdx.x) * 24) + ((int)threadIdx.x)) % 50)) + 5.000000e-01f) * 6.400000e-01f) - 5.000000e-01f))) + 1), 31), 0))] * ((((((float)(((((int)blockIdx.x) * 24) + ((int)threadIdx.x)) % 50)) + 5.000000e-01f) * 6.400000e-01f) - 5.000000e-01f) - ((float)((int)floorf((((((float)(((((int)blockIdx.x) * 24) + ((int)threadIdx.x)) % 50)) + 5.000000e-01f) * 6.400000e-01f) - 5.000000e-01f))))))) * (1.000000e+00f - ((((((float)((((((int)blockIdx.x) * 512) + (((int)threadIdx.x) >> 1)) % 1250) / 25)) + 5.000000e-01f) * 6.400000e-01f) - 5.000000e-01f) - ((float)((int)floorf((((((float)((((((int)blockIdx.x) * 512) + (((int)threadIdx.x) >> 1)) % 1250) / 25)) + 5.000000e-01f) * 6.400000e-01f) - 5.000000e-01f))))))) + (((A[((((((((int)blockIdx.x) * 256) + (((int)threadIdx.x) >> 2)) / 625) * 1024) + (max(min((((int)floorf((((((float)((((((int)blockIdx.x) * 512) + (((int)threadIdx.x) >> 1)) % 1250) / 25)) + 5.000000e-01f) * 6.400000e-01f) - 5.000000e-01f))) + 1), 31), 0) * 32)) + max(min(((int)floorf((((((float)(((((int)blockIdx.x) * 24) + ((int)threadIdx.x)) % 50)) + 5.000000e-01f) * 6.400000e-01f) - 5.000000e-01f))), 31), 0))] * (1.000000e+00f - ((((((float)(((((int)blockIdx.x) * 24) + ((int)threadIdx.x)) % 50)) + 5.000000e-01f) * 6.400000e-01f) - 5.000000e-01f) - ((float)((int)floorf((((((float)(((((int)blockIdx.x) * 24) + ((int)threadIdx.x)) % 50)) + 5.000000e-01f) * 6.400000e-01f) - 5.000000e-01f))))))) + (A[((((((((int)blockIdx.x) * 256) + (((int)threadIdx.x) >> 2)) / 625) * 1024) + (max(min((((int)floorf((((((float)((((((int)blockIdx.x) * 512) + (((int)threadIdx.x) >> 1)) % 1250) / 25)) + 5.000000e-01f) * 6.400000e-01f) - 5.000000e-01f))) + 1), 31), 0) * 32)) + max(min((((int)floorf((((((float)(((((int)blockIdx.x) * 24) + ((int)threadIdx.x)) % 50)) + 5.000000e-01f) * 6.400000e-01f) - 5.000000e-01f))) + 1), 31), 0))] * ((((((float)(((((int)blockIdx.x) * 24) + ((int)threadIdx.x)) % 50)) + 5.000000e-01f) * 6.400000e-01f) - 5.000000e-01f) - ((float)((int)floorf((((((float)(((((int)blockIdx.x) * 24) + ((int)threadIdx.x)) % 50)) + 5.000000e-01f) * 6.400000e-01f) - 5.000000e-01f))))))) * ((((((float)((((((int)blockIdx.x) * 512) + (((int)threadIdx.x) >> 1)) % 1250) / 25)) + 5.000000e-01f) * 6.400000e-01f) - 5.000000e-01f) - ((float)((int)floorf((((((float)((((((int)blockIdx.x) * 512) + (((int)threadIdx.x) >> 1)) % 1250) / 25)) + 5.000000e-01f) * 6.400000e-01f) - 5.000000e-01f)))))));\n  }\n}\n\n",
        "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(A: T.Buffer((4, 16, 32, 32), \"float32\"), resize: T.Buffer((4, 16, 50, 50), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused in T.parallel(64):\n            for i2, i3_outer, i3_inner in T.grid(50, 4, 16):\n                if T.likely(i3_outer * 8 + i3_inner // 2 < 25):\n                    cse_var_4: T.int32 = i3_outer * 16\n                    cse_var_3: T.int32 = i0_i1_fused * 1024\n                    cse_var_2: T.float32 = (T.Cast(\"float32\", i2) + T.float32(0.5)) * T.float32(0.63999998569488525) - T.float32(0.5)\n                    cse_var_1: T.float32 = (T.Cast(\"float32\", cse_var_4 + i3_inner) + T.float32(0.5)) * T.float32(0.63999998569488525) - T.float32(0.5)\n                    resize_1 = T.Buffer((160000,), data=resize.data)\n                    A_1 = T.Buffer((65536,), data=A.data)\n                    resize_1[i0_i1_fused * 2500 + i2 * 50 + cse_var_4 + i3_inner] = (A_1[cse_var_3 + T.max(T.min(T.Cast(\"int32\", T.floor(cse_var_2)), 31), 0) * 32 + T.max(T.min(T.Cast(\"int32\", T.floor(cse_var_1)), 31), 0)] * (T.float32(1) - (cse_var_1 - T.Cast(\"float32\", T.Cast(\"int32\", T.floor(cse_var_1))))) + A_1[cse_var_3 + T.max(T.min(T.Cast(\"int32\", T.floor(cse_var_2)), 31), 0) * 32 + T.max(T.min(T.Cast(\"int32\", T.floor(cse_var_1)) + 1, 31), 0)] * (cse_var_1 - T.Cast(\"float32\", T.Cast(\"int32\", T.floor(cse_var_1))))) * (T.float32(1) - (cse_var_2 - T.Cast(\"float32\", T.Cast(\"int32\", T.floor(cse_var_2))))) + (A_1[cse_var_3 + T.max(T.min(T.Cast(\"int32\", T.floor(cse_var_2)) + 1, 31), 0) * 32 + T.max(T.min(T.Cast(\"int32\", T.floor(cse_var_1)), 31), 0)] * (T.float32(1) - (cse_var_1 - T.Cast(\"float32\", T.Cast(\"int32\", T.floor(cse_var_1))))) + A_1[cse_var_3 + T.max(T.min(T.Cast(\"int32\", T.floor(cse_var_2)) + 1, 31), 0) * 32 + T.max(T.min(T.Cast(\"int32\", T.floor(cse_var_1)) + 1, 31), 0)] * (cse_var_1 - T.Cast(\"float32\", T.Cast(\"int32\", T.floor(cse_var_1))))) * (cse_var_2 - T.Cast(\"float32\", T.Cast(\"int32\", T.floor(cse_var_2))))",
        "op_args": "None",
        "input_shape": [
            [
                4,
                16,
                32,
                32
            ]
        ],
        "output_shape": [
            [
                4,
                16,
                50,
                50
            ]
        ],
        "input_name": [
            "A"
        ],
        "output_name": [
            "resize"
        ]
    },
    {
        "op_name": "resize3d",
        "c_code": "void default_function_kernel(float* A, float* resize) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused = 0; i0_i1_fused_i2_fused < 480; ++i0_i1_fused_i2_fused) {\n    for (int32_t i3 = 0; i3 < 10; ++i3) {\n      for (int32_t i4_inner = 0; i4_inner < 10; ++i4_inner) {\n        float cse_var_3 = (((((float)i4_inner) + 5.000000e-01f) * 3.200000e+00f) - 5.000000e-01f);\n        float cse_var_2 = (((((float)i3) + 5.000000e-01f) * 3.200000e+00f) - 5.000000e-01f);\n        float cse_var_1 = (((((float)(i0_i1_fused_i2_fused % 10)) + 5.000000e-01f) * 3.200000e+00f) - 5.000000e-01f);\n        resize[(((i0_i1_fused_i2_fused * 100) + (i3 * 10)) + i4_inner)] = ((((((A[(((((i0_i1_fused_i2_fused / 10) * 32768) + (max(min(((int32_t)floorf(cse_var_1)), 31), 0) * 1024)) + (max(min(((int32_t)floorf(cse_var_2)), 31), 0) * 32)) + max(min(((int32_t)floorf(cse_var_3)), 31), 0))] * (1.000000e+00f - (cse_var_3 - ((float)((int32_t)floorf(cse_var_3)))))) + (A[(((((i0_i1_fused_i2_fused / 10) * 32768) + (max(min(((int32_t)floorf(cse_var_1)), 31), 0) * 1024)) + (max(min(((int32_t)floorf(cse_var_2)), 31), 0) * 32)) + max(min((((int32_t)floorf(cse_var_3)) + 1), 31), 0))] * (cse_var_3 - ((float)((int32_t)floorf(cse_var_3)))))) * (1.000000e+00f - (cse_var_2 - ((float)((int32_t)floorf(cse_var_2)))))) + (((A[(((((i0_i1_fused_i2_fused / 10) * 32768) + (max(min(((int32_t)floorf(cse_var_1)), 31), 0) * 1024)) + (max(min((((int32_t)floorf(cse_var_2)) + 1), 31), 0) * 32)) + max(min(((int32_t)floorf(cse_var_3)), 31), 0))] * (1.000000e+00f - (cse_var_3 - ((float)((int32_t)floorf(cse_var_3)))))) + (A[(((((i0_i1_fused_i2_fused / 10) * 32768) + (max(min(((int32_t)floorf(cse_var_1)), 31), 0) * 1024)) + (max(min((((int32_t)floorf(cse_var_2)) + 1), 31), 0) * 32)) + max(min((((int32_t)floorf(cse_var_3)) + 1), 31), 0))] * (cse_var_3 - ((float)((int32_t)floorf(cse_var_3)))))) * (cse_var_2 - ((float)((int32_t)floorf(cse_var_2)))))) * (1.000000e+00f - (cse_var_1 - ((float)((int32_t)floorf(cse_var_1)))))) + (((((A[(((((i0_i1_fused_i2_fused / 10) * 32768) + (max(min((((int32_t)floorf(cse_var_1)) + 1), 31), 0) * 1024)) + (max(min(((int32_t)floorf(cse_var_2)), 31), 0) * 32)) + max(min(((int32_t)floorf(cse_var_3)), 31), 0))] * (1.000000e+00f - (cse_var_3 - ((float)((int32_t)floorf(cse_var_3)))))) + (A[(((((i0_i1_fused_i2_fused / 10) * 32768) + (max(min((((int32_t)floorf(cse_var_1)) + 1), 31), 0) * 1024)) + (max(min(((int32_t)floorf(cse_var_2)), 31), 0) * 32)) + max(min((((int32_t)floorf(cse_var_3)) + 1), 31), 0))] * (cse_var_3 - ((float)((int32_t)floorf(cse_var_3)))))) * (1.000000e+00f - (cse_var_2 - ((float)((int32_t)floorf(cse_var_2)))))) + (((A[(((((i0_i1_fused_i2_fused / 10) * 32768) + (max(min((((int32_t)floorf(cse_var_1)) + 1), 31), 0) * 1024)) + (max(min((((int32_t)floorf(cse_var_2)) + 1), 31), 0) * 32)) + max(min(((int32_t)floorf(cse_var_3)), 31), 0))] * (1.000000e+00f - (cse_var_3 - ((float)((int32_t)floorf(cse_var_3)))))) + (A[(((((i0_i1_fused_i2_fused / 10) * 32768) + (max(min((((int32_t)floorf(cse_var_1)) + 1), 31), 0) * 1024)) + (max(min((((int32_t)floorf(cse_var_2)) + 1), 31), 0) * 32)) + max(min((((int32_t)floorf(cse_var_3)) + 1), 31), 0))] * (cse_var_3 - ((float)((int32_t)floorf(cse_var_3)))))) * (cse_var_2 - ((float)((int32_t)floorf(cse_var_2)))))) * (cse_var_1 - ((float)((int32_t)floorf(cse_var_1))))));\n      }\n    }\n  }\n}\n\n",
        "cuda_code": "extern \"C\" __global__ void __launch_bounds__(1024) default_function_kernel(float* __restrict__ A, float* __restrict__ resize) {\n  if (((((int)blockIdx.x) * 8) + (((int)threadIdx.x) >> 7)) < 375) {\n    resize[((((int)blockIdx.x) * 1024) + ((int)threadIdx.x))] = ((((((A[(((((((((int)blockIdx.x) * 128) + (((int)threadIdx.x) >> 3)) / 125) * 32768) + (max(min(((int)floorf((((((float)((((((int)blockIdx.x) * 6) + (((int)threadIdx.x) >> 2)) % 250) / 25)) + 5.000000e-01f) * 3.200000e+00f) - 5.000000e-01f))), 31), 0) * 1024)) + (max(min(((int)floorf((((((float)((((((int)blockIdx.x) * 12) + (((int)threadIdx.x) >> 1)) % 50) / 5)) + 5.000000e-01f) * 3.200000e+00f) - 5.000000e-01f))), 31), 0) * 32)) + max(min(((int)floorf((((((float)(((((int)blockIdx.x) * 4) + ((int)threadIdx.x)) % 10)) + 5.000000e-01f) * 3.200000e+00f) - 5.000000e-01f))), 31), 0))] * (1.000000e+00f - ((((((float)(((((int)blockIdx.x) * 4) + ((int)threadIdx.x)) % 10)) + 5.000000e-01f) * 3.200000e+00f) - 5.000000e-01f) - ((float)((int)floorf((((((float)(((((int)blockIdx.x) * 4) + ((int)threadIdx.x)) % 10)) + 5.000000e-01f) * 3.200000e+00f) - 5.000000e-01f))))))) + (A[(((((((((int)blockIdx.x) * 128) + (((int)threadIdx.x) >> 3)) / 125) * 32768) + (max(min(((int)floorf((((((float)((((((int)blockIdx.x) * 6) + (((int)threadIdx.x) >> 2)) % 250) / 25)) + 5.000000e-01f) * 3.200000e+00f) - 5.000000e-01f))), 31), 0) * 1024)) + (max(min(((int)floorf((((((float)((((((int)blockIdx.x) * 12) + (((int)threadIdx.x) >> 1)) % 50) / 5)) + 5.000000e-01f) * 3.200000e+00f) - 5.000000e-01f))), 31), 0) * 32)) + max(min((((int)floorf((((((float)(((((int)blockIdx.x) * 4) + ((int)threadIdx.x)) % 10)) + 5.000000e-01f) * 3.200000e+00f) - 5.000000e-01f))) + 1), 31), 0))] * ((((((float)(((((int)blockIdx.x) * 4) + ((int)threadIdx.x)) % 10)) + 5.000000e-01f) * 3.200000e+00f) - 5.000000e-01f) - ((float)((int)floorf((((((float)(((((int)blockIdx.x) * 4) + ((int)threadIdx.x)) % 10)) + 5.000000e-01f) * 3.200000e+00f) - 5.000000e-01f))))))) * (1.000000e+00f - ((((((float)((((((int)blockIdx.x) * 12) + (((int)threadIdx.x) >> 1)) % 50) / 5)) + 5.000000e-01f) * 3.200000e+00f) - 5.000000e-01f) - ((float)((int)floorf((((((float)((((((int)blockIdx.x) * 12) + (((int)threadIdx.x) >> 1)) % 50) / 5)) + 5.000000e-01f) * 3.200000e+00f) - 5.000000e-01f))))))) + (((A[(((((((((int)blockIdx.x) * 128) + (((int)threadIdx.x) >> 3)) / 125) * 32768) + (max(min(((int)floorf((((((float)((((((int)blockIdx.x) * 6) + (((int)threadIdx.x) >> 2)) % 250) / 25)) + 5.000000e-01f) * 3.200000e+00f) - 5.000000e-01f))), 31), 0) * 1024)) + (max(min((((int)floorf((((((float)((((((int)blockIdx.x) * 12) + (((int)threadIdx.x) >> 1)) % 50) / 5)) + 5.000000e-01f) * 3.200000e+00f) - 5.000000e-01f))) + 1), 31), 0) * 32)) + max(min(((int)floorf((((((float)(((((int)blockIdx.x) * 4) + ((int)threadIdx.x)) % 10)) + 5.000000e-01f) * 3.200000e+00f) - 5.000000e-01f))), 31), 0))] * (1.000000e+00f - ((((((float)(((((int)blockIdx.x) * 4) + ((int)threadIdx.x)) % 10)) + 5.000000e-01f) * 3.200000e+00f) - 5.000000e-01f) - ((float)((int)floorf((((((float)(((((int)blockIdx.x) * 4) + ((int)threadIdx.x)) % 10)) + 5.000000e-01f) * 3.200000e+00f) - 5.000000e-01f))))))) + (A[(((((((((int)blockIdx.x) * 128) + (((int)threadIdx.x) >> 3)) / 125) * 32768) + (max(min(((int)floorf((((((float)((((((int)blockIdx.x) * 6) + (((int)threadIdx.x) >> 2)) % 250) / 25)) + 5.000000e-01f) * 3.200000e+00f) - 5.000000e-01f))), 31), 0) * 1024)) + (max(min((((int)floorf((((((float)((((((int)blockIdx.x) * 12) + (((int)threadIdx.x) >> 1)) % 50) / 5)) + 5.000000e-01f) * 3.200000e+00f) - 5.000000e-01f))) + 1), 31), 0) * 32)) + max(min((((int)floorf((((((float)(((((int)blockIdx.x) * 4) + ((int)threadIdx.x)) % 10)) + 5.000000e-01f) * 3.200000e+00f) - 5.000000e-01f))) + 1), 31), 0))] * ((((((float)(((((int)blockIdx.x) * 4) + ((int)threadIdx.x)) % 10)) + 5.000000e-01f) * 3.200000e+00f) - 5.000000e-01f) - ((float)((int)floorf((((((float)(((((int)blockIdx.x) * 4) + ((int)threadIdx.x)) % 10)) + 5.000000e-01f) * 3.200000e+00f) - 5.000000e-01f))))))) * ((((((float)((((((int)blockIdx.x) * 12) + (((int)threadIdx.x) >> 1)) % 50) / 5)) + 5.000000e-01f) * 3.200000e+00f) - 5.000000e-01f) - ((float)((int)floorf((((((float)((((((int)blockIdx.x) * 12) + (((int)threadIdx.x) >> 1)) % 50) / 5)) + 5.000000e-01f) * 3.200000e+00f) - 5.000000e-01f))))))) * (1.000000e+00f - ((((((float)((((((int)blockIdx.x) * 6) + (((int)threadIdx.x) >> 2)) % 250) / 25)) + 5.000000e-01f) * 3.200000e+00f) - 5.000000e-01f) - ((float)((int)floorf((((((float)((((((int)blockIdx.x) * 6) + (((int)threadIdx.x) >> 2)) % 250) / 25)) + 5.000000e-01f) * 3.200000e+00f) - 5.000000e-01f))))))) + (((((A[(((((((((int)blockIdx.x) * 128) + (((int)threadIdx.x) >> 3)) / 125) * 32768) + (max(min((((int)floorf((((((float)((((((int)blockIdx.x) * 6) + (((int)threadIdx.x) >> 2)) % 250) / 25)) + 5.000000e-01f) * 3.200000e+00f) - 5.000000e-01f))) + 1), 31), 0) * 1024)) + (max(min(((int)floorf((((((float)((((((int)blockIdx.x) * 12) + (((int)threadIdx.x) >> 1)) % 50) / 5)) + 5.000000e-01f) * 3.200000e+00f) - 5.000000e-01f))), 31), 0) * 32)) + max(min(((int)floorf((((((float)(((((int)blockIdx.x) * 4) + ((int)threadIdx.x)) % 10)) + 5.000000e-01f) * 3.200000e+00f) - 5.000000e-01f))), 31), 0))] * (1.000000e+00f - ((((((float)(((((int)blockIdx.x) * 4) + ((int)threadIdx.x)) % 10)) + 5.000000e-01f) * 3.200000e+00f) - 5.000000e-01f) - ((float)((int)floorf((((((float)(((((int)blockIdx.x) * 4) + ((int)threadIdx.x)) % 10)) + 5.000000e-01f) * 3.200000e+00f) - 5.000000e-01f))))))) + (A[(((((((((int)blockIdx.x) * 128) + (((int)threadIdx.x) >> 3)) / 125) * 32768) + (max(min((((int)floorf((((((float)((((((int)blockIdx.x) * 6) + (((int)threadIdx.x) >> 2)) % 250) / 25)) + 5.000000e-01f) * 3.200000e+00f) - 5.000000e-01f))) + 1), 31), 0) * 1024)) + (max(min(((int)floorf((((((float)((((((int)blockIdx.x) * 12) + (((int)threadIdx.x) >> 1)) % 50) / 5)) + 5.000000e-01f) * 3.200000e+00f) - 5.000000e-01f))), 31), 0) * 32)) + max(min((((int)floorf((((((float)(((((int)blockIdx.x) * 4) + ((int)threadIdx.x)) % 10)) + 5.000000e-01f) * 3.200000e+00f) - 5.000000e-01f))) + 1), 31), 0))] * ((((((float)(((((int)blockIdx.x) * 4) + ((int)threadIdx.x)) % 10)) + 5.000000e-01f) * 3.200000e+00f) - 5.000000e-01f) - ((float)((int)floorf((((((float)(((((int)blockIdx.x) * 4) + ((int)threadIdx.x)) % 10)) + 5.000000e-01f) * 3.200000e+00f) - 5.000000e-01f))))))) * (1.000000e+00f - ((((((float)((((((int)blockIdx.x) * 12) + (((int)threadIdx.x) >> 1)) % 50) / 5)) + 5.000000e-01f) * 3.200000e+00f) - 5.000000e-01f) - ((float)((int)floorf((((((float)((((((int)blockIdx.x) * 12) + (((int)threadIdx.x) >> 1)) % 50) / 5)) + 5.000000e-01f) * 3.200000e+00f) - 5.000000e-01f))))))) + (((A[(((((((((int)blockIdx.x) * 128) + (((int)threadIdx.x) >> 3)) / 125) * 32768) + (max(min((((int)floorf((((((float)((((((int)blockIdx.x) * 6) + (((int)threadIdx.x) >> 2)) % 250) / 25)) + 5.000000e-01f) * 3.200000e+00f) - 5.000000e-01f))) + 1), 31), 0) * 1024)) + (max(min((((int)floorf((((((float)((((((int)blockIdx.x) * 12) + (((int)threadIdx.x) >> 1)) % 50) / 5)) + 5.000000e-01f) * 3.200000e+00f) - 5.000000e-01f))) + 1), 31), 0) * 32)) + max(min(((int)floorf((((((float)(((((int)blockIdx.x) * 4) + ((int)threadIdx.x)) % 10)) + 5.000000e-01f) * 3.200000e+00f) - 5.000000e-01f))), 31), 0))] * (1.000000e+00f - ((((((float)(((((int)blockIdx.x) * 4) + ((int)threadIdx.x)) % 10)) + 5.000000e-01f) * 3.200000e+00f) - 5.000000e-01f) - ((float)((int)floorf((((((float)(((((int)blockIdx.x) * 4) + ((int)threadIdx.x)) % 10)) + 5.000000e-01f) * 3.200000e+00f) - 5.000000e-01f))))))) + (A[(((((((((int)blockIdx.x) * 128) + (((int)threadIdx.x) >> 3)) / 125) * 32768) + (max(min((((int)floorf((((((float)((((((int)blockIdx.x) * 6) + (((int)threadIdx.x) >> 2)) % 250) / 25)) + 5.000000e-01f) * 3.200000e+00f) - 5.000000e-01f))) + 1), 31), 0) * 1024)) + (max(min((((int)floorf((((((float)((((((int)blockIdx.x) * 12) + (((int)threadIdx.x) >> 1)) % 50) / 5)) + 5.000000e-01f) * 3.200000e+00f) - 5.000000e-01f))) + 1), 31), 0) * 32)) + max(min((((int)floorf((((((float)(((((int)blockIdx.x) * 4) + ((int)threadIdx.x)) % 10)) + 5.000000e-01f) * 3.200000e+00f) - 5.000000e-01f))) + 1), 31), 0))] * ((((((float)(((((int)blockIdx.x) * 4) + ((int)threadIdx.x)) % 10)) + 5.000000e-01f) * 3.200000e+00f) - 5.000000e-01f) - ((float)((int)floorf((((((float)(((((int)blockIdx.x) * 4) + ((int)threadIdx.x)) % 10)) + 5.000000e-01f) * 3.200000e+00f) - 5.000000e-01f))))))) * ((((((float)((((((int)blockIdx.x) * 12) + (((int)threadIdx.x) >> 1)) % 50) / 5)) + 5.000000e-01f) * 3.200000e+00f) - 5.000000e-01f) - ((float)((int)floorf((((((float)((((((int)blockIdx.x) * 12) + (((int)threadIdx.x) >> 1)) % 50) / 5)) + 5.000000e-01f) * 3.200000e+00f) - 5.000000e-01f))))))) * ((((((float)((((((int)blockIdx.x) * 6) + (((int)threadIdx.x) >> 2)) % 250) / 25)) + 5.000000e-01f) * 3.200000e+00f) - 5.000000e-01f) - ((float)((int)floorf((((((float)((((((int)blockIdx.x) * 6) + (((int)threadIdx.x) >> 2)) % 250) / 25)) + 5.000000e-01f) * 3.200000e+00f) - 5.000000e-01f)))))));\n  }\n}\n\n",
        "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(A: T.Buffer((3, 16, 32, 32, 32), \"float32\"), resize: T.Buffer((3, 16, 10, 10, 10), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused_i2_fused in T.parallel(480):\n            for i3, i4_inner in T.grid(10, 10):\n                cse_var_4: T.int32 = i0_i1_fused_i2_fused // 10 * 32768\n                cse_var_3: T.float32 = (T.Cast(\"float32\", i4_inner) + T.float32(0.5)) * T.float32(3.2000000476837158) - T.float32(0.5)\n                cse_var_2: T.float32 = (T.Cast(\"float32\", i3) + T.float32(0.5)) * T.float32(3.2000000476837158) - T.float32(0.5)\n                cse_var_1: T.float32 = (T.Cast(\"float32\", i0_i1_fused_i2_fused % 10) + T.float32(0.5)) * T.float32(3.2000000476837158) - T.float32(0.5)\n                resize_1 = T.Buffer((48000,), data=resize.data)\n                A_1 = T.Buffer((1572864,), data=A.data)\n                resize_1[i0_i1_fused_i2_fused * 100 + i3 * 10 + i4_inner] = ((A_1[cse_var_4 + T.max(T.min(T.Cast(\"int32\", T.floor(cse_var_1)), 31), 0) * 1024 + T.max(T.min(T.Cast(\"int32\", T.floor(cse_var_2)), 31), 0) * 32 + T.max(T.min(T.Cast(\"int32\", T.floor(cse_var_3)), 31), 0)] * (T.float32(1) - (cse_var_3 - T.Cast(\"float32\", T.Cast(\"int32\", T.floor(cse_var_3))))) + A_1[cse_var_4 + T.max(T.min(T.Cast(\"int32\", T.floor(cse_var_1)), 31), 0) * 1024 + T.max(T.min(T.Cast(\"int32\", T.floor(cse_var_2)), 31), 0) * 32 + T.max(T.min(T.Cast(\"int32\", T.floor(cse_var_3)) + 1, 31), 0)] * (cse_var_3 - T.Cast(\"float32\", T.Cast(\"int32\", T.floor(cse_var_3))))) * (T.float32(1) - (cse_var_2 - T.Cast(\"float32\", T.Cast(\"int32\", T.floor(cse_var_2))))) + (A_1[cse_var_4 + T.max(T.min(T.Cast(\"int32\", T.floor(cse_var_1)), 31), 0) * 1024 + T.max(T.min(T.Cast(\"int32\", T.floor(cse_var_2)) + 1, 31), 0) * 32 + T.max(T.min(T.Cast(\"int32\", T.floor(cse_var_3)), 31), 0)] * (T.float32(1) - (cse_var_3 - T.Cast(\"float32\", T.Cast(\"int32\", T.floor(cse_var_3))))) + A_1[cse_var_4 + T.max(T.min(T.Cast(\"int32\", T.floor(cse_var_1)), 31), 0) * 1024 + T.max(T.min(T.Cast(\"int32\", T.floor(cse_var_2)) + 1, 31), 0) * 32 + T.max(T.min(T.Cast(\"int32\", T.floor(cse_var_3)) + 1, 31), 0)] * (cse_var_3 - T.Cast(\"float32\", T.Cast(\"int32\", T.floor(cse_var_3))))) * (cse_var_2 - T.Cast(\"float32\", T.Cast(\"int32\", T.floor(cse_var_2))))) * (T.float32(1) - (cse_var_1 - T.Cast(\"float32\", T.Cast(\"int32\", T.floor(cse_var_1))))) + ((A_1[cse_var_4 + T.max(T.min(T.Cast(\"int32\", T.floor(cse_var_1)) + 1, 31), 0) * 1024 + T.max(T.min(T.Cast(\"int32\", T.floor(cse_var_2)), 31), 0) * 32 + T.max(T.min(T.Cast(\"int32\", T.floor(cse_var_3)), 31), 0)] * (T.float32(1) - (cse_var_3 - T.Cast(\"float32\", T.Cast(\"int32\", T.floor(cse_var_3))))) + A_1[cse_var_4 + T.max(T.min(T.Cast(\"int32\", T.floor(cse_var_1)) + 1, 31), 0) * 1024 + T.max(T.min(T.Cast(\"int32\", T.floor(cse_var_2)), 31), 0) * 32 + T.max(T.min(T.Cast(\"int32\", T.floor(cse_var_3)) + 1, 31), 0)] * (cse_var_3 - T.Cast(\"float32\", T.Cast(\"int32\", T.floor(cse_var_3))))) * (T.float32(1) - (cse_var_2 - T.Cast(\"float32\", T.Cast(\"int32\", T.floor(cse_var_2))))) + (A_1[cse_var_4 + T.max(T.min(T.Cast(\"int32\", T.floor(cse_var_1)) + 1, 31), 0) * 1024 + T.max(T.min(T.Cast(\"int32\", T.floor(cse_var_2)) + 1, 31), 0) * 32 + T.max(T.min(T.Cast(\"int32\", T.floor(cse_var_3)), 31), 0)] * (T.float32(1) - (cse_var_3 - T.Cast(\"float32\", T.Cast(\"int32\", T.floor(cse_var_3))))) + A_1[cse_var_4 + T.max(T.min(T.Cast(\"int32\", T.floor(cse_var_1)) + 1, 31), 0) * 1024 + T.max(T.min(T.Cast(\"int32\", T.floor(cse_var_2)) + 1, 31), 0) * 32 + T.max(T.min(T.Cast(\"int32\", T.floor(cse_var_3)) + 1, 31), 0)] * (cse_var_3 - T.Cast(\"float32\", T.Cast(\"int32\", T.floor(cse_var_3))))) * (cse_var_2 - T.Cast(\"float32\", T.Cast(\"int32\", T.floor(cse_var_2))))) * (cse_var_1 - T.Cast(\"float32\", T.Cast(\"int32\", T.floor(cse_var_1))))",
        "op_args": "None",
        "input_shape": [
            [
                3,
                16,
                32,
                32,
                32
            ]
        ],
        "output_shape": [
            [
                3,
                16,
                10,
                10,
                10
            ]
        ],
        "input_name": [
            "A"
        ],
        "output_name": [
            "resize"
        ]
    },
    {
        "op_name": "rsqrt",
        "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0 = 0; i0 < 15; ++i0) {\n    for (int32_t i1 = 0; i1 < 11; ++i1) {\n      for (int32_t i2 = 0; i2 < 16; ++i2) {\n        for (int32_t i3 = 0; i3 < 20; ++i3) {\n          compute[((((i0 * 3520) + (i1 * 320)) + (i2 * 20)) + i3)] = (1.000000e+00f / sqrtf(data[((((i0 * 3520) + (i1 * 320)) + (i2 * 20)) + i3)]));\n        }\n      }\n    }\n  }\n}\n\n",
        "cuda_code": "extern \"C\" __global__ void __launch_bounds__(48) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 48) + ((int)threadIdx.x))] = (1.000000e+00f / sqrtf(data[((((int)blockIdx.x) * 48) + ((int)threadIdx.x))]));\n}\n\n",
        "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((15, 11, 16, 20), \"float32\"), compute: T.Buffer((15, 11, 16, 20), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0 in T.parallel(15):\n            for i1, i2, i3 in T.grid(11, 16, 20):\n                cse_var_1: T.int32 = i0 * 3520 + i1 * 320 + i2 * 20 + i3\n                compute_1 = T.Buffer((52800,), data=compute.data)\n                data_1 = T.Buffer((52800,), data=data.data)\n                compute_1[cse_var_1] = T.rsqrt(data_1[cse_var_1])",
        "op_args": [
            15,
            11,
            16,
            20
        ],
        "input_shape": [
            [
                15,
                11,
                16,
                20
            ]
        ],
        "output_shape": [
            [
                15,
                11,
                16,
                20
            ]
        ]
    },
    {
        "op_name": "sinh",
        "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0 = 0; i0 < 13; ++i0) {\n    for (int32_t i1 = 0; i1 < 7; ++i1) {\n      for (int32_t i2 = 0; i2 < 14; ++i2) {\n        for (int32_t i3 = 0; i3 < 17; ++i3) {\n          compute[((((i0 * 1666) + (i1 * 238)) + (i2 * 17)) + i3)] = sinhf(data[((((i0 * 1666) + (i1 * 238)) + (i2 * 17)) + i3)]);\n        }\n      }\n    }\n  }\n}\n\n",
        "cuda_code": "extern \"C\" __global__ void __launch_bounds__(34) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 34) + ((int)threadIdx.x))] = sinhf(data[((((int)blockIdx.x) * 34) + ((int)threadIdx.x))]);\n}\n\n",
        "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((13, 7, 14, 17), \"float32\"), compute: T.Buffer((13, 7, 14, 17), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0 in T.parallel(13):\n            for i1, i2, i3 in T.grid(7, 14, 17):\n                cse_var_1: T.int32 = i0 * 1666 + i1 * 238 + i2 * 17 + i3\n                compute_1 = T.Buffer((21658,), data=compute.data)\n                data_1 = T.Buffer((21658,), data=data.data)\n                compute_1[cse_var_1] = T.sinh(data_1[cse_var_1])",
        "op_args": [
            13,
            7,
            14,
            17
        ],
        "input_shape": [
            [
                13,
                7,
                14,
                17
            ]
        ],
        "output_shape": [
            [
                13,
                7,
                14,
                17
            ]
        ]
    },
    {
        "op_name": "cosh",
        "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused_i3_fused = 0; i0_i1_fused_i2_fused_i3_fused < 5814; ++i0_i1_fused_i2_fused_i3_fused) {\n    compute[i0_i1_fused_i2_fused_i3_fused] = coshf(data[i0_i1_fused_i2_fused_i3_fused]);\n  }\n}\n\n",
        "cuda_code": "extern \"C\" __global__ void __launch_bounds__(48) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  if (((((int)blockIdx.x) * 8) + (((int)threadIdx.x) / 6)) < 969) {\n    compute[((((int)blockIdx.x) * 48) + ((int)threadIdx.x))] = coshf(data[((((int)blockIdx.x) * 48) + ((int)threadIdx.x))]);\n  }\n}\n\n",
        "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((3, 6, 17, 19), \"float32\"), compute: T.Buffer((3, 6, 17, 19), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused_i2_fused_i3_fused in T.parallel(5814):\n            compute_1 = T.Buffer((5814,), data=compute.data)\n            data_1 = T.Buffer((5814,), data=data.data)\n            compute_1[i0_i1_fused_i2_fused_i3_fused] = T.cosh(data_1[i0_i1_fused_i2_fused_i3_fused])",
        "op_args": [
            3,
            6,
            17,
            19
        ],
        "input_shape": [
            [
                3,
                6,
                17,
                19
            ]
        ],
        "output_shape": [
            [
                3,
                6,
                17,
                19
            ]
        ]
    },
    {
        "op_name": "grid_sample",
        "c_code": "void default_function_kernel(float* compute, float* data, float* grid) {\n  #pragma omp parallel for\n  for (int32_t n_c_fused = 0; n_c_fused < 16; ++n_c_fused) {\n    for (int32_t h = 0; h < 16; ++h) {\n      for (int32_t w_inner = 0; w_inner < 16; ++w_inner) {\n        compute[(((n_c_fused * 256) + (h * 16)) + w_inner)] = ((((((((((0 <= ((int32_t)floorf((((grid[(((((n_c_fused >> 2) * 512) + (h * 16)) + w_inner) + 256)] + 1.000000e+00f) * 7.000000e+00f) * 5.000000e-01f)))) && (0 <= ((int32_t)floorf((((grid[((((n_c_fused >> 2) * 512) + (h * 16)) + w_inner)] + 1.000000e+00f) * 7.000000e+00f) * 5.000000e-01f))))) && (((int32_t)floorf((((grid[(((((n_c_fused >> 2) * 512) + (h * 16)) + w_inner) + 256)] + 1.000000e+00f) * 7.000000e+00f) * 5.000000e-01f))) < 8)) && (((int32_t)floorf((((grid[((((n_c_fused >> 2) * 512) + (h * 16)) + w_inner)] + 1.000000e+00f) * 7.000000e+00f) * 5.000000e-01f))) < 8)) ? data[(((n_c_fused * 64) + (((int32_t)floorf((((grid[(((((n_c_fused >> 2) * 512) + (h * 16)) + w_inner) + 256)] + 1.000000e+00f) * 7.000000e+00f) * 5.000000e-01f))) * 8)) + ((int32_t)floorf((((grid[((((n_c_fused >> 2) * 512) + (h * 16)) + w_inner)] + 1.000000e+00f) * 7.000000e+00f) * 5.000000e-01f))))] : 0.000000e+00f) * (1.000000e+00f - ((((grid[(((((n_c_fused >> 2) * 512) + (h * 16)) + w_inner) + 256)] + 1.000000e+00f) * 7.000000e+00f) * 5.000000e-01f) - ((float)((int32_t)floorf((((grid[(((((n_c_fused >> 2) * 512) + (h * 16)) + w_inner) + 256)] + 1.000000e+00f) * 7.000000e+00f) * 5.000000e-01f))))))) * (1.000000e+00f - ((((grid[((((n_c_fused >> 2) * 512) + (h * 16)) + w_inner)] + 1.000000e+00f) * 7.000000e+00f) * 5.000000e-01f) - ((float)((int32_t)floorf((((grid[((((n_c_fused >> 2) * 512) + (h * 16)) + w_inner)] + 1.000000e+00f) * 7.000000e+00f) * 5.000000e-01f))))))) + (((((((0 <= ((int32_t)floorf((((grid[(((((n_c_fused >> 2) * 512) + (h * 16)) + w_inner) + 256)] + 1.000000e+00f) * 7.000000e+00f) * 5.000000e-01f)))) && (-1 <= ((int32_t)floorf((((grid[((((n_c_fused >> 2) * 512) + (h * 16)) + w_inner)] + 1.000000e+00f) * 7.000000e+00f) * 5.000000e-01f))))) && (((int32_t)floorf((((grid[(((((n_c_fused >> 2) * 512) + (h * 16)) + w_inner) + 256)] + 1.000000e+00f) * 7.000000e+00f) * 5.000000e-01f))) < 8)) && (((int32_t)floorf((((grid[((((n_c_fused >> 2) * 512) + (h * 16)) + w_inner)] + 1.000000e+00f) * 7.000000e+00f) * 5.000000e-01f))) < 7)) ? data[((((n_c_fused * 64) + (((int32_t)floorf((((grid[(((((n_c_fused >> 2) * 512) + (h * 16)) + w_inner) + 256)] + 1.000000e+00f) * 7.000000e+00f) * 5.000000e-01f))) * 8)) + ((int32_t)floorf((((grid[((((n_c_fused >> 2) * 512) + (h * 16)) + w_inner)] + 1.000000e+00f) * 7.000000e+00f) * 5.000000e-01f)))) + 1)] : 0.000000e+00f) * (1.000000e+00f - ((((grid[(((((n_c_fused >> 2) * 512) + (h * 16)) + w_inner) + 256)] + 1.000000e+00f) * 7.000000e+00f) * 5.000000e-01f) - ((float)((int32_t)floorf((((grid[(((((n_c_fused >> 2) * 512) + (h * 16)) + w_inner) + 256)] + 1.000000e+00f) * 7.000000e+00f) * 5.000000e-01f))))))) * ((((grid[((((n_c_fused >> 2) * 512) + (h * 16)) + w_inner)] + 1.000000e+00f) * 7.000000e+00f) * 5.000000e-01f) - ((float)((int32_t)floorf((((grid[((((n_c_fused >> 2) * 512) + (h * 16)) + w_inner)] + 1.000000e+00f) * 7.000000e+00f) * 5.000000e-01f))))))) + (((((((-1 <= ((int32_t)floorf((((grid[(((((n_c_fused >> 2) * 512) + (h * 16)) + w_inner) + 256)] + 1.000000e+00f) * 7.000000e+00f) * 5.000000e-01f)))) && (0 <= ((int32_t)floorf((((grid[((((n_c_fused >> 2) * 512) + (h * 16)) + w_inner)] + 1.000000e+00f) * 7.000000e+00f) * 5.000000e-01f))))) && (((int32_t)floorf((((grid[(((((n_c_fused >> 2) * 512) + (h * 16)) + w_inner) + 256)] + 1.000000e+00f) * 7.000000e+00f) * 5.000000e-01f))) < 7)) && (((int32_t)floorf((((grid[((((n_c_fused >> 2) * 512) + (h * 16)) + w_inner)] + 1.000000e+00f) * 7.000000e+00f) * 5.000000e-01f))) < 8)) ? data[((((n_c_fused * 64) + (((int32_t)floorf((((grid[(((((n_c_fused >> 2) * 512) + (h * 16)) + w_inner) + 256)] + 1.000000e+00f) * 7.000000e+00f) * 5.000000e-01f))) * 8)) + ((int32_t)floorf((((grid[((((n_c_fused >> 2) * 512) + (h * 16)) + w_inner)] + 1.000000e+00f) * 7.000000e+00f) * 5.000000e-01f)))) + 8)] : 0.000000e+00f) * ((((grid[(((((n_c_fused >> 2) * 512) + (h * 16)) + w_inner) + 256)] + 1.000000e+00f) * 7.000000e+00f) * 5.000000e-01f) - ((float)((int32_t)floorf((((grid[(((((n_c_fused >> 2) * 512) + (h * 16)) + w_inner) + 256)] + 1.000000e+00f) * 7.000000e+00f) * 5.000000e-01f)))))) * (1.000000e+00f - ((((grid[((((n_c_fused >> 2) * 512) + (h * 16)) + w_inner)] + 1.000000e+00f) * 7.000000e+00f) * 5.000000e-01f) - ((float)((int32_t)floorf((((grid[((((n_c_fused >> 2) * 512) + (h * 16)) + w_inner)] + 1.000000e+00f) * 7.000000e+00f) * 5.000000e-01f)))))))) + (((((((-1 <= ((int32_t)floorf((((grid[(((((n_c_fused >> 2) * 512) + (h * 16)) + w_inner) + 256)] + 1.000000e+00f) * 7.000000e+00f) * 5.000000e-01f)))) && (-1 <= ((int32_t)floorf((((grid[((((n_c_fused >> 2) * 512) + (h * 16)) + w_inner)] + 1.000000e+00f) * 7.000000e+00f) * 5.000000e-01f))))) && (((int32_t)floorf((((grid[(((((n_c_fused >> 2) * 512) + (h * 16)) + w_inner) + 256)] + 1.000000e+00f) * 7.000000e+00f) * 5.000000e-01f))) < 7)) && (((int32_t)floorf((((grid[((((n_c_fused >> 2) * 512) + (h * 16)) + w_inner)] + 1.000000e+00f) * 7.000000e+00f) * 5.000000e-01f))) < 7)) ? data[((((n_c_fused * 64) + (((int32_t)floorf((((grid[(((((n_c_fused >> 2) * 512) + (h * 16)) + w_inner) + 256)] + 1.000000e+00f) * 7.000000e+00f) * 5.000000e-01f))) * 8)) + ((int32_t)floorf((((grid[((((n_c_fused >> 2) * 512) + (h * 16)) + w_inner)] + 1.000000e+00f) * 7.000000e+00f) * 5.000000e-01f)))) + 9)] : 0.000000e+00f) * ((((grid[(((((n_c_fused >> 2) * 512) + (h * 16)) + w_inner) + 256)] + 1.000000e+00f) * 7.000000e+00f) * 5.000000e-01f) - ((float)((int32_t)floorf((((grid[(((((n_c_fused >> 2) * 512) + (h * 16)) + w_inner) + 256)] + 1.000000e+00f) * 7.000000e+00f) * 5.000000e-01f)))))) * ((((grid[((((n_c_fused >> 2) * 512) + (h * 16)) + w_inner)] + 1.000000e+00f) * 7.000000e+00f) * 5.000000e-01f) - ((float)((int32_t)floorf((((grid[((((n_c_fused >> 2) * 512) + (h * 16)) + w_inner)] + 1.000000e+00f) * 7.000000e+00f) * 5.000000e-01f)))))));\n      }\n    }\n  }\n}\n\n",
        "cuda_code": "extern \"C\" __global__ void __launch_bounds__(1024) default_function_kernel(float* __restrict__ compute, float* __restrict__ data, float* __restrict__ grid) {\n  compute[((((int)blockIdx.x) * 1024) + ((int)threadIdx.x))] = ((((((((((0 <= ((int)floorf((((grid[(((((int)blockIdx.x) * 512) + (((int)threadIdx.x) & 255)) + 256)] + 1.000000e+00f) * 7.000000e+00f) * 5.000000e-01f)))) && (0 <= ((int)floorf((((grid[((((int)blockIdx.x) * 512) + (((int)threadIdx.x) & 255))] + 1.000000e+00f) * 7.000000e+00f) * 5.000000e-01f))))) && (((int)floorf((((grid[(((((int)blockIdx.x) * 512) + (((int)threadIdx.x) & 255)) + 256)] + 1.000000e+00f) * 7.000000e+00f) * 5.000000e-01f))) < 8)) && (((int)floorf((((grid[((((int)blockIdx.x) * 512) + (((int)threadIdx.x) & 255))] + 1.000000e+00f) * 7.000000e+00f) * 5.000000e-01f))) < 8)) ? data[((((((int)blockIdx.x) * 256) + ((((int)threadIdx.x) >> 8) * 64)) + (((int)floorf((((grid[(((((int)blockIdx.x) * 512) + (((int)threadIdx.x) & 255)) + 256)] + 1.000000e+00f) * 7.000000e+00f) * 5.000000e-01f))) * 8)) + ((int)floorf((((grid[((((int)blockIdx.x) * 512) + (((int)threadIdx.x) & 255))] + 1.000000e+00f) * 7.000000e+00f) * 5.000000e-01f))))] : 0.000000e+00f) * (1.000000e+00f - ((((grid[(((((int)blockIdx.x) * 512) + (((int)threadIdx.x) & 255)) + 256)] + 1.000000e+00f) * 7.000000e+00f) * 5.000000e-01f) - ((float)((int)floorf((((grid[(((((int)blockIdx.x) * 512) + (((int)threadIdx.x) & 255)) + 256)] + 1.000000e+00f) * 7.000000e+00f) * 5.000000e-01f))))))) * (1.000000e+00f - ((((grid[((((int)blockIdx.x) * 512) + (((int)threadIdx.x) & 255))] + 1.000000e+00f) * 7.000000e+00f) * 5.000000e-01f) - ((float)((int)floorf((((grid[((((int)blockIdx.x) * 512) + (((int)threadIdx.x) & 255))] + 1.000000e+00f) * 7.000000e+00f) * 5.000000e-01f))))))) + (((((((0 <= ((int)floorf((((grid[(((((int)blockIdx.x) * 512) + (((int)threadIdx.x) & 255)) + 256)] + 1.000000e+00f) * 7.000000e+00f) * 5.000000e-01f)))) && (-1 <= ((int)floorf((((grid[((((int)blockIdx.x) * 512) + (((int)threadIdx.x) & 255))] + 1.000000e+00f) * 7.000000e+00f) * 5.000000e-01f))))) && (((int)floorf((((grid[(((((int)blockIdx.x) * 512) + (((int)threadIdx.x) & 255)) + 256)] + 1.000000e+00f) * 7.000000e+00f) * 5.000000e-01f))) < 8)) && (((int)floorf((((grid[((((int)blockIdx.x) * 512) + (((int)threadIdx.x) & 255))] + 1.000000e+00f) * 7.000000e+00f) * 5.000000e-01f))) < 7)) ? data[(((((((int)blockIdx.x) * 256) + ((((int)threadIdx.x) >> 8) * 64)) + (((int)floorf((((grid[(((((int)blockIdx.x) * 512) + (((int)threadIdx.x) & 255)) + 256)] + 1.000000e+00f) * 7.000000e+00f) * 5.000000e-01f))) * 8)) + ((int)floorf((((grid[((((int)blockIdx.x) * 512) + (((int)threadIdx.x) & 255))] + 1.000000e+00f) * 7.000000e+00f) * 5.000000e-01f)))) + 1)] : 0.000000e+00f) * (1.000000e+00f - ((((grid[(((((int)blockIdx.x) * 512) + (((int)threadIdx.x) & 255)) + 256)] + 1.000000e+00f) * 7.000000e+00f) * 5.000000e-01f) - ((float)((int)floorf((((grid[(((((int)blockIdx.x) * 512) + (((int)threadIdx.x) & 255)) + 256)] + 1.000000e+00f) * 7.000000e+00f) * 5.000000e-01f))))))) * ((((grid[((((int)blockIdx.x) * 512) + (((int)threadIdx.x) & 255))] + 1.000000e+00f) * 7.000000e+00f) * 5.000000e-01f) - ((float)((int)floorf((((grid[((((int)blockIdx.x) * 512) + (((int)threadIdx.x) & 255))] + 1.000000e+00f) * 7.000000e+00f) * 5.000000e-01f))))))) + (((((((-1 <= ((int)floorf((((grid[(((((int)blockIdx.x) * 512) + (((int)threadIdx.x) & 255)) + 256)] + 1.000000e+00f) * 7.000000e+00f) * 5.000000e-01f)))) && (0 <= ((int)floorf((((grid[((((int)blockIdx.x) * 512) + (((int)threadIdx.x) & 255))] + 1.000000e+00f) * 7.000000e+00f) * 5.000000e-01f))))) && (((int)floorf((((grid[(((((int)blockIdx.x) * 512) + (((int)threadIdx.x) & 255)) + 256)] + 1.000000e+00f) * 7.000000e+00f) * 5.000000e-01f))) < 7)) && (((int)floorf((((grid[((((int)blockIdx.x) * 512) + (((int)threadIdx.x) & 255))] + 1.000000e+00f) * 7.000000e+00f) * 5.000000e-01f))) < 8)) ? data[(((((((int)blockIdx.x) * 256) + ((((int)threadIdx.x) >> 8) * 64)) + (((int)floorf((((grid[(((((int)blockIdx.x) * 512) + (((int)threadIdx.x) & 255)) + 256)] + 1.000000e+00f) * 7.000000e+00f) * 5.000000e-01f))) * 8)) + ((int)floorf((((grid[((((int)blockIdx.x) * 512) + (((int)threadIdx.x) & 255))] + 1.000000e+00f) * 7.000000e+00f) * 5.000000e-01f)))) + 8)] : 0.000000e+00f) * ((((grid[(((((int)blockIdx.x) * 512) + (((int)threadIdx.x) & 255)) + 256)] + 1.000000e+00f) * 7.000000e+00f) * 5.000000e-01f) - ((float)((int)floorf((((grid[(((((int)blockIdx.x) * 512) + (((int)threadIdx.x) & 255)) + 256)] + 1.000000e+00f) * 7.000000e+00f) * 5.000000e-01f)))))) * (1.000000e+00f - ((((grid[((((int)blockIdx.x) * 512) + (((int)threadIdx.x) & 255))] + 1.000000e+00f) * 7.000000e+00f) * 5.000000e-01f) - ((float)((int)floorf((((grid[((((int)blockIdx.x) * 512) + (((int)threadIdx.x) & 255))] + 1.000000e+00f) * 7.000000e+00f) * 5.000000e-01f)))))))) + (((((((-1 <= ((int)floorf((((grid[(((((int)blockIdx.x) * 512) + (((int)threadIdx.x) & 255)) + 256)] + 1.000000e+00f) * 7.000000e+00f) * 5.000000e-01f)))) && (-1 <= ((int)floorf((((grid[((((int)blockIdx.x) * 512) + (((int)threadIdx.x) & 255))] + 1.000000e+00f) * 7.000000e+00f) * 5.000000e-01f))))) && (((int)floorf((((grid[(((((int)blockIdx.x) * 512) + (((int)threadIdx.x) & 255)) + 256)] + 1.000000e+00f) * 7.000000e+00f) * 5.000000e-01f))) < 7)) && (((int)floorf((((grid[((((int)blockIdx.x) * 512) + (((int)threadIdx.x) & 255))] + 1.000000e+00f) * 7.000000e+00f) * 5.000000e-01f))) < 7)) ? data[(((((((int)blockIdx.x) * 256) + ((((int)threadIdx.x) >> 8) * 64)) + (((int)floorf((((grid[(((((int)blockIdx.x) * 512) + (((int)threadIdx.x) & 255)) + 256)] + 1.000000e+00f) * 7.000000e+00f) * 5.000000e-01f))) * 8)) + ((int)floorf((((grid[((((int)blockIdx.x) * 512) + (((int)threadIdx.x) & 255))] + 1.000000e+00f) * 7.000000e+00f) * 5.000000e-01f)))) + 9)] : 0.000000e+00f) * ((((grid[(((((int)blockIdx.x) * 512) + (((int)threadIdx.x) & 255)) + 256)] + 1.000000e+00f) * 7.000000e+00f) * 5.000000e-01f) - ((float)((int)floorf((((grid[(((((int)blockIdx.x) * 512) + (((int)threadIdx.x) & 255)) + 256)] + 1.000000e+00f) * 7.000000e+00f) * 5.000000e-01f)))))) * ((((grid[((((int)blockIdx.x) * 512) + (((int)threadIdx.x) & 255))] + 1.000000e+00f) * 7.000000e+00f) * 5.000000e-01f) - ((float)((int)floorf((((grid[((((int)blockIdx.x) * 512) + (((int)threadIdx.x) & 255))] + 1.000000e+00f) * 7.000000e+00f) * 5.000000e-01f)))))));\n}\n\n",
        "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((4, 4, 8, 8), \"float32\"), grid: T.Buffer((4, 2, 16, 16), \"float32\"), compute: T.Buffer((4, 4, 16, 16), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for n_c_fused in T.parallel(16):\n            for h, w_inner in T.grid(16, 16):\n                cse_var_4: T.int32 = h * 16\n                cse_var_3: T.int32 = n_c_fused * 64\n                cse_var_2: T.int32 = n_c_fused // 4 * 512 + cse_var_4 + w_inner\n                cse_var_1: T.int32 = cse_var_2 + 256\n                compute_1 = T.Buffer((4096,), data=compute.data)\n                grid_1 = T.Buffer((2048,), data=grid.data)\n                data_1 = T.Buffer((1024,), data=data.data)\n                compute_1[n_c_fused * 256 + cse_var_4 + w_inner] = T.if_then_else(0 <= T.Cast(\"int32\", T.floor((grid_1[cse_var_1] + T.float32(1)) * T.float32(7) * T.float32(0.5))) and 0 <= T.Cast(\"int32\", T.floor((grid_1[cse_var_2] + T.float32(1)) * T.float32(7) * T.float32(0.5))) and T.Cast(\"int32\", T.floor((grid_1[cse_var_1] + T.float32(1)) * T.float32(7) * T.float32(0.5))) < 8 and T.Cast(\"int32\", T.floor((grid_1[cse_var_2] + T.float32(1)) * T.float32(7) * T.float32(0.5))) < 8, data_1[cse_var_3 + T.Cast(\"int32\", T.floor((grid_1[cse_var_1] + T.float32(1)) * T.float32(7) * T.float32(0.5))) * 8 + T.Cast(\"int32\", T.floor((grid_1[cse_var_2] + T.float32(1)) * T.float32(7) * T.float32(0.5)))], T.float32(0)) * (T.float32(1) - ((grid_1[cse_var_1] + T.float32(1)) * T.float32(7) * T.float32(0.5) - T.Cast(\"float32\", T.Cast(\"int32\", T.floor((grid_1[cse_var_1] + T.float32(1)) * T.float32(7) * T.float32(0.5)))))) * (T.float32(1) - ((grid_1[cse_var_2] + T.float32(1)) * T.float32(7) * T.float32(0.5) - T.Cast(\"float32\", T.Cast(\"int32\", T.floor((grid_1[cse_var_2] + T.float32(1)) * T.float32(7) * T.float32(0.5)))))) + T.if_then_else(0 <= T.Cast(\"int32\", T.floor((grid_1[cse_var_1] + T.float32(1)) * T.float32(7) * T.float32(0.5))) and -1 <= T.Cast(\"int32\", T.floor((grid_1[cse_var_2] + T.float32(1)) * T.float32(7) * T.float32(0.5))) and T.Cast(\"int32\", T.floor((grid_1[cse_var_1] + T.float32(1)) * T.float32(7) * T.float32(0.5))) < 8 and T.Cast(\"int32\", T.floor((grid_1[cse_var_2] + T.float32(1)) * T.float32(7) * T.float32(0.5))) < 7, data_1[cse_var_3 + T.Cast(\"int32\", T.floor((grid_1[cse_var_1] + T.float32(1)) * T.float32(7) * T.float32(0.5))) * 8 + T.Cast(\"int32\", T.floor((grid_1[cse_var_2] + T.float32(1)) * T.float32(7) * T.float32(0.5))) + 1], T.float32(0)) * (T.float32(1) - ((grid_1[cse_var_1] + T.float32(1)) * T.float32(7) * T.float32(0.5) - T.Cast(\"float32\", T.Cast(\"int32\", T.floor((grid_1[cse_var_1] + T.float32(1)) * T.float32(7) * T.float32(0.5)))))) * ((grid_1[cse_var_2] + T.float32(1)) * T.float32(7) * T.float32(0.5) - T.Cast(\"float32\", T.Cast(\"int32\", T.floor((grid_1[cse_var_2] + T.float32(1)) * T.float32(7) * T.float32(0.5))))) + T.if_then_else(-1 <= T.Cast(\"int32\", T.floor((grid_1[cse_var_1] + T.float32(1)) * T.float32(7) * T.float32(0.5))) and 0 <= T.Cast(\"int32\", T.floor((grid_1[cse_var_2] + T.float32(1)) * T.float32(7) * T.float32(0.5))) and T.Cast(\"int32\", T.floor((grid_1[cse_var_1] + T.float32(1)) * T.float32(7) * T.float32(0.5))) < 7 and T.Cast(\"int32\", T.floor((grid_1[cse_var_2] + T.float32(1)) * T.float32(7) * T.float32(0.5))) < 8, data_1[cse_var_3 + T.Cast(\"int32\", T.floor((grid_1[cse_var_1] + T.float32(1)) * T.float32(7) * T.float32(0.5))) * 8 + T.Cast(\"int32\", T.floor((grid_1[cse_var_2] + T.float32(1)) * T.float32(7) * T.float32(0.5))) + 8], T.float32(0)) * ((grid_1[cse_var_1] + T.float32(1)) * T.float32(7) * T.float32(0.5) - T.Cast(\"float32\", T.Cast(\"int32\", T.floor((grid_1[cse_var_1] + T.float32(1)) * T.float32(7) * T.float32(0.5))))) * (T.float32(1) - ((grid_1[cse_var_2] + T.float32(1)) * T.float32(7) * T.float32(0.5) - T.Cast(\"float32\", T.Cast(\"int32\", T.floor((grid_1[cse_var_2] + T.float32(1)) * T.float32(7) * T.float32(0.5)))))) + T.if_then_else(-1 <= T.Cast(\"int32\", T.floor((grid_1[cse_var_1] + T.float32(1)) * T.float32(7) * T.float32(0.5))) and -1 <= T.Cast(\"int32\", T.floor((grid_1[cse_var_2] + T.float32(1)) * T.float32(7) * T.float32(0.5))) and T.Cast(\"int32\", T.floor((grid_1[cse_var_1] + T.float32(1)) * T.float32(7) * T.float32(0.5))) < 7 and T.Cast(\"int32\", T.floor((grid_1[cse_var_2] + T.float32(1)) * T.float32(7) * T.float32(0.5))) < 7, data_1[cse_var_3 + T.Cast(\"int32\", T.floor((grid_1[cse_var_1] + T.float32(1)) * T.float32(7) * T.float32(0.5))) * 8 + T.Cast(\"int32\", T.floor((grid_1[cse_var_2] + T.float32(1)) * T.float32(7) * T.float32(0.5))) + 9], T.float32(0)) * ((grid_1[cse_var_1] + T.float32(1)) * T.float32(7) * T.float32(0.5) - T.Cast(\"float32\", T.Cast(\"int32\", T.floor((grid_1[cse_var_1] + T.float32(1)) * T.float32(7) * T.float32(0.5))))) * ((grid_1[cse_var_2] + T.float32(1)) * T.float32(7) * T.float32(0.5) - T.Cast(\"float32\", T.Cast(\"int32\", T.floor((grid_1[cse_var_2] + T.float32(1)) * T.float32(7) * T.float32(0.5)))))",
        "op_args": "None",
        "input_shape": [
            [
                4,
                4,
                8,
                8
            ],
            [
                4,
                2,
                16,
                16
            ]
        ],
        "output_shape": [
            [
                4,
                4,
                16,
                16
            ]
        ],
        "input_name": [
            "data",
            "grid"
        ],
        "output_name": [
            "compute"
        ]
    },
    {
        "op_name": "argsort",
        "c_code": "void default_function_kernel(float* data, int32_t* extern_1) {\n  float temp_data[1];\n  int32_t temp_index[1];\n  #pragma omp parallel for\n  for (int32_t i = 0; i < 64; ++i) {\n    for (int32_t j = 0; j < 256; ++j) {\n      extern_1[((i * 512) + (j * 2))] = (j * 2);\n    }\n    for (int32_t k = 0; k < 256; ++k) {\n      extern_1[(((i * 512) + (k * 2)) + 1)] = ((k * 2) + 1);\n    }\n    for (int32_t i_0 = 0; i_0 < 512; ++i_0) {\n      for (int32_t i_1 = 0; i_1 < 256; ++i_1) {\n        if (((((i * 512) + (i_1 * 2)) + (i_0 & 1)) < 511) && (data[(((i * 512) + (i_1 * 2)) + (i_0 & 1))] < data[((((i * 512) + (i_1 * 2)) + (i_0 & 1)) + 1)])) {\n          temp_data[0] = data[(((i * 512) + (i_1 * 2)) + (i_0 & 1))];\n          data[(((i * 512) + (i_1 * 2)) + (i_0 & 1))] = data[((((i * 512) + (i_1 * 2)) + (i_0 & 1)) + 1)];\n          data[((((i * 512) + (i_1 * 2)) + (i_0 & 1)) + 1)] = temp_data[0];\n          temp_index[0] = extern_1[(((i * 512) + (i_1 * 2)) + (i_0 & 1))];\n          extern_1[(((i * 512) + (i_1 * 2)) + (i_0 & 1))] = extern_1[((((i * 512) + (i_1 * 2)) + (i_0 & 1)) + 1)];\n          extern_1[((((i * 512) + (i_1 * 2)) + (i_0 & 1)) + 1)] = temp_index[0];\n        }\n      }\n    }\n  }\n}\n\n",
        "cuda_code": "extern \"C\" __global__ void default_function_kernel_2(float* __restrict__ argsort_gpu, float* __restrict__ argsort_gpu_v0, float* __restrict__ argsort_gpu_v2, float* __restrict__ argsort_gpu_v3, int64_t cse_var_1, int64_t i_0) {\n  int64_t first[1];\n  int64_t last[1];\n  int64_t first_1[1];\n  int64_t last_1[1];\n  if ((((int64_t)2 << cse_var_1) * ((int64_t)((int)blockIdx.z))) < (int64_t)512) {\n    if (i_0 == (int64_t)0) {\n      first[0] = max((int64_t)0, ((((((int64_t)2 << cse_var_1) >> (int64_t)1) + (((int64_t)2 << cse_var_1) * ((int64_t)((int)blockIdx.z)))) + (((int64_t)((int)threadIdx.x)) * (((((((int64_t)((int)((int64_t)2 << cse_var_1))) >= (int64_t)0) && (((((int64_t)2 << cse_var_1) - (int64_t)1) % ((int64_t)((int)((int64_t)2 << cse_var_1)))) >= (int64_t)0)) || ((((int64_t)((int)((int64_t)2 << cse_var_1))) < (int64_t)0) && (((((int64_t)2 << cse_var_1) - (int64_t)1) % ((int64_t)((int)((int64_t)2 << cse_var_1)))) <= (int64_t)0))) ? ((((int64_t)2 << cse_var_1) - (int64_t)1) / ((int64_t)((int)((int64_t)2 << cse_var_1)))) : (((((int64_t)2 << cse_var_1) - (int64_t)1) / ((int64_t)((int)((int64_t)2 << cse_var_1)))) - (int64_t)1)) + (int64_t)1))) - (((int64_t)2 << cse_var_1) * (((int64_t)((int)blockIdx.z)) + (int64_t)1))));\n      last[0] = min((((int64_t)((int)threadIdx.x)) * (((((((int64_t)((int)((int64_t)2 << cse_var_1))) >= (int64_t)0) && (((((int64_t)2 << cse_var_1) - (int64_t)1) % ((int64_t)((int)((int64_t)2 << cse_var_1)))) >= (int64_t)0)) || ((((int64_t)((int)((int64_t)2 << cse_var_1))) < (int64_t)0) && (((((int64_t)2 << cse_var_1) - (int64_t)1) % ((int64_t)((int)((int64_t)2 << cse_var_1)))) <= (int64_t)0))) ? ((((int64_t)2 << cse_var_1) - (int64_t)1) / ((int64_t)((int)((int64_t)2 << cse_var_1)))) : (((((int64_t)2 << cse_var_1) - (int64_t)1) / ((int64_t)((int)((int64_t)2 << cse_var_1)))) - (int64_t)1)) + (int64_t)1)), (((int64_t)2 << cse_var_1) >> (int64_t)1));\n      while ((first[0] < last[0])) {\n        if (argsort_gpu_v0[(((((int64_t)((int)blockIdx.y)) * (int64_t)512) + (((int64_t)2 << cse_var_1) * ((int64_t)((int)blockIdx.z)))) + ((first[0] + last[0]) >> (int64_t)1))] <= argsort_gpu_v0[((((((((int64_t)((int)blockIdx.y)) * (int64_t)512) + (((int64_t)2 << cse_var_1) >> (int64_t)1)) + (((int64_t)2 << cse_var_1) * ((int64_t)((int)blockIdx.z)))) + (((int64_t)((int)threadIdx.x)) * (((((((int64_t)((int)((int64_t)2 << cse_var_1))) >= (int64_t)0) && (((((int64_t)2 << cse_var_1) - (int64_t)1) % ((int64_t)((int)((int64_t)2 << cse_var_1)))) >= (int64_t)0)) || ((((int64_t)((int)((int64_t)2 << cse_var_1))) < (int64_t)0) && (((((int64_t)2 << cse_var_1) - (int64_t)1) % ((int64_t)((int)((int64_t)2 << cse_var_1)))) <= (int64_t)0))) ? ((((int64_t)2 << cse_var_1) - (int64_t)1) / ((int64_t)((int)((int64_t)2 << cse_var_1)))) : (((((int64_t)2 << cse_var_1) - (int64_t)1) / ((int64_t)((int)((int64_t)2 << cse_var_1)))) - (int64_t)1)) + (int64_t)1))) - ((first[0] + last[0]) >> (int64_t)1)) - (int64_t)1)]) {\n          first[0] = (((first[0] + last[0]) >> (int64_t)1) + (int64_t)1);\n        } else {\n          last[0] = ((first[0] + last[0]) >> (int64_t)1);\n        }\n      }\n      first[0] = ((((int64_t)2 << cse_var_1) * ((int64_t)((int)blockIdx.z))) + first[0]);\n      last[0] = ((((((int64_t)2 << cse_var_1) >> (int64_t)1) + (((int64_t)2 << cse_var_1) * ((int64_t)((int)blockIdx.z)))) + (((int64_t)((int)threadIdx.x)) * (((((((int64_t)((int)((int64_t)2 << cse_var_1))) >= (int64_t)0) && (((((int64_t)2 << cse_var_1) - (int64_t)1) % ((int64_t)((int)((int64_t)2 << cse_var_1)))) >= (int64_t)0)) || ((((int64_t)((int)((int64_t)2 << cse_var_1))) < (int64_t)0) && (((((int64_t)2 << cse_var_1) - (int64_t)1) % ((int64_t)((int)((int64_t)2 << cse_var_1)))) <= (int64_t)0))) ? ((((int64_t)2 << cse_var_1) - (int64_t)1) / ((int64_t)((int)((int64_t)2 << cse_var_1)))) : (((((int64_t)2 << cse_var_1) - (int64_t)1) / ((int64_t)((int)((int64_t)2 << cse_var_1)))) - (int64_t)1)) + (int64_t)1))) - last[0]);\n      for (int i_1 = 0; i_1 < ((int)min((((int64_t)2 << cse_var_1) - (((int64_t)((int)threadIdx.x)) * (((((((int64_t)((int)((int64_t)2 << cse_var_1))) >= (int64_t)0) && (((((int64_t)2 << cse_var_1) - (int64_t)1) % ((int64_t)((int)((int64_t)2 << cse_var_1)))) >= (int64_t)0)) || ((((int64_t)((int)((int64_t)2 << cse_var_1))) < (int64_t)0) && (((((int64_t)2 << cse_var_1) - (int64_t)1) % ((int64_t)((int)((int64_t)2 << cse_var_1)))) <= (int64_t)0))) ? ((((int64_t)2 << cse_var_1) - (int64_t)1) / ((int64_t)((int)((int64_t)2 << cse_var_1)))) : (((((int64_t)2 << cse_var_1) - (int64_t)1) / ((int64_t)((int)((int64_t)2 << cse_var_1)))) - (int64_t)1)) + (int64_t)1))), (((((((int64_t)((int)((int64_t)2 << cse_var_1))) >= (int64_t)0) && (((((int64_t)2 << cse_var_1) - (int64_t)1) % ((int64_t)((int)((int64_t)2 << cse_var_1)))) >= (int64_t)0)) || ((((int64_t)((int)((int64_t)2 << cse_var_1))) < (int64_t)0) && (((((int64_t)2 << cse_var_1) - (int64_t)1) % ((int64_t)((int)((int64_t)2 << cse_var_1)))) <= (int64_t)0))) ? ((((int64_t)2 << cse_var_1) - (int64_t)1) / ((int64_t)((int)((int64_t)2 << cse_var_1)))) : (((((int64_t)2 << cse_var_1) - (int64_t)1) / ((int64_t)((int)((int64_t)2 << cse_var_1)))) - (int64_t)1)) + (int64_t)1))); ++i_1) {\n        if ((((first[0] < ((((int64_t)2 << cse_var_1) >> (int64_t)1) + (((int64_t)2 << cse_var_1) * ((int64_t)((int)blockIdx.z))))) && (first[0] < (int64_t)512)) && (last[0] < (((int64_t)2 << cse_var_1) * (((int64_t)((int)blockIdx.z)) + (int64_t)1)))) && (last[0] < (int64_t)512)) {\n          if (argsort_gpu_v0[((((int64_t)((int)blockIdx.y)) * (int64_t)512) + first[0])] <= argsort_gpu_v0[((((int64_t)((int)blockIdx.y)) * (int64_t)512) + last[0])]) {\n            argsort_gpu_v2[((((((int64_t)((int)blockIdx.y)) * (int64_t)512) + (((int64_t)2 << cse_var_1) * ((int64_t)((int)blockIdx.z)))) + (((int64_t)((int)threadIdx.x)) * (((((((int64_t)((int)((int64_t)2 << cse_var_1))) >= (int64_t)0) && (((((int64_t)2 << cse_var_1) - (int64_t)1) % ((int64_t)((int)((int64_t)2 << cse_var_1)))) >= (int64_t)0)) || ((((int64_t)((int)((int64_t)2 << cse_var_1))) < (int64_t)0) && (((((int64_t)2 << cse_var_1) - (int64_t)1) % ((int64_t)((int)((int64_t)2 << cse_var_1)))) <= (int64_t)0))) ? ((((int64_t)2 << cse_var_1) - (int64_t)1) / ((int64_t)((int)((int64_t)2 << cse_var_1)))) : (((((int64_t)2 << cse_var_1) - (int64_t)1) / ((int64_t)((int)((int64_t)2 << cse_var_1)))) - (int64_t)1)) + (int64_t)1))) + ((int64_t)i_1))] = argsort_gpu_v0[((((int64_t)((int)blockIdx.y)) * (int64_t)512) + first[0])];\n            argsort_gpu_v3[((((((int64_t)((int)blockIdx.y)) * (int64_t)512) + (((int64_t)2 << cse_var_1) * ((int64_t)((int)blockIdx.z)))) + (((int64_t)((int)threadIdx.x)) * (((((((int64_t)((int)((int64_t)2 << cse_var_1))) >= (int64_t)0) && (((((int64_t)2 << cse_var_1) - (int64_t)1) % ((int64_t)((int)((int64_t)2 << cse_var_1)))) >= (int64_t)0)) || ((((int64_t)((int)((int64_t)2 << cse_var_1))) < (int64_t)0) && (((((int64_t)2 << cse_var_1) - (int64_t)1) % ((int64_t)((int)((int64_t)2 << cse_var_1)))) <= (int64_t)0))) ? ((((int64_t)2 << cse_var_1) - (int64_t)1) / ((int64_t)((int)((int64_t)2 << cse_var_1)))) : (((((int64_t)2 << cse_var_1) - (int64_t)1) / ((int64_t)((int)((int64_t)2 << cse_var_1)))) - (int64_t)1)) + (int64_t)1))) + ((int64_t)i_1))] = argsort_gpu[((((int64_t)((int)blockIdx.y)) * (int64_t)512) + first[0])];\n            first[0] = (first[0] + (int64_t)1);\n          } else {\n            argsort_gpu_v2[((((((int64_t)((int)blockIdx.y)) * (int64_t)512) + (((int64_t)2 << cse_var_1) * ((int64_t)((int)blockIdx.z)))) + (((int64_t)((int)threadIdx.x)) * (((((((int64_t)((int)((int64_t)2 << cse_var_1))) >= (int64_t)0) && (((((int64_t)2 << cse_var_1) - (int64_t)1) % ((int64_t)((int)((int64_t)2 << cse_var_1)))) >= (int64_t)0)) || ((((int64_t)((int)((int64_t)2 << cse_var_1))) < (int64_t)0) && (((((int64_t)2 << cse_var_1) - (int64_t)1) % ((int64_t)((int)((int64_t)2 << cse_var_1)))) <= (int64_t)0))) ? ((((int64_t)2 << cse_var_1) - (int64_t)1) / ((int64_t)((int)((int64_t)2 << cse_var_1)))) : (((((int64_t)2 << cse_var_1) - (int64_t)1) / ((int64_t)((int)((int64_t)2 << cse_var_1)))) - (int64_t)1)) + (int64_t)1))) + ((int64_t)i_1))] = argsort_gpu_v0[((((int64_t)((int)blockIdx.y)) * (int64_t)512) + last[0])];\n            argsort_gpu_v3[((((((int64_t)((int)blockIdx.y)) * (int64_t)512) + (((int64_t)2 << cse_var_1) * ((int64_t)((int)blockIdx.z)))) + (((int64_t)((int)threadIdx.x)) * (((((((int64_t)((int)((int64_t)2 << cse_var_1))) >= (int64_t)0) && (((((int64_t)2 << cse_var_1) - (int64_t)1) % ((int64_t)((int)((int64_t)2 << cse_var_1)))) >= (int64_t)0)) || ((((int64_t)((int)((int64_t)2 << cse_var_1))) < (int64_t)0) && (((((int64_t)2 << cse_var_1) - (int64_t)1) % ((int64_t)((int)((int64_t)2 << cse_var_1)))) <= (int64_t)0))) ? ((((int64_t)2 << cse_var_1) - (int64_t)1) / ((int64_t)((int)((int64_t)2 << cse_var_1)))) : (((((int64_t)2 << cse_var_1) - (int64_t)1) / ((int64_t)((int)((int64_t)2 << cse_var_1)))) - (int64_t)1)) + (int64_t)1))) + ((int64_t)i_1))] = argsort_gpu[((((int64_t)((int)blockIdx.y)) * (int64_t)512) + last[0])];\n            last[0] = (last[0] + (int64_t)1);\n          }\n        } else {\n          if ((first[0] < ((((int64_t)2 << cse_var_1) >> (int64_t)1) + (((int64_t)2 << cse_var_1) * ((int64_t)((int)blockIdx.z))))) && (first[0] < (int64_t)512)) {\n            argsort_gpu_v2[((((((int64_t)((int)blockIdx.y)) * (int64_t)512) + (((int64_t)2 << cse_var_1) * ((int64_t)((int)blockIdx.z)))) + (((int64_t)((int)threadIdx.x)) * (((((((int64_t)((int)((int64_t)2 << cse_var_1))) >= (int64_t)0) && (((((int64_t)2 << cse_var_1) - (int64_t)1) % ((int64_t)((int)((int64_t)2 << cse_var_1)))) >= (int64_t)0)) || ((((int64_t)((int)((int64_t)2 << cse_var_1))) < (int64_t)0) && (((((int64_t)2 << cse_var_1) - (int64_t)1) % ((int64_t)((int)((int64_t)2 << cse_var_1)))) <= (int64_t)0))) ? ((((int64_t)2 << cse_var_1) - (int64_t)1) / ((int64_t)((int)((int64_t)2 << cse_var_1)))) : (((((int64_t)2 << cse_var_1) - (int64_t)1) / ((int64_t)((int)((int64_t)2 << cse_var_1)))) - (int64_t)1)) + (int64_t)1))) + ((int64_t)i_1))] = argsort_gpu_v0[((((int64_t)((int)blockIdx.y)) * (int64_t)512) + first[0])];\n            argsort_gpu_v3[((((((int64_t)((int)blockIdx.y)) * (int64_t)512) + (((int64_t)2 << cse_var_1) * ((int64_t)((int)blockIdx.z)))) + (((int64_t)((int)threadIdx.x)) * (((((((int64_t)((int)((int64_t)2 << cse_var_1))) >= (int64_t)0) && (((((int64_t)2 << cse_var_1) - (int64_t)1) % ((int64_t)((int)((int64_t)2 << cse_var_1)))) >= (int64_t)0)) || ((((int64_t)((int)((int64_t)2 << cse_var_1))) < (int64_t)0) && (((((int64_t)2 << cse_var_1) - (int64_t)1) % ((int64_t)((int)((int64_t)2 << cse_var_1)))) <= (int64_t)0))) ? ((((int64_t)2 << cse_var_1) - (int64_t)1) / ((int64_t)((int)((int64_t)2 << cse_var_1)))) : (((((int64_t)2 << cse_var_1) - (int64_t)1) / ((int64_t)((int)((int64_t)2 << cse_var_1)))) - (int64_t)1)) + (int64_t)1))) + ((int64_t)i_1))] = argsort_gpu[((((int64_t)((int)blockIdx.y)) * (int64_t)512) + first[0])];\n            first[0] = (first[0] + (int64_t)1);\n          } else {\n            argsort_gpu_v2[((((((int64_t)((int)blockIdx.y)) * (int64_t)512) + (((int64_t)2 << cse_var_1) * ((int64_t)((int)blockIdx.z)))) + (((int64_t)((int)threadIdx.x)) * (((((((int64_t)((int)((int64_t)2 << cse_var_1))) >= (int64_t)0) && (((((int64_t)2 << cse_var_1) - (int64_t)1) % ((int64_t)((int)((int64_t)2 << cse_var_1)))) >= (int64_t)0)) || ((((int64_t)((int)((int64_t)2 << cse_var_1))) < (int64_t)0) && (((((int64_t)2 << cse_var_1) - (int64_t)1) % ((int64_t)((int)((int64_t)2 << cse_var_1)))) <= (int64_t)0))) ? ((((int64_t)2 << cse_var_1) - (int64_t)1) / ((int64_t)((int)((int64_t)2 << cse_var_1)))) : (((((int64_t)2 << cse_var_1) - (int64_t)1) / ((int64_t)((int)((int64_t)2 << cse_var_1)))) - (int64_t)1)) + (int64_t)1))) + ((int64_t)i_1))] = argsort_gpu_v0[((((int64_t)((int)blockIdx.y)) * (int64_t)512) + last[0])];\n            argsort_gpu_v3[((((((int64_t)((int)blockIdx.y)) * (int64_t)512) + (((int64_t)2 << cse_var_1) * ((int64_t)((int)blockIdx.z)))) + (((int64_t)((int)threadIdx.x)) * (((((((int64_t)((int)((int64_t)2 << cse_var_1))) >= (int64_t)0) && (((((int64_t)2 << cse_var_1) - (int64_t)1) % ((int64_t)((int)((int64_t)2 << cse_var_1)))) >= (int64_t)0)) || ((((int64_t)((int)((int64_t)2 << cse_var_1))) < (int64_t)0) && (((((int64_t)2 << cse_var_1) - (int64_t)1) % ((int64_t)((int)((int64_t)2 << cse_var_1)))) <= (int64_t)0))) ? ((((int64_t)2 << cse_var_1) - (int64_t)1) / ((int64_t)((int)((int64_t)2 << cse_var_1)))) : (((((int64_t)2 << cse_var_1) - (int64_t)1) / ((int64_t)((int)((int64_t)2 << cse_var_1)))) - (int64_t)1)) + (int64_t)1))) + ((int64_t)i_1))] = argsort_gpu[((((int64_t)((int)blockIdx.y)) * (int64_t)512) + last[0])];\n            last[0] = (last[0] + (int64_t)1);\n          }\n        }\n      }\n    } else {\n      first_1[0] = max((int64_t)0, ((min(((((int64_t)2 << cse_var_1) >> (int64_t)1) + (((int64_t)2 << cse_var_1) * ((int64_t)((int)blockIdx.z)))), (int64_t)512) + (((int64_t)((int)threadIdx.x)) * (((((((int64_t)((int)((int64_t)2 << cse_var_1))) >= (int64_t)0) && (((((int64_t)2 << cse_var_1) - (int64_t)1) % ((int64_t)((int)((int64_t)2 << cse_var_1)))) >= (int64_t)0)) || ((((int64_t)((int)((int64_t)2 << cse_var_1))) < (int64_t)0) && (((((int64_t)2 << cse_var_1) - (int64_t)1) % ((int64_t)((int)((int64_t)2 << cse_var_1)))) <= (int64_t)0))) ? ((((int64_t)2 << cse_var_1) - (int64_t)1) / ((int64_t)((int)((int64_t)2 << cse_var_1)))) : (((((int64_t)2 << cse_var_1) - (int64_t)1) / ((int64_t)((int)((int64_t)2 << cse_var_1)))) - (int64_t)1)) + (int64_t)1))) - (int64_t)512));\n      last_1[0] = min((((int64_t)((int)threadIdx.x)) * (((((((int64_t)((int)((int64_t)2 << cse_var_1))) >= (int64_t)0) && (((((int64_t)2 << cse_var_1) - (int64_t)1) % ((int64_t)((int)((int64_t)2 << cse_var_1)))) >= (int64_t)0)) || ((((int64_t)((int)((int64_t)2 << cse_var_1))) < (int64_t)0) && (((((int64_t)2 << cse_var_1) - (int64_t)1) % ((int64_t)((int)((int64_t)2 << cse_var_1)))) <= (int64_t)0))) ? ((((int64_t)2 << cse_var_1) - (int64_t)1) / ((int64_t)((int)((int64_t)2 << cse_var_1)))) : (((((int64_t)2 << cse_var_1) - (int64_t)1) / ((int64_t)((int)((int64_t)2 << cse_var_1)))) - (int64_t)1)) + (int64_t)1)), min((((int64_t)2 << cse_var_1) >> (int64_t)1), ((int64_t)512 - (((int64_t)2 << cse_var_1) * ((int64_t)((int)blockIdx.z))))));\n      while ((first_1[0] < last_1[0])) {\n        if (argsort_gpu_v2[(((((int64_t)((int)blockIdx.y)) * (int64_t)512) + (((int64_t)2 << cse_var_1) * ((int64_t)((int)blockIdx.z)))) + ((first_1[0] + last_1[0]) >> (int64_t)1))] <= argsort_gpu_v2[(((((((int64_t)((int)blockIdx.y)) * (int64_t)512) + min(((((int64_t)2 << cse_var_1) >> (int64_t)1) + (((int64_t)2 << cse_var_1) * ((int64_t)((int)blockIdx.z)))), (int64_t)512)) + (((int64_t)((int)threadIdx.x)) * (((((((int64_t)((int)((int64_t)2 << cse_var_1))) >= (int64_t)0) && (((((int64_t)2 << cse_var_1) - (int64_t)1) % ((int64_t)((int)((int64_t)2 << cse_var_1)))) >= (int64_t)0)) || ((((int64_t)((int)((int64_t)2 << cse_var_1))) < (int64_t)0) && (((((int64_t)2 << cse_var_1) - (int64_t)1) % ((int64_t)((int)((int64_t)2 << cse_var_1)))) <= (int64_t)0))) ? ((((int64_t)2 << cse_var_1) - (int64_t)1) / ((int64_t)((int)((int64_t)2 << cse_var_1)))) : (((((int64_t)2 << cse_var_1) - (int64_t)1) / ((int64_t)((int)((int64_t)2 << cse_var_1)))) - (int64_t)1)) + (int64_t)1))) - ((first_1[0] + last_1[0]) >> (int64_t)1)) - (int64_t)1)]) {\n          first_1[0] = (((first_1[0] + last_1[0]) >> (int64_t)1) + (int64_t)1);\n        } else {\n          last_1[0] = ((first_1[0] + last_1[0]) >> (int64_t)1);\n        }\n      }\n      first_1[0] = ((((int64_t)2 << cse_var_1) * ((int64_t)((int)blockIdx.z))) + first_1[0]);\n      last_1[0] = ((min(((((int64_t)2 << cse_var_1) >> (int64_t)1) + (((int64_t)2 << cse_var_1) * ((int64_t)((int)blockIdx.z)))), (int64_t)512) + (((int64_t)((int)threadIdx.x)) * (((((((int64_t)((int)((int64_t)2 << cse_var_1))) >= (int64_t)0) && (((((int64_t)2 << cse_var_1) - (int64_t)1) % ((int64_t)((int)((int64_t)2 << cse_var_1)))) >= (int64_t)0)) || ((((int64_t)((int)((int64_t)2 << cse_var_1))) < (int64_t)0) && (((((int64_t)2 << cse_var_1) - (int64_t)1) % ((int64_t)((int)((int64_t)2 << cse_var_1)))) <= (int64_t)0))) ? ((((int64_t)2 << cse_var_1) - (int64_t)1) / ((int64_t)((int)((int64_t)2 << cse_var_1)))) : (((((int64_t)2 << cse_var_1) - (int64_t)1) / ((int64_t)((int)((int64_t)2 << cse_var_1)))) - (int64_t)1)) + (int64_t)1))) - last_1[0]);\n      for (int i_2 = 0; i_2 < ((int)min((((int64_t)512 - (((int64_t)2 << cse_var_1) * ((int64_t)((int)blockIdx.z)))) - (((int64_t)((int)threadIdx.x)) * (((((((int64_t)((int)((int64_t)2 << cse_var_1))) >= (int64_t)0) && (((((int64_t)2 << cse_var_1) - (int64_t)1) % ((int64_t)((int)((int64_t)2 << cse_var_1)))) >= (int64_t)0)) || ((((int64_t)((int)((int64_t)2 << cse_var_1))) < (int64_t)0) && (((((int64_t)2 << cse_var_1) - (int64_t)1) % ((int64_t)((int)((int64_t)2 << cse_var_1)))) <= (int64_t)0))) ? ((((int64_t)2 << cse_var_1) - (int64_t)1) / ((int64_t)((int)((int64_t)2 << cse_var_1)))) : (((((int64_t)2 << cse_var_1) - (int64_t)1) / ((int64_t)((int)((int64_t)2 << cse_var_1)))) - (int64_t)1)) + (int64_t)1))), (((((((int64_t)((int)((int64_t)2 << cse_var_1))) >= (int64_t)0) && (((((int64_t)2 << cse_var_1) - (int64_t)1) % ((int64_t)((int)((int64_t)2 << cse_var_1)))) >= (int64_t)0)) || ((((int64_t)((int)((int64_t)2 << cse_var_1))) < (int64_t)0) && (((((int64_t)2 << cse_var_1) - (int64_t)1) % ((int64_t)((int)((int64_t)2 << cse_var_1)))) <= (int64_t)0))) ? ((((int64_t)2 << cse_var_1) - (int64_t)1) / ((int64_t)((int)((int64_t)2 << cse_var_1)))) : (((((int64_t)2 << cse_var_1) - (int64_t)1) / ((int64_t)((int)((int64_t)2 << cse_var_1)))) - (int64_t)1)) + (int64_t)1))); ++i_2) {\n        if (((first_1[0] < ((((int64_t)2 << cse_var_1) >> (int64_t)1) + (((int64_t)2 << cse_var_1) * ((int64_t)((int)blockIdx.z))))) && (first_1[0] < (int64_t)512)) && (last_1[0] < (int64_t)512)) {\n          if (argsort_gpu_v2[((((int64_t)((int)blockIdx.y)) * (int64_t)512) + first_1[0])] <= argsort_gpu_v2[((((int64_t)((int)blockIdx.y)) * (int64_t)512) + last_1[0])]) {\n            argsort_gpu_v0[((((((int64_t)((int)blockIdx.y)) * (int64_t)512) + (((int64_t)2 << cse_var_1) * ((int64_t)((int)blockIdx.z)))) + (((int64_t)((int)threadIdx.x)) * (((((((int64_t)((int)((int64_t)2 << cse_var_1))) >= (int64_t)0) && (((((int64_t)2 << cse_var_1) - (int64_t)1) % ((int64_t)((int)((int64_t)2 << cse_var_1)))) >= (int64_t)0)) || ((((int64_t)((int)((int64_t)2 << cse_var_1))) < (int64_t)0) && (((((int64_t)2 << cse_var_1) - (int64_t)1) % ((int64_t)((int)((int64_t)2 << cse_var_1)))) <= (int64_t)0))) ? ((((int64_t)2 << cse_var_1) - (int64_t)1) / ((int64_t)((int)((int64_t)2 << cse_var_1)))) : (((((int64_t)2 << cse_var_1) - (int64_t)1) / ((int64_t)((int)((int64_t)2 << cse_var_1)))) - (int64_t)1)) + (int64_t)1))) + ((int64_t)i_2))] = argsort_gpu_v2[((((int64_t)((int)blockIdx.y)) * (int64_t)512) + first_1[0])];\n            argsort_gpu[((((((int64_t)((int)blockIdx.y)) * (int64_t)512) + (((int64_t)2 << cse_var_1) * ((int64_t)((int)blockIdx.z)))) + (((int64_t)((int)threadIdx.x)) * (((((((int64_t)((int)((int64_t)2 << cse_var_1))) >= (int64_t)0) && (((((int64_t)2 << cse_var_1) - (int64_t)1) % ((int64_t)((int)((int64_t)2 << cse_var_1)))) >= (int64_t)0)) || ((((int64_t)((int)((int64_t)2 << cse_var_1))) < (int64_t)0) && (((((int64_t)2 << cse_var_1) - (int64_t)1) % ((int64_t)((int)((int64_t)2 << cse_var_1)))) <= (int64_t)0))) ? ((((int64_t)2 << cse_var_1) - (int64_t)1) / ((int64_t)((int)((int64_t)2 << cse_var_1)))) : (((((int64_t)2 << cse_var_1) - (int64_t)1) / ((int64_t)((int)((int64_t)2 << cse_var_1)))) - (int64_t)1)) + (int64_t)1))) + ((int64_t)i_2))] = argsort_gpu_v3[((((int64_t)((int)blockIdx.y)) * (int64_t)512) + first_1[0])];\n            first_1[0] = (first_1[0] + (int64_t)1);\n          } else {\n            argsort_gpu_v0[((((((int64_t)((int)blockIdx.y)) * (int64_t)512) + (((int64_t)2 << cse_var_1) * ((int64_t)((int)blockIdx.z)))) + (((int64_t)((int)threadIdx.x)) * (((((((int64_t)((int)((int64_t)2 << cse_var_1))) >= (int64_t)0) && (((((int64_t)2 << cse_var_1) - (int64_t)1) % ((int64_t)((int)((int64_t)2 << cse_var_1)))) >= (int64_t)0)) || ((((int64_t)((int)((int64_t)2 << cse_var_1))) < (int64_t)0) && (((((int64_t)2 << cse_var_1) - (int64_t)1) % ((int64_t)((int)((int64_t)2 << cse_var_1)))) <= (int64_t)0))) ? ((((int64_t)2 << cse_var_1) - (int64_t)1) / ((int64_t)((int)((int64_t)2 << cse_var_1)))) : (((((int64_t)2 << cse_var_1) - (int64_t)1) / ((int64_t)((int)((int64_t)2 << cse_var_1)))) - (int64_t)1)) + (int64_t)1))) + ((int64_t)i_2))] = argsort_gpu_v2[((((int64_t)((int)blockIdx.y)) * (int64_t)512) + last_1[0])];\n            argsort_gpu[((((((int64_t)((int)blockIdx.y)) * (int64_t)512) + (((int64_t)2 << cse_var_1) * ((int64_t)((int)blockIdx.z)))) + (((int64_t)((int)threadIdx.x)) * (((((((int64_t)((int)((int64_t)2 << cse_var_1))) >= (int64_t)0) && (((((int64_t)2 << cse_var_1) - (int64_t)1) % ((int64_t)((int)((int64_t)2 << cse_var_1)))) >= (int64_t)0)) || ((((int64_t)((int)((int64_t)2 << cse_var_1))) < (int64_t)0) && (((((int64_t)2 << cse_var_1) - (int64_t)1) % ((int64_t)((int)((int64_t)2 << cse_var_1)))) <= (int64_t)0))) ? ((((int64_t)2 << cse_var_1) - (int64_t)1) / ((int64_t)((int)((int64_t)2 << cse_var_1)))) : (((((int64_t)2 << cse_var_1) - (int64_t)1) / ((int64_t)((int)((int64_t)2 << cse_var_1)))) - (int64_t)1)) + (int64_t)1))) + ((int64_t)i_2))] = argsort_gpu_v3[((((int64_t)((int)blockIdx.y)) * (int64_t)512) + last_1[0])];\n            last_1[0] = (last_1[0] + (int64_t)1);\n          }\n        } else {\n          if ((first_1[0] < ((((int64_t)2 << cse_var_1) >> (int64_t)1) + (((int64_t)2 << cse_var_1) * ((int64_t)((int)blockIdx.z))))) && (first_1[0] < (int64_t)512)) {\n            argsort_gpu_v0[((((((int64_t)((int)blockIdx.y)) * (int64_t)512) + (((int64_t)2 << cse_var_1) * ((int64_t)((int)blockIdx.z)))) + (((int64_t)((int)threadIdx.x)) * (((((((int64_t)((int)((int64_t)2 << cse_var_1))) >= (int64_t)0) && (((((int64_t)2 << cse_var_1) - (int64_t)1) % ((int64_t)((int)((int64_t)2 << cse_var_1)))) >= (int64_t)0)) || ((((int64_t)((int)((int64_t)2 << cse_var_1))) < (int64_t)0) && (((((int64_t)2 << cse_var_1) - (int64_t)1) % ((int64_t)((int)((int64_t)2 << cse_var_1)))) <= (int64_t)0))) ? ((((int64_t)2 << cse_var_1) - (int64_t)1) / ((int64_t)((int)((int64_t)2 << cse_var_1)))) : (((((int64_t)2 << cse_var_1) - (int64_t)1) / ((int64_t)((int)((int64_t)2 << cse_var_1)))) - (int64_t)1)) + (int64_t)1))) + ((int64_t)i_2))] = argsort_gpu_v2[((((int64_t)((int)blockIdx.y)) * (int64_t)512) + first_1[0])];\n            argsort_gpu[((((((int64_t)((int)blockIdx.y)) * (int64_t)512) + (((int64_t)2 << cse_var_1) * ((int64_t)((int)blockIdx.z)))) + (((int64_t)((int)threadIdx.x)) * (((((((int64_t)((int)((int64_t)2 << cse_var_1))) >= (int64_t)0) && (((((int64_t)2 << cse_var_1) - (int64_t)1) % ((int64_t)((int)((int64_t)2 << cse_var_1)))) >= (int64_t)0)) || ((((int64_t)((int)((int64_t)2 << cse_var_1))) < (int64_t)0) && (((((int64_t)2 << cse_var_1) - (int64_t)1) % ((int64_t)((int)((int64_t)2 << cse_var_1)))) <= (int64_t)0))) ? ((((int64_t)2 << cse_var_1) - (int64_t)1) / ((int64_t)((int)((int64_t)2 << cse_var_1)))) : (((((int64_t)2 << cse_var_1) - (int64_t)1) / ((int64_t)((int)((int64_t)2 << cse_var_1)))) - (int64_t)1)) + (int64_t)1))) + ((int64_t)i_2))] = argsort_gpu_v3[((((int64_t)((int)blockIdx.y)) * (int64_t)512) + first_1[0])];\n            first_1[0] = (first_1[0] + (int64_t)1);\n          } else {\n            argsort_gpu_v0[((((((int64_t)((int)blockIdx.y)) * (int64_t)512) + (((int64_t)2 << cse_var_1) * ((int64_t)((int)blockIdx.z)))) + (((int64_t)((int)threadIdx.x)) * (((((((int64_t)((int)((int64_t)2 << cse_var_1))) >= (int64_t)0) && (((((int64_t)2 << cse_var_1) - (int64_t)1) % ((int64_t)((int)((int64_t)2 << cse_var_1)))) >= (int64_t)0)) || ((((int64_t)((int)((int64_t)2 << cse_var_1))) < (int64_t)0) && (((((int64_t)2 << cse_var_1) - (int64_t)1) % ((int64_t)((int)((int64_t)2 << cse_var_1)))) <= (int64_t)0))) ? ((((int64_t)2 << cse_var_1) - (int64_t)1) / ((int64_t)((int)((int64_t)2 << cse_var_1)))) : (((((int64_t)2 << cse_var_1) - (int64_t)1) / ((int64_t)((int)((int64_t)2 << cse_var_1)))) - (int64_t)1)) + (int64_t)1))) + ((int64_t)i_2))] = argsort_gpu_v2[((((int64_t)((int)blockIdx.y)) * (int64_t)512) + last_1[0])];\n            argsort_gpu[((((((int64_t)((int)blockIdx.y)) * (int64_t)512) + (((int64_t)2 << cse_var_1) * ((int64_t)((int)blockIdx.z)))) + (((int64_t)((int)threadIdx.x)) * (((((((int64_t)((int)((int64_t)2 << cse_var_1))) >= (int64_t)0) && (((((int64_t)2 << cse_var_1) - (int64_t)1) % ((int64_t)((int)((int64_t)2 << cse_var_1)))) >= (int64_t)0)) || ((((int64_t)((int)((int64_t)2 << cse_var_1))) < (int64_t)0) && (((((int64_t)2 << cse_var_1) - (int64_t)1) % ((int64_t)((int)((int64_t)2 << cse_var_1)))) <= (int64_t)0))) ? ((((int64_t)2 << cse_var_1) - (int64_t)1) / ((int64_t)((int)((int64_t)2 << cse_var_1)))) : (((((int64_t)2 << cse_var_1) - (int64_t)1) / ((int64_t)((int)((int64_t)2 << cse_var_1)))) - (int64_t)1)) + (int64_t)1))) + ((int64_t)i_2))] = argsort_gpu_v3[((((int64_t)((int)blockIdx.y)) * (int64_t)512) + last_1[0])];\n            last_1[0] = (last_1[0] + (int64_t)1);\n          }\n        }\n      }\n    }\n  }\n}\n\nextern \"C\" __global__ void __launch_bounds__(1024) default_function_kernel(float* __restrict__ argsort_gpu, float* __restrict__ argsort_gpu_v0, float* __restrict__ data) {\n  if (((int)threadIdx.x) < 512) {\n    argsort_gpu_v0[((((int)blockIdx.y) * 512) + ((int)threadIdx.x))] = data[((((int)blockIdx.y) * 512) + ((int)threadIdx.x))];\n    argsort_gpu[((((int)blockIdx.y) * 512) + ((int)threadIdx.x))] = ((float)((int)threadIdx.x));\n  }\n}\n\nextern \"C\" __global__ void __launch_bounds__(64) default_function_kernel_1(float* __restrict__ argsort_gpu, float* __restrict__ argsort_gpu_v0, float* __restrict__ argsort_gpu_v2, float* __restrict__ argsort_gpu_v3) {\n  __shared__ float temp_keys_swap[128];\n  __shared__ float temp_values_swap[128];\n  float temp_cond1[1];\n  float temp_cond2[1];\n  float temp_keys[1];\n  float temp_values[1];\n  for (int i = 0; i < 2; ++i) {\n    temp_keys_swap[((((int)threadIdx.x) * 2) + i)] = argsort_gpu_v0[((((((int)blockIdx.y) * 512) + (((int)blockIdx.x) * 128)) + (((int)threadIdx.x) * 2)) + i)];\n    temp_values_swap[((((int)threadIdx.x) * 2) + i)] = argsort_gpu[((((((int)blockIdx.y) * 512) + (((int)blockIdx.x) * 128)) + (((int)threadIdx.x) * 2)) + i)];\n  }\n  __syncthreads();\n  for (int j = 0; j < 128; ++j) {\n    if (((((int)threadIdx.x) * 2) + (j & 1)) < 127) {\n      temp_cond1[0] = temp_keys_swap[((((int)threadIdx.x) * 2) + (j & 1))];\n      temp_cond2[0] = temp_keys_swap[(((((int)threadIdx.x) * 2) + (j & 1)) + 1)];\n      if (temp_cond2[0] < temp_cond1[0]) {\n        temp_keys[0] = temp_keys_swap[((((int)threadIdx.x) * 2) + (j & 1))];\n        temp_keys_swap[((((int)threadIdx.x) * 2) + (j & 1))] = temp_keys_swap[(((((int)threadIdx.x) * 2) + (j & 1)) + 1)];\n        temp_keys_swap[(((((int)threadIdx.x) * 2) + (j & 1)) + 1)] = temp_keys[0];\n        temp_values[0] = temp_values_swap[((((int)threadIdx.x) * 2) + (j & 1))];\n        temp_values_swap[((((int)threadIdx.x) * 2) + (j & 1))] = temp_values_swap[(((((int)threadIdx.x) * 2) + (j & 1)) + 1)];\n        temp_values_swap[(((((int)threadIdx.x) * 2) + (j & 1)) + 1)] = temp_values[0];\n      }\n    }\n    __syncthreads();\n  }\n  for (int k = 0; k < 2; ++k) {\n    argsort_gpu_v0[((((((int)blockIdx.y) * 512) + (((int)blockIdx.x) * 128)) + (((int)threadIdx.x) * 2)) + k)] = temp_keys_swap[((((int)threadIdx.x) * 2) + k)];\n    argsort_gpu_v2[((((((int)blockIdx.y) * 512) + (((int)blockIdx.x) * 128)) + (((int)threadIdx.x) * 2)) + k)] = temp_keys_swap[((((int)threadIdx.x) * 2) + k)];\n    argsort_gpu[((((((int)blockIdx.y) * 512) + (((int)blockIdx.x) * 128)) + (((int)threadIdx.x) * 2)) + k)] = temp_values_swap[((((int)threadIdx.x) * 2) + k)];\n    argsort_gpu_v3[((((((int)blockIdx.y) * 512) + (((int)blockIdx.x) * 128)) + (((int)threadIdx.x) * 2)) + k)] = temp_values_swap[((((int)threadIdx.x) * 2) + k)];\n  }\n}\n\n",
        "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((64, 512), \"float32\"), extern: T.Buffer((64, 512), \"int32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        temp_data = T.allocate([1], \"float32\", \"global\")\n        temp_index = T.allocate([1], \"int32\", \"global\")\n        T.attr(0, \"extern_scope\", 0)\n        for i in T.parallel(64):\n            extern_1 = T.Buffer((32768,), \"int32\", data=extern.data)\n            for j in range(256):\n                cse_var_1: T.int32 = j * 2\n                extern_1[i * 512 + cse_var_1] = cse_var_1\n            for k in range(256):\n                cse_var_2: T.int32 = k * 2\n                extern_1[i * 512 + cse_var_2 + 1] = cse_var_2 + 1\n            for i_0, i_1 in T.grid(512, 256):\n                cse_var_4: T.int32 = i * 512 + i_1 * 2 + i_0 % 2\n                cse_var_3: T.int32 = cse_var_4 + 1\n                data_1 = T.Buffer((32768,), data=data.data)\n                if cse_var_4 < 511 and data_1[cse_var_4] < data_1[cse_var_3]:\n                    temp_data_1 = T.Buffer((1,), data=temp_data)\n                    temp_data_1[0] = data_1[cse_var_4]\n                    data_1[cse_var_4] = data_1[cse_var_3]\n                    data_1[cse_var_3] = temp_data_1[0]\n                    temp_index_1 = T.Buffer((1,), \"int32\", data=temp_index)\n                    temp_index_1[0] = extern_1[cse_var_4]\n                    extern_1[cse_var_4] = extern_1[cse_var_3]\n                    extern_1[cse_var_3] = temp_index_1[0]",
        "op_args": "None",
        "input_shape": [
            [
                64,
                512
            ]
        ],
        "output_shape": [
            [
                64,
                512
            ]
        ],
        "input_name": [
            "data"
        ],
        "output_name": [
            "extern"
        ]
    },
    {
        "op_name": "conv2d_opt",
        "c_code": "void default_function_kernel(float* data, float* kernel, float* output_unpack) {\n  float data_vec[4194304];\n  float kernel_vec[18432];\n  #pragma omp parallel for\n  for (int32_t bs_c_fused_h_fused = 0; bs_c_fused_h_fused < 4096; ++bs_c_fused_h_fused) {\n    for (int32_t w = 0; w < 256; ++w) {\n      for (int32_t vc = 0; vc < 4; ++vc) {\n        data_vec[(((bs_c_fused_h_fused * 1024) + (w * 4)) + vc)] = data[(((((bs_c_fused_h_fused >> 8) * 262144) + (vc * 65536)) + ((bs_c_fused_h_fused & 255) * 256)) + w)];\n      }\n    }\n  }\n  #pragma omp parallel for\n  for (int32_t occ_k_h_fused = 0; occ_k_h_fused < 48; ++occ_k_h_fused) {\n    for (int32_t icc = 0; icc < 8; ++icc) {\n      for (int32_t k_w = 0; k_w < 3; ++k_w) {\n        for (int32_t icb = 0; icb < 4; ++icb) {\n          for (int32_t ocb = 0; ocb < 4; ++ocb) {\n            kernel_vec[(((((((occ_k_h_fused / 3) * 1152) + (icc * 144)) + ((occ_k_h_fused % 3) * 48)) + (k_w * 16)) + (icb * 4)) + ocb)] = kernel[(((((((occ_k_h_fused / 3) * 1152) + (ocb * 288)) + (icc * 36)) + (icb * 9)) + ((occ_k_h_fused % 3) * 3)) + k_w)];\n          }\n        }\n      }\n    }\n  }\n  #pragma omp parallel for\n  for (int32_t n_c_outer_fused_h_fused = 0; n_c_outer_fused_h_fused < 8128; ++n_c_outer_fused_h_fused) {\n    float conv2d_NCHWc[1016];\n    float conv2d_NCHWc_global[8];\n    for (int32_t ow_outer = 0; ow_outer < 127; ++ow_outer) {\n      for (int32_t oc_block_c_init = 0; oc_block_c_init < 4; ++oc_block_c_init) {\n        conv2d_NCHWc_global[oc_block_c_init] = 0.000000e+00f;\n      }\n      for (int32_t oc_block_c_init_1 = 0; oc_block_c_init_1 < 4; ++oc_block_c_init_1) {\n        conv2d_NCHWc_global[(oc_block_c_init_1 + 4)] = 0.000000e+00f;\n      }\n      for (int32_t ic_outer = 0; ic_outer < 8; ++ic_outer) {\n        for (int32_t kh = 0; kh < 3; ++kh) {\n          for (int32_t kw = 0; kw < 3; ++kw) {\n            for (int32_t ic_inner = 0; ic_inner < 4; ++ic_inner) {\n              for (int32_t oc_block_c = 0; oc_block_c < 4; ++oc_block_c) {\n                conv2d_NCHWc_global[oc_block_c] = (conv2d_NCHWc_global[oc_block_c] + (data_vec[((((((((n_c_outer_fused_h_fused / 4064) * 2097152) + (ic_outer * 262144)) + (kh * 1024)) + ((n_c_outer_fused_h_fused % 254) * 1024)) + (ow_outer * 8)) + (kw * 4)) + ic_inner)] * kernel_vec[((((((((n_c_outer_fused_h_fused % 4064) / 254) * 1152) + (ic_outer * 144)) + (kh * 48)) + (kw * 16)) + (ic_inner * 4)) + oc_block_c)]));\n              }\n              for (int32_t oc_block_c_1 = 0; oc_block_c_1 < 4; ++oc_block_c_1) {\n                conv2d_NCHWc_global[(oc_block_c_1 + 4)] = (conv2d_NCHWc_global[(oc_block_c_1 + 4)] + (data_vec[(((((((((n_c_outer_fused_h_fused / 4064) * 2097152) + (ic_outer * 262144)) + (kh * 1024)) + ((n_c_outer_fused_h_fused % 254) * 1024)) + (ow_outer * 8)) + (kw * 4)) + ic_inner) + 4)] * kernel_vec[((((((((n_c_outer_fused_h_fused % 4064) / 254) * 1152) + (ic_outer * 144)) + (kh * 48)) + (kw * 16)) + (ic_inner * 4)) + oc_block_c_1)]));\n              }\n            }\n          }\n        }\n      }\n      for (int32_t ow_inner = 0; ow_inner < 2; ++ow_inner) {\n        for (int32_t oc_block = 0; oc_block < 4; ++oc_block) {\n          conv2d_NCHWc[(((ow_outer * 8) + (ow_inner * 4)) + oc_block)] = conv2d_NCHWc_global[((ow_inner * 4) + oc_block)];\n        }\n      }\n    }\n    for (int32_t w_outer = 0; w_outer < 127; ++w_outer) {\n      for (int32_t w_inner = 0; w_inner < 2; ++w_inner) {\n        for (int32_t c_inner = 0; c_inner < 4; ++c_inner) {\n          output_unpack[((((((n_c_outer_fused_h_fused / 254) * 258064) + (c_inner * 64516)) + ((n_c_outer_fused_h_fused % 254) * 254)) + (w_outer * 2)) + w_inner)] = conv2d_NCHWc[(((w_outer * 8) + (w_inner * 4)) + c_inner)];\n        }\n      }\n    }\n  }\n}\n\n",
        "cuda_code": "extern \"C\" __global__ void __launch_bounds__(16) default_function_kernel(float* __restrict__ conv2d_nchw, float* __restrict__ data, float* __restrict__ kernel) {\n  float conv2d_nchw_local[8];\n  __shared__ float pad_temp_shared[32];\n  __shared__ float kernel_shared[576];\n  for (int yy_c_init = 0; yy_c_init < 2; ++yy_c_init) {\n    conv2d_nchw_local[yy_c_init] = 0.000000e+00f;\n    conv2d_nchw_local[(yy_c_init + 2)] = 0.000000e+00f;\n    conv2d_nchw_local[(yy_c_init + 4)] = 0.000000e+00f;\n    conv2d_nchw_local[(yy_c_init + 6)] = 0.000000e+00f;\n  }\n  for (int rc_outer = 0; rc_outer < 16; ++rc_outer) {\n    __syncthreads();\n    for (int ax0_ax1_fused_ax2_fused_ax3_fused_inner_inner_inner = 0; ax0_ax1_fused_ax2_fused_ax3_fused_inner_inner_inner < 2; ++ax0_ax1_fused_ax2_fused_ax3_fused_inner_inner_inner) {\n      pad_temp_shared[(((((int)threadIdx.z) * 4) + (((int)threadIdx.x) * 2)) + ax0_ax1_fused_ax2_fused_ax3_fused_inner_inner_inner)] = data[(((((((((((int)blockIdx.z) >> 1) * 2097152) + (rc_outer * 131072)) + ((((int)threadIdx.z) >> 2) * 65536)) + (((int)blockIdx.y) * 512)) + ((((int)threadIdx.z) & 3) * 256)) + (((int)blockIdx.x) * 2)) + (((int)threadIdx.x) * 2)) + ax0_ax1_fused_ax2_fused_ax3_fused_inner_inner_inner)];\n    }\n    for (int ax0_ax1_fused_ax2_fused_ax3_fused_inner_inner_inner_1 = 0; ax0_ax1_fused_ax2_fused_ax3_fused_inner_inner_inner_1 < 36; ++ax0_ax1_fused_ax2_fused_ax3_fused_inner_inner_inner_1) {\n      kernel_shared[(((((int)threadIdx.z) * 72) + (((int)threadIdx.x) * 36)) + ax0_ax1_fused_ax2_fused_ax3_fused_inner_inner_inner_1)] = kernel[(((((((((int)blockIdx.z) & 1) * 9216) + (((int)threadIdx.z) * 1152)) + (((int)threadIdx.x) * 576)) + ((ax0_ax1_fused_ax2_fused_ax3_fused_inner_inner_inner_1 / 18) * 288)) + (rc_outer * 18)) + (ax0_ax1_fused_ax2_fused_ax3_fused_inner_inner_inner_1 % 18))];\n    }\n    __syncthreads();\n    for (int rc_inner = 0; rc_inner < 2; ++rc_inner) {\n      for (int ry_inner = 0; ry_inner < 3; ++ry_inner) {\n        for (int rx_inner = 0; rx_inner < 3; ++rx_inner) {\n          for (int yy_c = 0; yy_c < 2; ++yy_c) {\n            conv2d_nchw_local[yy_c] = (conv2d_nchw_local[yy_c] + (pad_temp_shared[(((((rc_inner * 16) + (yy_c * 4)) + (ry_inner * 4)) + ((int)threadIdx.x)) + rx_inner)] * kernel_shared[((((((int)threadIdx.z) * 18) + (rc_inner * 9)) + (ry_inner * 3)) + rx_inner)]));\n            conv2d_nchw_local[(yy_c + 2)] = (conv2d_nchw_local[(yy_c + 2)] + (pad_temp_shared[(((((rc_inner * 16) + (yy_c * 4)) + (ry_inner * 4)) + ((int)threadIdx.x)) + rx_inner)] * kernel_shared[(((((((int)threadIdx.z) * 18) + (rc_inner * 9)) + (ry_inner * 3)) + rx_inner) + 144)]));\n            conv2d_nchw_local[(yy_c + 4)] = (conv2d_nchw_local[(yy_c + 4)] + (pad_temp_shared[(((((rc_inner * 16) + (yy_c * 4)) + (ry_inner * 4)) + ((int)threadIdx.x)) + rx_inner)] * kernel_shared[(((((((int)threadIdx.z) * 18) + (rc_inner * 9)) + (ry_inner * 3)) + rx_inner) + 288)]));\n            conv2d_nchw_local[(yy_c + 6)] = (conv2d_nchw_local[(yy_c + 6)] + (pad_temp_shared[(((((rc_inner * 16) + (yy_c * 4)) + (ry_inner * 4)) + ((int)threadIdx.x)) + rx_inner)] * kernel_shared[(((((((int)threadIdx.z) * 18) + (rc_inner * 9)) + (ry_inner * 3)) + rx_inner) + 432)]));\n          }\n        }\n      }\n    }\n  }\n  for (int yy_inner_inner_inner = 0; yy_inner_inner_inner < 2; ++yy_inner_inner_inner) {\n    conv2d_nchw[((((((((int)blockIdx.z) * 2064512) + (((int)threadIdx.z) * 64516)) + (((int)blockIdx.y) * 508)) + (yy_inner_inner_inner * 254)) + (((int)blockIdx.x) * 2)) + ((int)threadIdx.x))] = conv2d_nchw_local[yy_inner_inner_inner];\n    conv2d_nchw[(((((((((int)blockIdx.z) * 2064512) + (((int)threadIdx.z) * 64516)) + (((int)blockIdx.y) * 508)) + (yy_inner_inner_inner * 254)) + (((int)blockIdx.x) * 2)) + ((int)threadIdx.x)) + 516128)] = conv2d_nchw_local[(yy_inner_inner_inner + 2)];\n    conv2d_nchw[(((((((((int)blockIdx.z) * 2064512) + (((int)threadIdx.z) * 64516)) + (((int)blockIdx.y) * 508)) + (yy_inner_inner_inner * 254)) + (((int)blockIdx.x) * 2)) + ((int)threadIdx.x)) + 1032256)] = conv2d_nchw_local[(yy_inner_inner_inner + 4)];\n    conv2d_nchw[(((((((((int)blockIdx.z) * 2064512) + (((int)threadIdx.z) * 64516)) + (((int)blockIdx.y) * 508)) + (yy_inner_inner_inner * 254)) + (((int)blockIdx.x) * 2)) + ((int)threadIdx.x)) + 1548384)] = conv2d_nchw_local[(yy_inner_inner_inner + 6)];\n  }\n}\n\n",
        "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((2, 32, 256, 256), \"float32\"), kernel: T.Buffer((64, 32, 3, 3), \"float32\"), output_unpack: T.Buffer((2, 64, 254, 254), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        data_vec = T.allocate([4194304], \"float32\", \"global\")\n        kernel_vec = T.allocate([18432], \"float32\", \"global\")\n        data_vec_1 = T.Buffer((4194304,), data=data_vec)\n        for bs_c_fused_h_fused in T.parallel(4096):\n            for w, vc in T.grid(256, 4):\n                data_1 = T.Buffer((4194304,), data=data.data)\n                data_vec_1[bs_c_fused_h_fused * 1024 + w * 4 + vc] = data_1[bs_c_fused_h_fused // 256 * 262144 + vc * 65536 + bs_c_fused_h_fused % 256 * 256 + w]\n        kernel_vec_1 = T.Buffer((18432,), data=kernel_vec)\n        for occ_k_h_fused in T.parallel(48):\n            for icc, k_w, icb, ocb in T.grid(8, 3, 4, 4):\n                cse_var_2: T.int32 = occ_k_h_fused % 3\n                cse_var_1: T.int32 = occ_k_h_fused // 3 * 1152\n                kernel_1 = T.Buffer((18432,), data=kernel.data)\n                kernel_vec_1[cse_var_1 + icc * 144 + cse_var_2 * 48 + k_w * 16 + icb * 4 + ocb] = kernel_1[cse_var_1 + ocb * 288 + icc * 36 + icb * 9 + cse_var_2 * 3 + k_w]\n        for n_c_outer_fused_h_fused in T.parallel(8128):\n            conv2d_NCHWc = T.allocate([1016], \"float32\", \"global\")\n            conv2d_NCHWc_global = T.allocate([8], \"float32\", \"global\")\n            conv2d_NCHWc_1 = T.Buffer((1016,), data=conv2d_NCHWc)\n            for ow_outer in range(127):\n                conv2d_NCHWc_global_1 = T.Buffer((8,), data=conv2d_NCHWc_global, align=32)\n                for oc_block_c_init in range(4):\n                    conv2d_NCHWc_global_1[oc_block_c_init] = T.float32(0)\n                for oc_block_c_init in range(4):\n                    conv2d_NCHWc_global_1[oc_block_c_init + 4] = T.float32(0)\n                for ic_outer, kh, kw, ic_inner in T.grid(8, 3, 3, 4):\n                    for oc_block_c in range(4):\n                        conv2d_NCHWc_global_1[oc_block_c] = conv2d_NCHWc_global_1[oc_block_c] + data_vec_1[n_c_outer_fused_h_fused // 4064 * 2097152 + ic_outer * 262144 + kh * 1024 + n_c_outer_fused_h_fused % 254 * 1024 + ow_outer * 8 + kw * 4 + ic_inner] * kernel_vec_1[n_c_outer_fused_h_fused % 4064 // 254 * 1152 + ic_outer * 144 + kh * 48 + kw * 16 + ic_inner * 4 + oc_block_c]\n                    for oc_block_c in range(4):\n                        cse_var_3: T.int32 = oc_block_c + 4\n                        conv2d_NCHWc_global_1[cse_var_3] = conv2d_NCHWc_global_1[cse_var_3] + data_vec_1[n_c_outer_fused_h_fused // 4064 * 2097152 + ic_outer * 262144 + kh * 1024 + n_c_outer_fused_h_fused % 254 * 1024 + ow_outer * 8 + kw * 4 + ic_inner + 4] * kernel_vec_1[n_c_outer_fused_h_fused % 4064 // 254 * 1152 + ic_outer * 144 + kh * 48 + kw * 16 + ic_inner * 4 + oc_block_c]\n                for ow_inner, oc_block in T.grid(2, 4):\n                    cse_var_4: T.int32 = ow_inner * 4\n                    conv2d_NCHWc_1[ow_outer * 8 + cse_var_4 + oc_block] = conv2d_NCHWc_global_1[cse_var_4 + oc_block]\n            for w_outer, w_inner, c_inner in T.grid(127, 2, 4):\n                output_unpack_1 = T.Buffer((8258048,), data=output_unpack.data)\n                output_unpack_1[n_c_outer_fused_h_fused // 254 * 258064 + c_inner * 64516 + n_c_outer_fused_h_fused % 254 * 254 + w_outer * 2 + w_inner] = conv2d_NCHWc_1[w_outer * 8 + w_inner * 4 + c_inner]",
        "op_args": "None",
        "input_shape": [
            [
                2,
                32,
                256,
                256
            ],
            [
                64,
                32,
                3,
                3
            ]
        ],
        "output_shape": [
            [
                2,
                64,
                254,
                254
            ]
        ],
        "input_name": [
            "data",
            "kernel"
        ],
        "output_name": [
            "output_unpack"
        ]
    },
    {
        "op_name": "dft",
        "c_code": "void default_function_kernel(float* Im, float* Re, float* dft_cpu, float* dft_cpu_1) {\n  #pragma omp parallel for\n  for (int32_t i = 0; i < 1200; ++i) {\n    for (int32_t j = 0; j < 50; ++j) {\n      dft_cpu[((i * 50) + j)] = 0.000000e+00f;\n      dft_cpu_1[((i * 50) + j)] = 0.000000e+00f;\n      for (int32_t k = 0; k < 50; ++k) {\n        float cse_var_2 = (((-6.283185e+00f * ((float)j)) * 2.000000e-02f) * ((float)k));\n        dft_cpu[((i * 50) + j)] = (dft_cpu[((i * 50) + j)] + ((Re[((i * 50) + k)] * cosf(cse_var_2)) - (Im[((i * 50) + k)] * sinf(cse_var_2))));\n        dft_cpu_1[((i * 50) + j)] = (dft_cpu_1[((i * 50) + j)] + ((Re[((i * 50) + k)] * sinf(cse_var_2)) + (Im[((i * 50) + k)] * cosf(cse_var_2))));\n      }\n    }\n  }\n}\n\n",
        "cuda_code": "extern \"C\" __global__ void __launch_bounds__(1024) default_function_kernel(float* __restrict__ Im, float* __restrict__ Re, float* __restrict__ dft_cuda, float* __restrict__ dft_cuda_1) {\n  if (((((int)blockIdx.x) * 64) + (((int)threadIdx.x) >> 4)) < 75) {\n    for (int i = 0; i < 50; ++i) {\n      dft_cuda[(((((int)blockIdx.x) * 51200) + (((int)threadIdx.x) * 50)) + i)] = 0.000000e+00f;\n      dft_cuda_1[(((((int)blockIdx.x) * 51200) + (((int)threadIdx.x) * 50)) + i)] = 0.000000e+00f;\n      for (int j = 0; j < 50; ++j) {\n        float cse_var_1 = (((-6.283185e+00f * ((float)i)) * 2.000000e-02f) * ((float)j));\n        dft_cuda[(((((int)blockIdx.x) * 51200) + (((int)threadIdx.x) * 50)) + i)] = (dft_cuda[(((((int)blockIdx.x) * 51200) + (((int)threadIdx.x) * 50)) + i)] + ((Re[(((((int)blockIdx.x) * 51200) + (((int)threadIdx.x) * 50)) + j)] * __cosf(cse_var_1)) - (Im[(((((int)blockIdx.x) * 51200) + (((int)threadIdx.x) * 50)) + j)] * __sinf(cse_var_1))));\n        dft_cuda_1[(((((int)blockIdx.x) * 51200) + (((int)threadIdx.x) * 50)) + i)] = (dft_cuda_1[(((((int)blockIdx.x) * 51200) + (((int)threadIdx.x) * 50)) + i)] + ((Re[(((((int)blockIdx.x) * 51200) + (((int)threadIdx.x) * 50)) + j)] * __sinf(cse_var_1)) + (Im[(((((int)blockIdx.x) * 51200) + (((int)threadIdx.x) * 50)) + j)] * __cosf(cse_var_1))));\n      }\n    }\n  }\n}\n\n",
        "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(Re: T.Buffer((30, 40, 50), \"float32\"), Im: T.Buffer((30, 40, 50), \"float32\"), dft_cpu: T.Buffer((30, 40, 50), \"float32\"), dft_cpu_1: T.Buffer((30, 40, 50), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        T.attr(0, \"extern_scope\", 0)\n        for i in T.parallel(1200):\n            for j in range(50):\n                cse_var_1: T.int32 = i * 50 + j\n                dft_cpu_2 = T.Buffer((60000,), data=dft_cpu.data)\n                dft_cpu_2[cse_var_1] = T.float32(0)\n                dft_cpu_3 = T.Buffer((60000,), data=dft_cpu_1.data)\n                dft_cpu_3[cse_var_1] = T.float32(0)\n                for k in range(50):\n                    cse_var_3: T.int32 = i * 50 + k\n                    cse_var_2: T.float32 = T.float32(-6.2831853071795862) * T.Cast(\"float32\", j) * T.float32(0.02) * T.Cast(\"float32\", k)\n                    Re_1 = T.Buffer((60000,), data=Re.data)\n                    Im_1 = T.Buffer((60000,), data=Im.data)\n                    dft_cpu_2[cse_var_1] = dft_cpu_2[cse_var_1] + (Re_1[cse_var_3] * T.cos(cse_var_2) - Im_1[cse_var_3] * T.sin(cse_var_2))\n                    dft_cpu_3[cse_var_1] = dft_cpu_3[cse_var_1] + (Re_1[cse_var_3] * T.sin(cse_var_2) + Im_1[cse_var_3] * T.cos(cse_var_2))",
        "op_args": "None",
        "input_shape": [
            [
                30,
                40,
                50
            ],
            [
                30,
                40,
                50
            ]
        ],
        "output_shape": [
            [
                30,
                40,
                50
            ],
            [
                30,
                40,
                50
            ]
        ],
        "input_name": [
            "Re",
            "Im"
        ],
        "output_name": [
            "dft_cpu.v0",
            "dft_cpu.v1"
        ]
    },
    {
        "op_name": "group_conv2d_opt",
        "c_code": "void default_function_kernel(float* A, float* W, float* output_unpack) {\n  float data_vec[8388608];\n  float kernel_vec[4608];\n  float conv_global[16516096];\n  for (int32_t g = 0; g < 4; ++g) {\n    #pragma omp parallel for\n    for (int32_t n_C_fused_h_fused = 0; n_C_fused_h_fused < 2048; ++n_C_fused_h_fused) {\n      for (int32_t c = 0; c < 4; ++c) {\n        for (int32_t w = 0; w < 256; ++w) {\n          data_vec[((((g * 2097152) + (n_C_fused_h_fused * 1024)) + (c * 256)) + w)] = A[(((((((n_C_fused_h_fused >> 9) * 2097152) + (g * 524288)) + (((n_C_fused_h_fused & 511) >> 8) * 262144)) + (c * 65536)) + ((n_C_fused_h_fused & 255) * 256)) + w)];\n        }\n      }\n    }\n  }\n  #pragma omp parallel for\n  for (int32_t g_out_channel_fused_h_fused = 0; g_out_channel_fused_h_fused < 48; ++g_out_channel_fused_h_fused) {\n    for (int32_t in_channel = 0; in_channel < 2; ++in_channel) {\n      for (int32_t w_1 = 0; w_1 < 3; ++w_1) {\n        for (int32_t ci = 0; ci < 4; ++ci) {\n          for (int32_t co = 0; co < 4; ++co) {\n            kernel_vec[(((((((g_out_channel_fused_h_fused / 3) * 288) + (in_channel * 144)) + ((g_out_channel_fused_h_fused % 3) * 48)) + (w_1 * 16)) + (ci * 4)) + co)] = W[(((((((g_out_channel_fused_h_fused / 3) * 288) + (co * 72)) + (in_channel * 36)) + (ci * 9)) + ((g_out_channel_fused_h_fused % 3) * 3)) + w_1)];\n          }\n        }\n      }\n    }\n  }\n  #pragma omp parallel for\n  for (int32_t g_c_n_c_fused_oc_chunk_c_fused_oh_c_fused = 0; g_c_n_c_fused_oc_chunk_c_fused_oh_c_fused < 16256; ++g_c_n_c_fused_oc_chunk_c_fused_oh_c_fused) {\n    for (int32_t ow_c_outer = 0; ow_c_outer < 127; ++ow_c_outer) {\n      for (int32_t oc_block_c_init = 0; oc_block_c_init < 4; ++oc_block_c_init) {\n        conv_global[(((g_c_n_c_fused_oc_chunk_c_fused_oh_c_fused * 1016) + (ow_c_outer * 8)) + oc_block_c_init)] = 0.000000e+00f;\n      }\n      for (int32_t oc_block_c_init_1 = 0; oc_block_c_init_1 < 4; ++oc_block_c_init_1) {\n        conv_global[((((g_c_n_c_fused_oc_chunk_c_fused_oh_c_fused * 1016) + (ow_c_outer * 8)) + oc_block_c_init_1) + 4)] = 0.000000e+00f;\n      }\n      for (int32_t ic_outer = 0; ic_outer < 2; ++ic_outer) {\n        for (int32_t kh = 0; kh < 3; ++kh) {\n          for (int32_t kw = 0; kw < 3; ++kw) {\n            for (int32_t ic_inner = 0; ic_inner < 4; ++ic_inner) {\n              for (int32_t oc_block_c = 0; oc_block_c < 4; ++oc_block_c) {\n                conv_global[(((g_c_n_c_fused_oc_chunk_c_fused_oh_c_fused * 1016) + (ow_c_outer * 8)) + oc_block_c)] = (conv_global[(((g_c_n_c_fused_oc_chunk_c_fused_oh_c_fused * 1016) + (ow_c_outer * 8)) + oc_block_c)] + (data_vec[((((((((g_c_n_c_fused_oc_chunk_c_fused_oh_c_fused / 1016) * 524288) + (ic_outer * 262144)) + (kh * 1024)) + ((g_c_n_c_fused_oc_chunk_c_fused_oh_c_fused % 254) * 1024)) + (ic_inner * 256)) + (ow_c_outer * 2)) + kw)] * kernel_vec[((((((((g_c_n_c_fused_oc_chunk_c_fused_oh_c_fused / 4064) * 1152) + (((g_c_n_c_fused_oc_chunk_c_fused_oh_c_fused % 1016) / 254) * 288)) + (ic_outer * 144)) + (kh * 48)) + (kw * 16)) + (ic_inner * 4)) + oc_block_c)]));\n              }\n              for (int32_t oc_block_c_1 = 0; oc_block_c_1 < 4; ++oc_block_c_1) {\n                conv_global[((((g_c_n_c_fused_oc_chunk_c_fused_oh_c_fused * 1016) + (ow_c_outer * 8)) + oc_block_c_1) + 4)] = (conv_global[((((g_c_n_c_fused_oc_chunk_c_fused_oh_c_fused * 1016) + (ow_c_outer * 8)) + oc_block_c_1) + 4)] + (data_vec[(((((((((g_c_n_c_fused_oc_chunk_c_fused_oh_c_fused / 1016) * 524288) + (ic_outer * 262144)) + (kh * 1024)) + ((g_c_n_c_fused_oc_chunk_c_fused_oh_c_fused % 254) * 1024)) + (ic_inner * 256)) + (ow_c_outer * 2)) + kw) + 1)] * kernel_vec[((((((((g_c_n_c_fused_oc_chunk_c_fused_oh_c_fused / 4064) * 1152) + (((g_c_n_c_fused_oc_chunk_c_fused_oh_c_fused % 1016) / 254) * 288)) + (ic_outer * 144)) + (kh * 48)) + (kw * 16)) + (ic_inner * 4)) + oc_block_c_1)]));\n              }\n            }\n          }\n        }\n      }\n    }\n  }\n  for (int32_t n = 0; n < 4; ++n) {\n    #pragma omp parallel for\n    for (int32_t c_outer_h_fused = 0; c_outer_h_fused < 4064; ++c_outer_h_fused) {\n      for (int32_t w_outer = 0; w_outer < 127; ++w_outer) {\n        for (int32_t w_inner = 0; w_inner < 2; ++w_inner) {\n          for (int32_t c_inner = 0; c_inner < 4; ++c_inner) {\n            output_unpack[((((((n * 4129024) + ((c_outer_h_fused / 254) * 258064)) + (c_inner * 64516)) + ((c_outer_h_fused % 254) * 254)) + (w_outer * 2)) + w_inner)] = conv_global[(((((((c_outer_h_fused / 1016) * 4129024) + (n * 1032256)) + ((c_outer_h_fused % 1016) * 1016)) + (w_outer * 8)) + (w_inner * 4)) + c_inner)];\n          }\n        }\n      }\n    }\n  }\n}\n\n",
        "cuda_code": "extern \"C\" __global__ void default_function_kernel(float* __restrict__ A, float* __restrict__ W, float* __restrict__ group_conv2d_nchw) {\n  float group_conv2d_nchw_local[1];\n  __shared__ float pad_temp_shared[1];\n  __shared__ float W_shared[1];\n  group_conv2d_nchw_local[0] = 0.000000e+00f;\n  for (int rc_outer = 0; rc_outer < 8; ++rc_outer) {\n    for (int ry_outer = 0; ry_outer < 3; ++ry_outer) {\n      for (int rx_outer = 0; rx_outer < 3; ++rx_outer) {\n        __syncthreads();\n        pad_temp_shared[0] = A[(((((((((int)blockIdx.z) * 2097152) + ((((int)blockIdx.y) >> 4) * 524288)) + (rc_outer * 65536)) + ((((int)blockIdx.x) / 254) * 256)) + (ry_outer * 256)) + rx_outer) + (((int)blockIdx.x) % 254))];\n        W_shared[0] = W[((((((int)blockIdx.y) * 72) + (rc_outer * 9)) + (ry_outer * 3)) + rx_outer)];\n        __syncthreads();\n        group_conv2d_nchw_local[0] = (group_conv2d_nchw_local[0] + (pad_temp_shared[0] * W_shared[0]));\n      }\n    }\n  }\n  group_conv2d_nchw[(((((int)blockIdx.z) * 4129024) + (((int)blockIdx.y) * 64516)) + ((int)blockIdx.x))] = group_conv2d_nchw_local[0];\n}\n\n",
        "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(A: T.Buffer((4, 32, 256, 256), \"float32\"), W: T.Buffer((64, 8, 3, 3), \"float32\"), output_unpack: T.Buffer((4, 64, 254, 254), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        data_vec = T.allocate([8388608], \"float32\", \"global\")\n        kernel_vec = T.allocate([4608], \"float32\", \"global\")\n        conv_global = T.allocate([16516096], \"float32\", \"global\")\n        data_vec_1 = T.Buffer((8388608,), data=data_vec)\n        for g in range(4):\n            for n_C_fused_h_fused in T.parallel(2048):\n                for c, w in T.grid(4, 256):\n                    A_1 = T.Buffer((8388608,), data=A.data)\n                    data_vec_1[g * 2097152 + n_C_fused_h_fused * 1024 + c * 256 + w] = A_1[n_C_fused_h_fused // 512 * 2097152 + g * 524288 + n_C_fused_h_fused % 512 // 256 * 262144 + c * 65536 + n_C_fused_h_fused % 256 * 256 + w]\n        kernel_vec_1 = T.Buffer((4608,), data=kernel_vec)\n        for g_out_channel_fused_h_fused in T.parallel(48):\n            for in_channel, w, ci, co in T.grid(2, 3, 4, 4):\n                cse_var_2: T.int32 = g_out_channel_fused_h_fused % 3\n                cse_var_1: T.int32 = g_out_channel_fused_h_fused // 3 * 288\n                W_1 = T.Buffer((4608,), data=W.data)\n                kernel_vec_1[cse_var_1 + in_channel * 144 + cse_var_2 * 48 + w * 16 + ci * 4 + co] = W_1[cse_var_1 + co * 72 + in_channel * 36 + ci * 9 + cse_var_2 * 3 + w]\n        for g_c_n_c_fused_oc_chunk_c_fused_oh_c_fused in T.parallel(16256):\n            for ow_c_outer in range(127):\n                conv_global_1 = T.Buffer((16516096,), data=conv_global)\n                for oc_block_c_init in range(4):\n                    conv_global_1[g_c_n_c_fused_oc_chunk_c_fused_oh_c_fused * 1016 + ow_c_outer * 8 + oc_block_c_init] = T.float32(0)\n                for oc_block_c_init in range(4):\n                    conv_global_1[g_c_n_c_fused_oc_chunk_c_fused_oh_c_fused * 1016 + ow_c_outer * 8 + oc_block_c_init + 4] = T.float32(0)\n                for ic_outer, kh, kw, ic_inner in T.grid(2, 3, 3, 4):\n                    for oc_block_c in range(4):\n                        cse_var_3: T.int32 = g_c_n_c_fused_oc_chunk_c_fused_oh_c_fused * 1016 + ow_c_outer * 8 + oc_block_c\n                        conv_global_1[cse_var_3] = conv_global_1[cse_var_3] + data_vec_1[g_c_n_c_fused_oc_chunk_c_fused_oh_c_fused // 1016 * 524288 + ic_outer * 262144 + kh * 1024 + g_c_n_c_fused_oc_chunk_c_fused_oh_c_fused % 254 * 1024 + ic_inner * 256 + ow_c_outer * 2 + kw] * kernel_vec_1[g_c_n_c_fused_oc_chunk_c_fused_oh_c_fused // 4064 * 1152 + g_c_n_c_fused_oc_chunk_c_fused_oh_c_fused % 1016 // 254 * 288 + ic_outer * 144 + kh * 48 + kw * 16 + ic_inner * 4 + oc_block_c]\n                    for oc_block_c in range(4):\n                        cse_var_4: T.int32 = g_c_n_c_fused_oc_chunk_c_fused_oh_c_fused * 1016 + ow_c_outer * 8 + oc_block_c + 4\n                        conv_global_1[cse_var_4] = conv_global_1[cse_var_4] + data_vec_1[g_c_n_c_fused_oc_chunk_c_fused_oh_c_fused // 1016 * 524288 + ic_outer * 262144 + kh * 1024 + g_c_n_c_fused_oc_chunk_c_fused_oh_c_fused % 254 * 1024 + ic_inner * 256 + ow_c_outer * 2 + kw + 1] * kernel_vec_1[g_c_n_c_fused_oc_chunk_c_fused_oh_c_fused // 4064 * 1152 + g_c_n_c_fused_oc_chunk_c_fused_oh_c_fused % 1016 // 254 * 288 + ic_outer * 144 + kh * 48 + kw * 16 + ic_inner * 4 + oc_block_c]\n        for n in range(4):\n            for c_outer_h_fused in T.parallel(4064):\n                for w_outer, w_inner, c_inner in T.grid(127, 2, 4):\n                    output_unpack_1 = T.Buffer((16516096,), data=output_unpack.data)\n                    conv_global_1 = T.Buffer((16516096,), data=conv_global)\n                    output_unpack_1[n * 4129024 + c_outer_h_fused // 254 * 258064 + c_inner * 64516 + c_outer_h_fused % 254 * 254 + w_outer * 2 + w_inner] = conv_global_1[c_outer_h_fused // 1016 * 4129024 + n * 1032256 + c_outer_h_fused % 1016 * 1016 + w_outer * 8 + w_inner * 4 + c_inner]",
        "op_args": "None",
        "input_shape": [
            [
                4,
                32,
                256,
                256
            ],
            [
                64,
                8,
                3,
                3
            ]
        ],
        "output_shape": [
            [
                4,
                64,
                254,
                254
            ]
        ],
        "input_name": [
            "A",
            "W"
        ],
        "output_name": [
            "output_unpack"
        ]
    },
    {
        "op_name": "batch_matmul_opt",
        "c_code": "void default_function_kernel(float* T_batch_matmul_NT, float* x, float* y) {\n  #pragma omp parallel for\n  for (int32_t b_i_outer_fused_j_outer_fused = 0; b_i_outer_fused_j_outer_fused < 1048576; ++b_i_outer_fused_j_outer_fused) {\n    float T_batch_matmul_NT_global_rf[1024];\n    float T_batch_matmul_NT_global[64];\n    for (int32_t k_inner = 0; k_inner < 16; ++k_inner) {\n      for (int32_t i_c_j_c_fused = 0; i_c_j_c_fused < 64; ++i_c_j_c_fused) {\n        T_batch_matmul_NT_global_rf[((k_inner * 64) + i_c_j_c_fused)] = 0.000000e+00f;\n        for (int32_t k_outer = 0; k_outer < 128; ++k_outer) {\n          T_batch_matmul_NT_global_rf[((k_inner * 64) + i_c_j_c_fused)] = (T_batch_matmul_NT_global_rf[((k_inner * 64) + i_c_j_c_fused)] + (x[(((((b_i_outer_fused_j_outer_fused >> 8) * 16384) + ((i_c_j_c_fused >> 3) * 2048)) + (k_outer * 16)) + k_inner)] * y[((((((b_i_outer_fused_j_outer_fused >> 16) * 4194304) + ((b_i_outer_fused_j_outer_fused & 255) * 16384)) + ((i_c_j_c_fused & 7) * 2048)) + (k_outer * 16)) + k_inner)]));\n        }\n      }\n    }\n    for (int32_t ax1 = 0; ax1 < 8; ++ax1) {\n      for (int32_t ax2 = 0; ax2 < 8; ++ax2) {\n        T_batch_matmul_NT_global[((ax1 * 8) + ax2)] = 0.000000e+00f;\n        T_batch_matmul_NT_global[((ax1 * 8) + ax2)] = (T_batch_matmul_NT_global[((ax1 * 8) + ax2)] + T_batch_matmul_NT_global_rf[((ax1 * 8) + ax2)]);\n        T_batch_matmul_NT_global[((ax1 * 8) + ax2)] = (T_batch_matmul_NT_global[((ax1 * 8) + ax2)] + T_batch_matmul_NT_global_rf[(((ax1 * 8) + ax2) + 64)]);\n        T_batch_matmul_NT_global[((ax1 * 8) + ax2)] = (T_batch_matmul_NT_global[((ax1 * 8) + ax2)] + T_batch_matmul_NT_global_rf[(((ax1 * 8) + ax2) + 128)]);\n        T_batch_matmul_NT_global[((ax1 * 8) + ax2)] = (T_batch_matmul_NT_global[((ax1 * 8) + ax2)] + T_batch_matmul_NT_global_rf[(((ax1 * 8) + ax2) + 192)]);\n        T_batch_matmul_NT_global[((ax1 * 8) + ax2)] = (T_batch_matmul_NT_global[((ax1 * 8) + ax2)] + T_batch_matmul_NT_global_rf[(((ax1 * 8) + ax2) + 256)]);\n        T_batch_matmul_NT_global[((ax1 * 8) + ax2)] = (T_batch_matmul_NT_global[((ax1 * 8) + ax2)] + T_batch_matmul_NT_global_rf[(((ax1 * 8) + ax2) + 320)]);\n        T_batch_matmul_NT_global[((ax1 * 8) + ax2)] = (T_batch_matmul_NT_global[((ax1 * 8) + ax2)] + T_batch_matmul_NT_global_rf[(((ax1 * 8) + ax2) + 384)]);\n        T_batch_matmul_NT_global[((ax1 * 8) + ax2)] = (T_batch_matmul_NT_global[((ax1 * 8) + ax2)] + T_batch_matmul_NT_global_rf[(((ax1 * 8) + ax2) + 448)]);\n        T_batch_matmul_NT_global[((ax1 * 8) + ax2)] = (T_batch_matmul_NT_global[((ax1 * 8) + ax2)] + T_batch_matmul_NT_global_rf[(((ax1 * 8) + ax2) + 512)]);\n        T_batch_matmul_NT_global[((ax1 * 8) + ax2)] = (T_batch_matmul_NT_global[((ax1 * 8) + ax2)] + T_batch_matmul_NT_global_rf[(((ax1 * 8) + ax2) + 576)]);\n        T_batch_matmul_NT_global[((ax1 * 8) + ax2)] = (T_batch_matmul_NT_global[((ax1 * 8) + ax2)] + T_batch_matmul_NT_global_rf[(((ax1 * 8) + ax2) + 640)]);\n        T_batch_matmul_NT_global[((ax1 * 8) + ax2)] = (T_batch_matmul_NT_global[((ax1 * 8) + ax2)] + T_batch_matmul_NT_global_rf[(((ax1 * 8) + ax2) + 704)]);\n        T_batch_matmul_NT_global[((ax1 * 8) + ax2)] = (T_batch_matmul_NT_global[((ax1 * 8) + ax2)] + T_batch_matmul_NT_global_rf[(((ax1 * 8) + ax2) + 768)]);\n        T_batch_matmul_NT_global[((ax1 * 8) + ax2)] = (T_batch_matmul_NT_global[((ax1 * 8) + ax2)] + T_batch_matmul_NT_global_rf[(((ax1 * 8) + ax2) + 832)]);\n        T_batch_matmul_NT_global[((ax1 * 8) + ax2)] = (T_batch_matmul_NT_global[((ax1 * 8) + ax2)] + T_batch_matmul_NT_global_rf[(((ax1 * 8) + ax2) + 896)]);\n        T_batch_matmul_NT_global[((ax1 * 8) + ax2)] = (T_batch_matmul_NT_global[((ax1 * 8) + ax2)] + T_batch_matmul_NT_global_rf[(((ax1 * 8) + ax2) + 960)]);\n      }\n    }\n    for (int32_t i_inner = 0; i_inner < 8; ++i_inner) {\n      T_batch_matmul_NT[((((b_i_outer_fused_j_outer_fused >> 8) * 16384) + (i_inner * 2048)) + ((b_i_outer_fused_j_outer_fused & 255) * 8))] = T_batch_matmul_NT_global[(i_inner * 8)];\n      T_batch_matmul_NT[(((((b_i_outer_fused_j_outer_fused >> 8) * 16384) + (i_inner * 2048)) + ((b_i_outer_fused_j_outer_fused & 255) * 8)) + 1)] = T_batch_matmul_NT_global[((i_inner * 8) + 1)];\n      T_batch_matmul_NT[(((((b_i_outer_fused_j_outer_fused >> 8) * 16384) + (i_inner * 2048)) + ((b_i_outer_fused_j_outer_fused & 255) * 8)) + 2)] = T_batch_matmul_NT_global[((i_inner * 8) + 2)];\n      T_batch_matmul_NT[(((((b_i_outer_fused_j_outer_fused >> 8) * 16384) + (i_inner * 2048)) + ((b_i_outer_fused_j_outer_fused & 255) * 8)) + 3)] = T_batch_matmul_NT_global[((i_inner * 8) + 3)];\n      T_batch_matmul_NT[(((((b_i_outer_fused_j_outer_fused >> 8) * 16384) + (i_inner * 2048)) + ((b_i_outer_fused_j_outer_fused & 255) * 8)) + 4)] = T_batch_matmul_NT_global[((i_inner * 8) + 4)];\n      T_batch_matmul_NT[(((((b_i_outer_fused_j_outer_fused >> 8) * 16384) + (i_inner * 2048)) + ((b_i_outer_fused_j_outer_fused & 255) * 8)) + 5)] = T_batch_matmul_NT_global[((i_inner * 8) + 5)];\n      T_batch_matmul_NT[(((((b_i_outer_fused_j_outer_fused >> 8) * 16384) + (i_inner * 2048)) + ((b_i_outer_fused_j_outer_fused & 255) * 8)) + 6)] = T_batch_matmul_NT_global[((i_inner * 8) + 6)];\n      T_batch_matmul_NT[(((((b_i_outer_fused_j_outer_fused >> 8) * 16384) + (i_inner * 2048)) + ((b_i_outer_fused_j_outer_fused & 255) * 8)) + 7)] = T_batch_matmul_NT_global[((i_inner * 8) + 7)];\n    }\n  }\n}\n\n",
        "cuda_code": "extern \"C\" __global__ void __launch_bounds__(64) default_function_kernel(float* __restrict__ T_batch_matmul_NT, float* __restrict__ x, float* __restrict__ y) {\n  float T_batch_matmul_NT_local[64];\n  __shared__ float x_shared[512];\n  __shared__ float y_shared[512];\n  float x_shared_local[8];\n  float y_shared_local[8];\n  for (int i_c_init = 0; i_c_init < 8; ++i_c_init) {\n    for (int j_c_init = 0; j_c_init < 8; ++j_c_init) {\n      T_batch_matmul_NT_local[((i_c_init * 8) + j_c_init)] = 0.000000e+00f;\n    }\n  }\n  for (int k_outer = 0; k_outer < 256; ++k_outer) {\n    __syncthreads();\n    #pragma unroll\n    for (int ax1_inner = 0; ax1_inner < 8; ++ax1_inner) {\n      x_shared[(((((int)threadIdx.y) * 64) + (ax1_inner * 8)) + ((int)threadIdx.x))] = x[((((((((int)blockIdx.z) * 4194304) + (((int)blockIdx.y) * 131072)) + (((int)threadIdx.y) * 16384)) + (ax1_inner * 2048)) + (k_outer * 8)) + ((int)threadIdx.x))];\n    }\n    #pragma unroll\n    for (int ax1_inner_1 = 0; ax1_inner_1 < 8; ++ax1_inner_1) {\n      y_shared[(((((int)threadIdx.y) * 64) + (ax1_inner_1 * 8)) + ((int)threadIdx.x))] = y[((((((((int)blockIdx.z) * 4194304) + (((int)blockIdx.x) * 131072)) + (((int)threadIdx.y) * 16384)) + (ax1_inner_1 * 2048)) + (k_outer * 8)) + ((int)threadIdx.x))];\n    }\n    __syncthreads();\n    for (int k_inner = 0; k_inner < 8; ++k_inner) {\n      #pragma unroll\n      for (int ax1 = 0; ax1 < 8; ++ax1) {\n        x_shared_local[ax1] = x_shared[(((((int)threadIdx.y) * 64) + (ax1 * 8)) + k_inner)];\n      }\n      #pragma unroll\n      for (int ax1_1 = 0; ax1_1 < 8; ++ax1_1) {\n        y_shared_local[ax1_1] = y_shared[(((((int)threadIdx.x) * 64) + (ax1_1 * 8)) + k_inner)];\n      }\n      for (int i_c = 0; i_c < 8; ++i_c) {\n        #pragma unroll\n        for (int j_c = 0; j_c < 8; ++j_c) {\n          T_batch_matmul_NT_local[((i_c * 8) + j_c)] = (T_batch_matmul_NT_local[((i_c * 8) + j_c)] + (x_shared_local[i_c] * y_shared_local[j_c]));\n        }\n      }\n    }\n  }\n  for (int i_inner_inner = 0; i_inner_inner < 8; ++i_inner_inner) {\n    #pragma unroll\n    for (int j_inner_inner = 0; j_inner_inner < 8; ++j_inner_inner) {\n      T_batch_matmul_NT[(((((((((int)blockIdx.z) * 4194304) + (((int)blockIdx.y) * 131072)) + (((int)threadIdx.y) * 16384)) + (i_inner_inner * 2048)) + (((int)blockIdx.x) * 64)) + (((int)threadIdx.x) * 8)) + j_inner_inner)] = T_batch_matmul_NT_local[((i_inner_inner * 8) + j_inner_inner)];\n    }\n  }\n}\n\n",
        "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(x: T.Buffer((16, 2048, 2048), \"float32\"), y: T.Buffer((16, 2048, 2048), \"float32\"), T_batch_matmul_NT: T.Buffer((16, 2048, 2048), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for b_i_outer_fused_j_outer_fused in T.parallel(1048576):\n            T_batch_matmul_NT_global_rf = T.allocate([1024], \"float32\", \"global\")\n            T_batch_matmul_NT_global = T.allocate([64], \"float32\", \"global\")\n            T_batch_matmul_NT_global_rf_1 = T.Buffer((1024,), data=T_batch_matmul_NT_global_rf)\n            for k_inner, i_c_j_c_fused in T.grid(16, 64):\n                T_batch_matmul_NT_global_rf_1[k_inner * 64 + i_c_j_c_fused] = T.float32(0)\n                for k_outer in range(128):\n                    cse_var_2: T.int32 = k_outer * 16\n                    cse_var_1: T.int32 = k_inner * 64 + i_c_j_c_fused\n                    x_1 = T.Buffer((67108864,), data=x.data)\n                    y_1 = T.Buffer((67108864,), data=y.data)\n                    T_batch_matmul_NT_global_rf_1[cse_var_1] = T_batch_matmul_NT_global_rf_1[cse_var_1] + x_1[b_i_outer_fused_j_outer_fused // 256 * 16384 + i_c_j_c_fused // 8 * 2048 + cse_var_2 + k_inner] * y_1[b_i_outer_fused_j_outer_fused // 65536 * 4194304 + b_i_outer_fused_j_outer_fused % 256 * 16384 + i_c_j_c_fused % 8 * 2048 + cse_var_2 + k_inner]\n            T_batch_matmul_NT_global_1 = T.Buffer((64,), data=T_batch_matmul_NT_global)\n            for ax1, ax2 in T.grid(8, 8):\n                cse_var_3: T.int32 = ax1 * 8 + ax2\n                T_batch_matmul_NT_global_1[cse_var_3] = T.float32(0)\n                T_batch_matmul_NT_global_1[cse_var_3] = T_batch_matmul_NT_global_1[cse_var_3] + T_batch_matmul_NT_global_rf_1[cse_var_3]\n                T_batch_matmul_NT_global_1[cse_var_3] = T_batch_matmul_NT_global_1[cse_var_3] + T_batch_matmul_NT_global_rf_1[cse_var_3 + 64]\n                T_batch_matmul_NT_global_1[cse_var_3] = T_batch_matmul_NT_global_1[cse_var_3] + T_batch_matmul_NT_global_rf_1[cse_var_3 + 128]\n                T_batch_matmul_NT_global_1[cse_var_3] = T_batch_matmul_NT_global_1[cse_var_3] + T_batch_matmul_NT_global_rf_1[cse_var_3 + 192]\n                T_batch_matmul_NT_global_1[cse_var_3] = T_batch_matmul_NT_global_1[cse_var_3] + T_batch_matmul_NT_global_rf_1[cse_var_3 + 256]\n                T_batch_matmul_NT_global_1[cse_var_3] = T_batch_matmul_NT_global_1[cse_var_3] + T_batch_matmul_NT_global_rf_1[cse_var_3 + 320]\n                T_batch_matmul_NT_global_1[cse_var_3] = T_batch_matmul_NT_global_1[cse_var_3] + T_batch_matmul_NT_global_rf_1[cse_var_3 + 384]\n                T_batch_matmul_NT_global_1[cse_var_3] = T_batch_matmul_NT_global_1[cse_var_3] + T_batch_matmul_NT_global_rf_1[cse_var_3 + 448]\n                T_batch_matmul_NT_global_1[cse_var_3] = T_batch_matmul_NT_global_1[cse_var_3] + T_batch_matmul_NT_global_rf_1[cse_var_3 + 512]\n                T_batch_matmul_NT_global_1[cse_var_3] = T_batch_matmul_NT_global_1[cse_var_3] + T_batch_matmul_NT_global_rf_1[cse_var_3 + 576]\n                T_batch_matmul_NT_global_1[cse_var_3] = T_batch_matmul_NT_global_1[cse_var_3] + T_batch_matmul_NT_global_rf_1[cse_var_3 + 640]\n                T_batch_matmul_NT_global_1[cse_var_3] = T_batch_matmul_NT_global_1[cse_var_3] + T_batch_matmul_NT_global_rf_1[cse_var_3 + 704]\n                T_batch_matmul_NT_global_1[cse_var_3] = T_batch_matmul_NT_global_1[cse_var_3] + T_batch_matmul_NT_global_rf_1[cse_var_3 + 768]\n                T_batch_matmul_NT_global_1[cse_var_3] = T_batch_matmul_NT_global_1[cse_var_3] + T_batch_matmul_NT_global_rf_1[cse_var_3 + 832]\n                T_batch_matmul_NT_global_1[cse_var_3] = T_batch_matmul_NT_global_1[cse_var_3] + T_batch_matmul_NT_global_rf_1[cse_var_3 + 896]\n                T_batch_matmul_NT_global_1[cse_var_3] = T_batch_matmul_NT_global_1[cse_var_3] + T_batch_matmul_NT_global_rf_1[cse_var_3 + 960]\n            for i_inner in range(8):\n                cse_var_5: T.int32 = i_inner * 8\n                cse_var_4: T.int32 = b_i_outer_fused_j_outer_fused // 256 * 16384 + i_inner * 2048 + b_i_outer_fused_j_outer_fused % 256 * 8\n                T_batch_matmul_NT_1 = T.Buffer((67108864,), data=T_batch_matmul_NT.data)\n                T_batch_matmul_NT_1[cse_var_4] = T_batch_matmul_NT_global_1[cse_var_5]\n                T_batch_matmul_NT_1[cse_var_4 + 1] = T_batch_matmul_NT_global_1[cse_var_5 + 1]\n                T_batch_matmul_NT_1[cse_var_4 + 2] = T_batch_matmul_NT_global_1[cse_var_5 + 2]\n                T_batch_matmul_NT_1[cse_var_4 + 3] = T_batch_matmul_NT_global_1[cse_var_5 + 3]\n                T_batch_matmul_NT_1[cse_var_4 + 4] = T_batch_matmul_NT_global_1[cse_var_5 + 4]\n                T_batch_matmul_NT_1[cse_var_4 + 5] = T_batch_matmul_NT_global_1[cse_var_5 + 5]\n                T_batch_matmul_NT_1[cse_var_4 + 6] = T_batch_matmul_NT_global_1[cse_var_5 + 6]\n                T_batch_matmul_NT_1[cse_var_4 + 7] = T_batch_matmul_NT_global_1[cse_var_5 + 7]",
        "op_args": "None",
        "input_shape": [
            [
                16,
                2048,
                2048
            ],
            [
                16,
                2048,
                2048
            ]
        ],
        "output_shape": [
            [
                16,
                2048,
                2048
            ]
        ],
        "input_name": [
            "x",
            "y"
        ],
        "output_name": [
            "T_batch_matmul_NT"
        ]
    },
    {
        "op_name": "sin",
        "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused_i3_fused = 0; i0_i1_fused_i2_fused_i3_fused < 2048; ++i0_i1_fused_i2_fused_i3_fused) {\n    compute[i0_i1_fused_i2_fused_i3_fused] = sinf(data[i0_i1_fused_i2_fused_i3_fused]);\n  }\n}\n\n",
        "cuda_code": "extern \"C\" __global__ void __launch_bounds__(4) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))] = __sinf(data[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))]);\n}\n\n",
        "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((16, 2, 16, 4), \"float32\"), compute: T.Buffer((16, 2, 16, 4), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused_i2_fused_i3_fused in T.parallel(2048):\n            compute_1 = T.Buffer((2048,), data=compute.data)\n            data_1 = T.Buffer((2048,), data=data.data)\n            compute_1[i0_i1_fused_i2_fused_i3_fused] = T.sin(data_1[i0_i1_fused_i2_fused_i3_fused])",
        "op_args": [
            16,
            2,
            16,
            4
        ],
        "input_shape": [
            [
                16,
                2,
                16,
                4
            ]
        ],
        "output_shape": [
            [
                16,
                2,
                16,
                4
            ]
        ]
    },
    {
        "op_name": "adaptive_pool_max",
        "c_code": "void default_function_kernel(float* adaptive_pool_max, float* data) {\n  #pragma omp parallel for\n  for (int32_t ax0_ax1_fused_ax2_fused = 0; ax0_ax1_fused_ax2_fused < 2040; ++ax0_ax1_fused_ax2_fused) {\n    for (int32_t ax3 = 0; ax3 < 8; ++ax3) {\n      adaptive_pool_max[((ax0_ax1_fused_ax2_fused * 8) + ax3)] = -3.402823e+38f;\n      for (int32_t rv0 = 0; rv0 < (((((((ax0_ax1_fused_ax2_fused & 7) * 5) + 5) % 8) == 0) ? ((((ax0_ax1_fused_ax2_fused & 7) * 5) + 5) >> 3) : (((((ax0_ax1_fused_ax2_fused & 7) * 5) + 5) >> 3) + 1)) - (((ax0_ax1_fused_ax2_fused & 7) * 5) >> 3)); ++rv0) {\n        for (int32_t rv1 = 0; rv1 < 2; ++rv1) {\n          adaptive_pool_max[((ax0_ax1_fused_ax2_fused * 8) + ax3)] = max(adaptive_pool_max[((ax0_ax1_fused_ax2_fused * 8) + ax3)], data[((((((ax0_ax1_fused_ax2_fused >> 3) * 80) + ((((ax0_ax1_fused_ax2_fused & 7) * 5) >> 3) * 16)) + (rv0 * 16)) + (ax3 * 2)) + rv1)]);\n        }\n      }\n    }\n  }\n}\n\n",
        "cuda_code": "extern \"C\" __global__ void __launch_bounds__(60) default_function_kernel(float* __restrict__ adaptive_pool_max, float* __restrict__ data) {\n  adaptive_pool_max[((((int)blockIdx.x) * 60) + ((int)threadIdx.x))] = -3.402823e+38f;\n  for (int rv0 = 0; rv0 < ((((((((((((int)blockIdx.x) * 15) + (((int)threadIdx.x) >> 2)) & 15) >> 1) * 5) + 5) % 8) == 0) ? (((((((((int)blockIdx.x) * 15) + (((int)threadIdx.x) >> 2)) & 15) >> 1) * 5) + 5) >> 3) : ((((((((((int)blockIdx.x) * 15) + (((int)threadIdx.x) >> 2)) & 15) >> 1) * 5) + 5) >> 3) + 1)) - ((((((((int)blockIdx.x) * 15) + (((int)threadIdx.x) >> 2)) & 15) >> 1) * 5) >> 3)); ++rv0) {\n    for (int rv1 = 0; rv1 < 2; ++rv1) {\n      adaptive_pool_max[((((int)blockIdx.x) * 60) + ((int)threadIdx.x))] = max(adaptive_pool_max[((((int)blockIdx.x) * 60) + ((int)threadIdx.x))], data[((((((((((int)blockIdx.x) * 15) + (((int)threadIdx.x) >> 2)) >> 4) * 80) + (((((((((int)blockIdx.x) * 15) + (((int)threadIdx.x) >> 2)) & 15) >> 1) * 5) >> 3) * 16)) + (rv0 * 16)) + ((((((int)blockIdx.x) * 4) + ((int)threadIdx.x)) & 7) * 2)) + rv1)]);\n    }\n  }\n}\n\n",
        "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((15, 17, 5, 16), \"float32\"), adaptive_pool_max: T.Buffer((15, 17, 8, 8), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0_ax1_fused_ax2_fused in T.parallel(2040):\n            for ax3 in range(8):\n                adaptive_pool_max_1 = T.Buffer((16320,), data=adaptive_pool_max.data)\n                adaptive_pool_max_1[ax0_ax1_fused_ax2_fused * 8 + ax3] = T.float32(-3.4028234663852886e+38)\n                for rv0, rv1 in T.grid(T.Let(T.Let(T.Let(T.Select(cse_var_3 % 8 == 0, cse_var_1, cse_var_1 + 1) - cse_var_2 // 8, where={cse_var_1: cse_var_3 // 8}), where={cse_var_3: cse_var_2 + 5}), where={cse_var_2: ax0_ax1_fused_ax2_fused % 8 * 5}), 2):\n                    cse_var_2 = T.int32()\n                    cse_var_3 = T.int32()\n                    cse_var_1 = T.int32()\n                    cse_var_4: T.int32 = ax0_ax1_fused_ax2_fused * 8 + ax3\n                    data_1 = T.Buffer((20400,), data=data.data)\n                    adaptive_pool_max_1[cse_var_4] = T.max(adaptive_pool_max_1[cse_var_4], data_1[ax0_ax1_fused_ax2_fused // 8 * 80 + ax0_ax1_fused_ax2_fused % 8 * 5 // 8 * 16 + rv0 * 16 + ax3 * 2 + rv1])",
        "op_args": [
            15,
            17,
            5,
            16
        ],
        "input_shape": [
            [
                15,
                17,
                5,
                16
            ]
        ],
        "output_shape": [
            [
                15,
                17,
                8,
                8
            ]
        ]
    },
    {
        "op_name": "abs",
        "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused = 0; i0_i1_fused < 48; ++i0_i1_fused) {\n    for (int32_t i2 = 0; i2 < 4; ++i2) {\n      for (int32_t i3 = 0; i3 < 12; ++i3) {\n        compute[(((i0_i1_fused * 48) + (i2 * 12)) + i3)] = fabsf(data[(((i0_i1_fused * 48) + (i2 * 12)) + i3)]);\n      }\n    }\n  }\n}\n\n",
        "cuda_code": "extern \"C\" __global__ void __launch_bounds__(64) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))] = fabsf(data[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))]);\n}\n\n",
        "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((16, 3, 4, 12), \"float32\"), compute: T.Buffer((16, 3, 4, 12), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused in T.parallel(48):\n            for i2, i3 in T.grid(4, 12):\n                cse_var_1: T.int32 = i0_i1_fused * 48 + i2 * 12 + i3\n                compute_1 = T.Buffer((2304,), data=compute.data)\n                data_1 = T.Buffer((2304,), data=data.data)\n                compute_1[cse_var_1] = T.fabs(data_1[cse_var_1])",
        "op_args": [
            16,
            3,
            4,
            12
        ],
        "input_shape": [
            [
                16,
                3,
                4,
                12
            ]
        ],
        "output_shape": [
            [
                16,
                3,
                4,
                12
            ]
        ]
    },
    {
        "op_name": "cos",
        "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused_i3_fused = 0; i0_i1_fused_i2_fused_i3_fused < 3094; ++i0_i1_fused_i2_fused_i3_fused) {\n    compute[i0_i1_fused_i2_fused_i3_fused] = cosf(data[i0_i1_fused_i2_fused_i3_fused]);\n  }\n}\n\n",
        "cuda_code": "extern \"C\" __global__ void __launch_bounds__(7) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 7) + ((int)threadIdx.x))] = __cosf(data[((((int)blockIdx.x) * 7) + ((int)threadIdx.x))]);\n}\n\n",
        "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((17, 2, 13, 7), \"float32\"), compute: T.Buffer((17, 2, 13, 7), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused_i2_fused_i3_fused in T.parallel(3094):\n            compute_1 = T.Buffer((3094,), data=compute.data)\n            data_1 = T.Buffer((3094,), data=data.data)\n            compute_1[i0_i1_fused_i2_fused_i3_fused] = T.cos(data_1[i0_i1_fused_i2_fused_i3_fused])",
        "op_args": [
            17,
            2,
            13,
            7
        ],
        "input_shape": [
            [
                17,
                2,
                13,
                7
            ]
        ],
        "output_shape": [
            [
                17,
                2,
                13,
                7
            ]
        ]
    },
    {
        "op_name": "atan",
        "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused = 0; i0_i1_fused_i2_fused < 1428; ++i0_i1_fused_i2_fused) {\n    for (int32_t i3_s = 0; i3_s < 9; ++i3_s) {\n      compute[((i0_i1_fused_i2_fused * 9) + i3_s)] = atanf(data[((i0_i1_fused_i2_fused * 9) + i3_s)]);\n    }\n  }\n}\n\n",
        "cuda_code": "extern \"C\" __global__ void __launch_bounds__(18) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))] = atanf(data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))]);\n}\n\n",
        "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((17, 12, 7, 9), \"float32\"), compute: T.Buffer((17, 12, 7, 9), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused_i2_fused in T.parallel(1428):\n            for i3_s in range(9):\n                cse_var_1: T.int32 = i0_i1_fused_i2_fused * 9 + i3_s\n                compute_1 = T.Buffer((12852,), data=compute.data)\n                data_1 = T.Buffer((12852,), data=data.data)\n                compute_1[cse_var_1] = T.atan(data_1[cse_var_1])",
        "op_args": [
            17,
            12,
            7,
            9
        ],
        "input_shape": [
            [
                17,
                12,
                7,
                9
            ]
        ],
        "output_shape": [
            [
                17,
                12,
                7,
                9
            ]
        ]
    },
    {
        "op_name": "add",
        "c_code": "void default_function_kernel(float* T_add, float* data, float* data_1) {\n  #pragma omp parallel for\n  for (int32_t ax0 = 0; ax0 < 20; ++ax0) {\n    for (int32_t ax1 = 0; ax1 < 10; ++ax1) {\n      for (int32_t ax2 = 0; ax2 < 9; ++ax2) {\n        for (int32_t ax3 = 0; ax3 < 18; ++ax3) {\n          T_add[((((ax0 * 1620) + (ax1 * 162)) + (ax2 * 18)) + ax3)] = (data[((((ax0 * 1620) + (ax1 * 162)) + (ax2 * 18)) + ax3)] + data_1[((((ax0 * 1620) + (ax1 * 162)) + (ax2 * 18)) + ax3)]);\n        }\n      }\n    }\n  }\n}\n\n",
        "cuda_code": "extern \"C\" __global__ void __launch_bounds__(50) default_function_kernel(float* __restrict__ T_add, float* __restrict__ data, float* __restrict__ data_1) {\n  T_add[((((int)blockIdx.x) * 50) + ((int)threadIdx.x))] = (data[((((int)blockIdx.x) * 50) + ((int)threadIdx.x))] + data_1[((((int)blockIdx.x) * 50) + ((int)threadIdx.x))]);\n}\n\n",
        "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((20, 10, 9, 18), \"float32\"), data_1: T.Buffer((20, 10, 9, 18), \"float32\"), T_add: T.Buffer((20, 10, 9, 18), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0 in T.parallel(20):\n            for ax1, ax2, ax3 in T.grid(10, 9, 18):\n                cse_var_1: T.int32 = ax0 * 1620 + ax1 * 162 + ax2 * 18 + ax3\n                T_add_1 = T.Buffer((32400,), data=T_add.data)\n                data_2 = T.Buffer((32400,), data=data.data)\n                data_3 = T.Buffer((32400,), data=data_1.data)\n                T_add_1[cse_var_1] = data_2[cse_var_1] + data_3[cse_var_1]",
        "op_args": [
            20,
            10,
            9,
            18
        ],
        "input_shape": [
            [
                20,
                10,
                9,
                18
            ],
            [
                20,
                10,
                9,
                18
            ]
        ],
        "output_shape": [
            [
                20,
                10,
                9,
                18
            ]
        ]
    },
    {
        "op_name": "adaptive_pool_avg",
        "c_code": "void default_function_kernel(float* adaptive_pool_avg, float* data) {\n  #pragma omp parallel for\n  for (int32_t ax0_ax1_fused = 0; ax0_ax1_fused < 195; ++ax0_ax1_fused) {\n    float adaptive_pool_sum[8];\n    for (int32_t ax2 = 0; ax2 < 8; ++ax2) {\n      for (int32_t ax3 = 0; ax3 < 8; ++ax3) {\n        adaptive_pool_sum[ax3] = 0.000000e+00f;\n        for (int32_t rv0 = 0; rv0 < ((((ax2 + 1) % 8) == 0) ? ((ax2 + 1) >> 3) : (((ax2 + 1) >> 3) + 1)); ++rv0) {\n          for (int32_t rv1 = 0; rv1 < ((((((ax3 * 2) + 2) % 8) == 0) ? ((ax3 + 1) >> 2) : (((ax3 + 1) >> 2) + 1)) - (ax3 >> 2)); ++rv1) {\n            adaptive_pool_sum[ax3] = (adaptive_pool_sum[ax3] + data[((((ax0_ax1_fused * 2) + (rv0 * 2)) + (ax3 >> 2)) + rv1)]);\n          }\n        }\n      }\n      for (int32_t ax3_1 = 0; ax3_1 < 8; ++ax3_1) {\n        adaptive_pool_avg[(((ax0_ax1_fused * 64) + (ax2 * 8)) + ax3_1)] = (adaptive_pool_sum[ax3_1] / (((float)((((ax2 + 1) % 8) == 0) ? ((ax2 + 1) >> 3) : (((ax2 + 1) >> 3) + 1))) * ((float)((((((ax3_1 * 2) + 2) % 8) == 0) ? ((ax3_1 + 1) >> 2) : (((ax3_1 + 1) >> 2) + 1)) - (ax3_1 >> 2)))));\n      }\n    }\n  }\n}\n\n",
        "cuda_code": "extern \"C\" __global__ void __launch_bounds__(48) default_function_kernel_1(float* __restrict__ adaptive_pool_avg, float* __restrict__ adaptive_pool_sum) {\n  adaptive_pool_avg[((((int)blockIdx.x) * 48) + ((int)threadIdx.x))] = (adaptive_pool_sum[((((int)blockIdx.x) * 48) + ((int)threadIdx.x))] / (((float)(((((((((int)blockIdx.x) * 6) + (((int)threadIdx.x) >> 3)) & 7) + 1) % 8) == 0) ? (((((((int)blockIdx.x) * 6) + (((int)threadIdx.x) >> 3)) & 7) + 1) >> 3) : ((((((((int)blockIdx.x) * 6) + (((int)threadIdx.x) >> 3)) & 7) + 1) >> 3) + 1))) * ((float)(((((((((int)threadIdx.x) & 7) * 2) + 2) % 8) == 0) ? (((((int)threadIdx.x) & 7) + 1) >> 2) : ((((((int)threadIdx.x) & 7) + 1) >> 2) + 1)) - ((((int)threadIdx.x) & 7) >> 2)))));\n}\n\nextern \"C\" __global__ void __launch_bounds__(32) default_function_kernel(float* __restrict__ adaptive_pool_sum, float* __restrict__ data) {\n  adaptive_pool_sum[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] = 0.000000e+00f;\n  for (int rv0 = 0; rv0 < (((((((((int)blockIdx.x) & 1) * 4) + (((int)threadIdx.x) >> 3)) + 1) % 8) == 0) ? ((((((int)threadIdx.x) + 8) >> 5) + (((int)blockIdx.x) & 1)) >> 1) : (((((((int)threadIdx.x) + 8) >> 5) + (((int)blockIdx.x) & 1)) >> 1) + 1)); ++rv0) {\n    for (int rv1 = 0; rv1 < (((((((((int)threadIdx.x) & 7) * 2) + 2) % 8) == 0) ? (((((int)threadIdx.x) & 7) + 1) >> 2) : ((((((int)threadIdx.x) & 7) + 1) >> 2) + 1)) - ((((int)threadIdx.x) & 7) >> 2)); ++rv1) {\n      adaptive_pool_sum[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] = (adaptive_pool_sum[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] + data[(((((((int)blockIdx.x) >> 1) * 2) + (rv0 * 2)) + ((((int)threadIdx.x) & 7) >> 2)) + rv1)]);\n    }\n  }\n}\n\n",
        "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((15, 13, 1, 2), \"float32\"), adaptive_pool_avg: T.Buffer((15, 13, 8, 8), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0_ax1_fused in T.parallel(195):\n            adaptive_pool_sum = T.allocate([8], \"float32\", \"global\")\n            for ax2 in range(8):\n                adaptive_pool_sum_1 = T.Buffer((8,), data=adaptive_pool_sum, align=32)\n                for ax3 in range(8):\n                    adaptive_pool_sum_1[ax3] = T.float32(0)\n                    for rv0, rv1 in T.grid(T.Let(T.Select((ax2 + 1) % 8 == 0, cse_var_1, cse_var_1 + 1), where={cse_var_1: (ax2 + 1) // 8}), T.Let(T.Select((ax3 * 2 + 2) % 8 == 0, cse_var_2, cse_var_2 + 1) - ax3 // 4, where={cse_var_2: (ax3 + 1) // 4})):\n                        cse_var_1 = T.int32()\n                        cse_var_2 = T.int32()\n                        data_1 = T.Buffer((390,), data=data.data)\n                        adaptive_pool_sum_1[ax3] = adaptive_pool_sum_1[ax3] + data_1[ax0_ax1_fused * 2 + rv0 * 2 + ax3 // 4 + rv1]\n                for ax3 in range(8):\n                    cse_var_5: T.int32 = ax2 + 1\n                    cse_var_4: T.int32 = cse_var_5 // 8\n                    cse_var_3: T.int32 = (ax3 + 1) // 4\n                    adaptive_pool_avg_1 = T.Buffer((12480,), data=adaptive_pool_avg.data)\n                    adaptive_pool_avg_1[ax0_ax1_fused * 64 + ax2 * 8 + ax3] = adaptive_pool_sum_1[ax3] / (T.Cast(\"float32\", T.Select(cse_var_5 % 8 == 0, cse_var_4, cse_var_4 + 1)) * T.Cast(\"float32\", T.Select((ax3 * 2 + 2) % 8 == 0, cse_var_3, cse_var_3 + 1) - ax3 // 4))",
        "op_args": [
            15,
            13,
            1,
            2
        ],
        "input_shape": [
            [
                15,
                13,
                1,
                2
            ]
        ],
        "output_shape": [
            [
                15,
                13,
                8,
                8
            ]
        ]
    },
    {
        "op_name": "sum",
        "c_code": "void default_function_kernel(float* data, float* data_red) {\n  float data_red_rf[27];\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_inner_init = 0; k0_k1_fused_k2_fused_k3_fused_inner_init < 27; ++k0_k1_fused_k2_fused_k3_fused_inner_init) {\n    data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner_init] = 0.000000e+00f;\n  }\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_outer = 0; k0_k1_fused_k2_fused_k3_fused_outer < 2210; ++k0_k1_fused_k2_fused_k3_fused_outer) {\n    for (int32_t k0_k1_fused_k2_fused_k3_fused_inner = 0; k0_k1_fused_k2_fused_k3_fused_inner < 27; ++k0_k1_fused_k2_fused_k3_fused_inner) {\n      data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner] = (data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner] + data[((k0_k1_fused_k2_fused_k3_fused_outer * 27) + k0_k1_fused_k2_fused_k3_fused_inner)]);\n    }\n  }\n  data_red[0] = 0.000000e+00f;\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_inner_v = 0; k0_k1_fused_k2_fused_k3_fused_inner_v < 27; ++k0_k1_fused_k2_fused_k3_fused_inner_v) {\n    data_red[0] = (data_red[0] + data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner_v]);\n  }\n}\n\n",
        "cuda_code": "extern \"C\" __global__ void __launch_bounds__(32) default_function_kernel(float* __restrict__ data, float* __restrict__ data_red) {\n  float normal_reduce_temp0[1];\n  float red_buf0[1];\n  normal_reduce_temp0[0] = 0.000000e+00f;\n  for (int k0_k1_fused_k2_fused_k3_fused_outer = 0; k0_k1_fused_k2_fused_k3_fused_outer < 1865; ++k0_k1_fused_k2_fused_k3_fused_outer) {\n    if (((k0_k1_fused_k2_fused_k3_fused_outer * 16) + (((int)threadIdx.x) >> 1)) < 29835) {\n      normal_reduce_temp0[0] = (normal_reduce_temp0[0] + data[((k0_k1_fused_k2_fused_k3_fused_outer * 32) + ((int)threadIdx.x))]);\n    }\n  }\n  uint mask[1];\n  float t0[1];\n  red_buf0[0] = normal_reduce_temp0[0];\n  mask[0] = __activemask();\n  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 16, 32);\n  red_buf0[0] = (red_buf0[0] + t0[0]);\n  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 8, 32);\n  red_buf0[0] = (red_buf0[0] + t0[0]);\n  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 4, 32);\n  red_buf0[0] = (red_buf0[0] + t0[0]);\n  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 2, 32);\n  red_buf0[0] = (red_buf0[0] + t0[0]);\n  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 1, 32);\n  red_buf0[0] = (red_buf0[0] + t0[0]);\n  red_buf0[0] = __shfl_sync(mask[0], red_buf0[0], 0, 32);\n  if (((int)threadIdx.x) == 0) {\n    data_red[0] = red_buf0[0];\n  }\n}\n\n",
        "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((13, 15, 18, 17), \"float32\"), data_red: T.Buffer((), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        data_red_rf = T.allocate([27], \"float32\", \"global\")\n        data_red_rf_1 = T.Buffer((27,), data=data_red_rf)\n        for k0_k1_fused_k2_fused_k3_fused_inner_init in range(27):\n            data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner_init] = T.float32(0)\n        for k0_k1_fused_k2_fused_k3_fused_outer, k0_k1_fused_k2_fused_k3_fused_inner in T.grid(2210, 27):\n            data_1 = T.Buffer((59670,), data=data.data)\n            data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner] = data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner] + data_1[k0_k1_fused_k2_fused_k3_fused_outer * 27 + k0_k1_fused_k2_fused_k3_fused_inner]\n        data_red_1 = T.Buffer((1,), data=data_red.data)\n        data_red_1[0] = T.float32(0)\n        for k0_k1_fused_k2_fused_k3_fused_inner_v in range(27):\n            data_red_1[0] = data_red_1[0] + data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner_v]",
        "op_args": [
            13,
            15,
            18,
            17
        ],
        "input_shape": [
            [
                13,
                15,
                18,
                17
            ]
        ],
        "output_shape": [
            []
        ]
    },
    {
        "op_name": "fast_softmax",
        "c_code": "void default_function_kernel(float* T_softmax_norm, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused = 0; i0_i1_fused < 260; ++i0_i1_fused) {\n    float T_softmax_maxelem[1];\n    float T_softmax_expsum[1];\n    for (int32_t i2 = 0; i2 < 3; ++i2) {\n      T_softmax_maxelem[0] = -3.402823e+38f;\n      for (int32_t k = 0; k < 15; ++k) {\n        T_softmax_maxelem[0] = max(T_softmax_maxelem[0], data[(((i0_i1_fused * 45) + (i2 * 15)) + k)]);\n      }\n      T_softmax_expsum[0] = 0.000000e+00f;\n      for (int32_t k_1 = 0; k_1 < 15; ++k_1) {\n          int32_t v_ = ((int32_t)(floorf(((max(min((data[(((i0_i1_fused * 45) + (i2 * 15)) + k_1)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) + 1.270000e+02f)) << 23;\n        T_softmax_expsum[0] = (T_softmax_expsum[0] + max(((*(float *)(&(v_))) * ((((((((((((((1.987569e-04f * (max(min((data[(((i0_i1_fused * 45) + (i2 * 15)) + k_1)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((i0_i1_fused * 45) + (i2 * 15)) + k_1)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.398200e-03f) * (max(min((data[(((i0_i1_fused * 45) + (i2 * 15)) + k_1)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((i0_i1_fused * 45) + (i2 * 15)) + k_1)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 8.333452e-03f) * (max(min((data[(((i0_i1_fused * 45) + (i2 * 15)) + k_1)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((i0_i1_fused * 45) + (i2 * 15)) + k_1)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 4.166580e-02f) * (max(min((data[(((i0_i1_fused * 45) + (i2 * 15)) + k_1)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((i0_i1_fused * 45) + (i2 * 15)) + k_1)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.666667e-01f) * (max(min((data[(((i0_i1_fused * 45) + (i2 * 15)) + k_1)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((i0_i1_fused * 45) + (i2 * 15)) + k_1)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 5.000000e-01f) * (max(min((data[(((i0_i1_fused * 45) + (i2 * 15)) + k_1)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((i0_i1_fused * 45) + (i2 * 15)) + k_1)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) * (max(min((data[(((i0_i1_fused * 45) + (i2 * 15)) + k_1)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((i0_i1_fused * 45) + (i2 * 15)) + k_1)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + (max(min((data[(((i0_i1_fused * 45) + (i2 * 15)) + k_1)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((i0_i1_fused * 45) + (i2 * 15)) + k_1)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.000000e+00f)), (data[(((i0_i1_fused * 45) + (i2 * 15)) + k_1)] - T_softmax_maxelem[0])));\n      }\n      for (int32_t i3_s = 0; i3_s < 15; ++i3_s) {\n          int32_t v__1 = ((int32_t)(floorf(((max(min((data[(((i0_i1_fused * 45) + (i2 * 15)) + i3_s)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) + 1.270000e+02f)) << 23;\n        T_softmax_norm[(((i0_i1_fused * 45) + (i2 * 15)) + i3_s)] = (max(((*(float *)(&(v__1))) * ((((((((((((((1.987569e-04f * (max(min((data[(((i0_i1_fused * 45) + (i2 * 15)) + i3_s)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((i0_i1_fused * 45) + (i2 * 15)) + i3_s)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.398200e-03f) * (max(min((data[(((i0_i1_fused * 45) + (i2 * 15)) + i3_s)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((i0_i1_fused * 45) + (i2 * 15)) + i3_s)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 8.333452e-03f) * (max(min((data[(((i0_i1_fused * 45) + (i2 * 15)) + i3_s)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((i0_i1_fused * 45) + (i2 * 15)) + i3_s)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 4.166580e-02f) * (max(min((data[(((i0_i1_fused * 45) + (i2 * 15)) + i3_s)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((i0_i1_fused * 45) + (i2 * 15)) + i3_s)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.666667e-01f) * (max(min((data[(((i0_i1_fused * 45) + (i2 * 15)) + i3_s)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((i0_i1_fused * 45) + (i2 * 15)) + i3_s)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 5.000000e-01f) * (max(min((data[(((i0_i1_fused * 45) + (i2 * 15)) + i3_s)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((i0_i1_fused * 45) + (i2 * 15)) + i3_s)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) * (max(min((data[(((i0_i1_fused * 45) + (i2 * 15)) + i3_s)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((i0_i1_fused * 45) + (i2 * 15)) + i3_s)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + (max(min((data[(((i0_i1_fused * 45) + (i2 * 15)) + i3_s)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((i0_i1_fused * 45) + (i2 * 15)) + i3_s)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.000000e+00f)), (data[(((i0_i1_fused * 45) + (i2 * 15)) + i3_s)] - T_softmax_maxelem[0])) / T_softmax_expsum[0]);\n      }\n    }\n  }\n}\n\n",
        "cuda_code": "extern \"C\" __global__ void __launch_bounds__(32) default_function_kernel_1(float* __restrict__ T_softmax_expsum, float* __restrict__ T_softmax_maxelem, float* __restrict__ data) {\n  if (((((int)blockIdx.x) * 8) + (((int)threadIdx.x) >> 2)) < 195) {\n    T_softmax_expsum[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] = 0.000000e+00f;\n  }\n  for (int k = 0; k < 15; ++k) {\n    if (((((int)blockIdx.x) * 8) + (((int)threadIdx.x) >> 2)) < 195) {\n        int v_ = ((int)(floorf(((max(min((data[(((((int)blockIdx.x) * 480) + (((int)threadIdx.x) * 15)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) + 1.270000e+02f)) << 23;\n      T_softmax_expsum[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] = (T_softmax_expsum[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] + max(((*(float *)(&(v_))) * ((((((((((((((1.987569e-04f * (max(min((data[(((((int)blockIdx.x) * 480) + (((int)threadIdx.x) * 15)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((((int)blockIdx.x) * 480) + (((int)threadIdx.x) * 15)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.398200e-03f) * (max(min((data[(((((int)blockIdx.x) * 480) + (((int)threadIdx.x) * 15)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((((int)blockIdx.x) * 480) + (((int)threadIdx.x) * 15)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 8.333452e-03f) * (max(min((data[(((((int)blockIdx.x) * 480) + (((int)threadIdx.x) * 15)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((((int)blockIdx.x) * 480) + (((int)threadIdx.x) * 15)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 4.166580e-02f) * (max(min((data[(((((int)blockIdx.x) * 480) + (((int)threadIdx.x) * 15)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((((int)blockIdx.x) * 480) + (((int)threadIdx.x) * 15)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.666667e-01f) * (max(min((data[(((((int)blockIdx.x) * 480) + (((int)threadIdx.x) * 15)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((((int)blockIdx.x) * 480) + (((int)threadIdx.x) * 15)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 5.000000e-01f) * (max(min((data[(((((int)blockIdx.x) * 480) + (((int)threadIdx.x) * 15)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((((int)blockIdx.x) * 480) + (((int)threadIdx.x) * 15)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) * (max(min((data[(((((int)blockIdx.x) * 480) + (((int)threadIdx.x) * 15)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((((int)blockIdx.x) * 480) + (((int)threadIdx.x) * 15)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + (max(min((data[(((((int)blockIdx.x) * 480) + (((int)threadIdx.x) * 15)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((((int)blockIdx.x) * 480) + (((int)threadIdx.x) * 15)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.000000e+00f)), (data[(((((int)blockIdx.x) * 480) + (((int)threadIdx.x) * 15)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))])));\n    }\n  }\n}\n\nextern \"C\" __global__ void __launch_bounds__(52) default_function_kernel_2(float* __restrict__ T_softmax_expsum, float* __restrict__ T_softmax_maxelem, float* __restrict__ T_softmax_norm, float* __restrict__ data) {\n    int v_ = ((int)(floorf(((max(min((data[((((int)blockIdx.x) * 52) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 52) + ((int)threadIdx.x)) / 15)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) + 1.270000e+02f)) << 23;\n  T_softmax_norm[((((int)blockIdx.x) * 52) + ((int)threadIdx.x))] = (max(((*(float *)(&(v_))) * ((((((((((((((1.987569e-04f * (max(min((data[((((int)blockIdx.x) * 52) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 52) + ((int)threadIdx.x)) / 15)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)blockIdx.x) * 52) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 52) + ((int)threadIdx.x)) / 15)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.398200e-03f) * (max(min((data[((((int)blockIdx.x) * 52) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 52) + ((int)threadIdx.x)) / 15)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)blockIdx.x) * 52) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 52) + ((int)threadIdx.x)) / 15)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 8.333452e-03f) * (max(min((data[((((int)blockIdx.x) * 52) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 52) + ((int)threadIdx.x)) / 15)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)blockIdx.x) * 52) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 52) + ((int)threadIdx.x)) / 15)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 4.166580e-02f) * (max(min((data[((((int)blockIdx.x) * 52) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 52) + ((int)threadIdx.x)) / 15)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)blockIdx.x) * 52) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 52) + ((int)threadIdx.x)) / 15)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.666667e-01f) * (max(min((data[((((int)blockIdx.x) * 52) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 52) + ((int)threadIdx.x)) / 15)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)blockIdx.x) * 52) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 52) + ((int)threadIdx.x)) / 15)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 5.000000e-01f) * (max(min((data[((((int)blockIdx.x) * 52) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 52) + ((int)threadIdx.x)) / 15)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)blockIdx.x) * 52) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 52) + ((int)threadIdx.x)) / 15)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) * (max(min((data[((((int)blockIdx.x) * 52) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 52) + ((int)threadIdx.x)) / 15)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)blockIdx.x) * 52) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 52) + ((int)threadIdx.x)) / 15)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + (max(min((data[((((int)blockIdx.x) * 52) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 52) + ((int)threadIdx.x)) / 15)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)blockIdx.x) * 52) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 52) + ((int)threadIdx.x)) / 15)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.000000e+00f)), (data[((((int)blockIdx.x) * 52) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 52) + ((int)threadIdx.x)) / 15)])) / T_softmax_expsum[(((((int)blockIdx.x) * 52) + ((int)threadIdx.x)) / 15)]);\n}\n\nextern \"C\" __global__ void __launch_bounds__(64) default_function_kernel(float* __restrict__ T_softmax_maxelem, float* __restrict__ data) {\n  if (((((int)blockIdx.x) * 16) + (((int)threadIdx.x) >> 2)) < 195) {\n    T_softmax_maxelem[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))] = -3.402823e+38f;\n  }\n  for (int k = 0; k < 15; ++k) {\n    if (((((int)blockIdx.x) * 16) + (((int)threadIdx.x) >> 2)) < 195) {\n      T_softmax_maxelem[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))] = max(T_softmax_maxelem[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))], data[(((((int)blockIdx.x) * 960) + (((int)threadIdx.x) * 15)) + k)]);\n    }\n  }\n}\n\n",
        "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((13, 20, 3, 15), \"float32\"), T_softmax_norm: T.Buffer((13, 20, 3, 15), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused in T.parallel(260):\n            T_softmax_maxelem = T.allocate([1], \"float32\", \"global\")\n            T_softmax_expsum = T.allocate([1], \"float32\", \"global\")\n            for i2 in range(3):\n                T_softmax_maxelem_1 = T.Buffer((1,), data=T_softmax_maxelem, align=4)\n                T_softmax_maxelem_1[0] = T.float32(-3.4028234663852886e+38)\n                data_1 = T.Buffer((11700,), data=data.data)\n                for k in range(15):\n                    T_softmax_maxelem_1[0] = T.max(T_softmax_maxelem_1[0], data_1[i0_i1_fused * 45 + i2 * 15 + k])\n                T_softmax_expsum_1 = T.Buffer((1,), data=T_softmax_expsum, align=4)\n                T_softmax_expsum_1[0] = T.float32(0)\n                for k in range(15):\n                    cse_var_1: T.int32 = i0_i1_fused * 45 + i2 * 15 + k\n                    T_softmax_expsum_1[0] = T_softmax_expsum_1[0] + T.max(T.reinterpret(\"float32\", T.shift_left(T.Cast(\"int32\", T.floor(T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) + T.float32(127)), 23)) * ((((((T.float32(0.00019875691214110702) * (T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.0013981999363750219)) * (T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.008333452045917511)) * (T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.041665796190500259)) * (T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.1666666567325592)) * (T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.5)) * (T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) * (T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + (T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(1)), data_1[cse_var_1] - T_softmax_maxelem_1[0])\n                for i3_s in range(15):\n                    cse_var_2: T.int32 = i0_i1_fused * 45 + i2 * 15 + i3_s\n                    T_softmax_norm_1 = T.Buffer((11700,), data=T_softmax_norm.data)\n                    T_softmax_norm_1[cse_var_2] = T.max(T.reinterpret(\"float32\", T.shift_left(T.Cast(\"int32\", T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) + T.float32(127)), 23)) * ((((((T.float32(0.00019875691214110702) * (T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.0013981999363750219)) * (T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.008333452045917511)) * (T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.041665796190500259)) * (T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.1666666567325592)) * (T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.5)) * (T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) * (T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + (T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(1)), data_1[cse_var_2] - T_softmax_maxelem_1[0]) / T_softmax_expsum_1[0]",
        "op_args": [
            13,
            20,
            3,
            15
        ],
        "input_shape": [
            [
                13,
                20,
                3,
                15
            ]
        ],
        "output_shape": [
            [
                13,
                20,
                3,
                15
            ]
        ]
    },
    {
        "op_name": "acos",
        "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused_i3_fused = 0; i0_i1_fused_i2_fused_i3_fused < 1496; ++i0_i1_fused_i2_fused_i3_fused) {\n    compute[i0_i1_fused_i2_fused_i3_fused] = acosf(data[i0_i1_fused_i2_fused_i3_fused]);\n  }\n}\n\n",
        "cuda_code": "extern \"C\" __global__ void __launch_bounds__(17) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 17) + ((int)threadIdx.x))] = acosf(data[((((int)blockIdx.x) * 17) + ((int)threadIdx.x))]);\n}\n\n",
        "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((8, 17, 1, 11), \"float32\"), compute: T.Buffer((8, 17, 1, 11), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused_i2_fused_i3_fused in T.parallel(1496):\n            compute_1 = T.Buffer((1496,), data=compute.data)\n            data_1 = T.Buffer((1496,), data=data.data)\n            compute_1[i0_i1_fused_i2_fused_i3_fused] = T.acos(data_1[i0_i1_fused_i2_fused_i3_fused])",
        "op_args": [
            8,
            17,
            1,
            11
        ],
        "input_shape": [
            [
                8,
                17,
                1,
                11
            ]
        ],
        "output_shape": [
            [
                8,
                17,
                1,
                11
            ]
        ]
    },
    {
        "op_name": "asin",
        "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0 = 0; i0 < 9; ++i0) {\n    for (int32_t i1 = 0; i1 < 11; ++i1) {\n      for (int32_t i2 = 0; i2 < 11; ++i2) {\n        for (int32_t i3_s = 0; i3_s < 7; ++i3_s) {\n          compute[((((i0 * 847) + (i1 * 77)) + (i2 * 7)) + i3_s)] = asinf(data[((((i0 * 847) + (i1 * 77)) + (i2 * 7)) + i3_s)]);\n        }\n      }\n    }\n  }\n}\n\n",
        "cuda_code": "extern \"C\" __global__ void __launch_bounds__(32) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  if (((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) < 7623) {\n    compute[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] = asinf(data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))]);\n  }\n}\n\n",
        "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((9, 11, 11, 7), \"float32\"), compute: T.Buffer((9, 11, 11, 7), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0 in T.parallel(9):\n            for i1, i2, i3_s in T.grid(11, 11, 7):\n                cse_var_1: T.int32 = i0 * 847 + i1 * 77 + i2 * 7 + i3_s\n                compute_1 = T.Buffer((7623,), data=compute.data)\n                data_1 = T.Buffer((7623,), data=data.data)\n                compute_1[cse_var_1] = T.asin(data_1[cse_var_1])",
        "op_args": [
            9,
            11,
            11,
            7
        ],
        "input_shape": [
            [
                9,
                11,
                11,
                7
            ]
        ],
        "output_shape": [
            [
                9,
                11,
                11,
                7
            ]
        ]
    },
    {
        "op_name": "batch_to_space_nd",
        "c_code": "void default_function_kernel(float* T_strided_slice, float* data) {\n  #pragma omp parallel for\n  for (int32_t ax0 = 0; ax0 < 3; ++ax0) {\n    float T_transpose[3040];\n    float T_reshape[80];\n    for (int32_t ax1 = 0; ax1 < 19; ++ax1) {\n      for (int32_t ax2 = 0; ax2 < 2; ++ax2) {\n        for (int32_t ax1_1 = 0; ax1_1 < 2; ++ax1_1) {\n          for (int32_t ax4 = 0; ax4 < 2; ++ax4) {\n            for (int32_t ax5 = 0; ax5 < 20; ++ax5) {\n              T_reshape[(((ax1_1 * 40) + (ax4 * 20)) + ax5)] = data[((((((ax2 * 4560) + (ax1_1 * 2280)) + (ax0 * 760)) + (ax1 * 40)) + (ax4 * 20)) + ax5)];\n            }\n          }\n        }\n        for (int32_t ax3 = 0; ax3 < 2; ++ax3) {\n          for (int32_t ax4_1 = 0; ax4_1 < 2; ++ax4_1) {\n            for (int32_t ax5_1 = 0; ax5_1 < 20; ++ax5_1) {\n              T_transpose[(((((ax1 * 160) + (ax2 * 80)) + (ax3 * 40)) + (ax4_1 * 20)) + ax5_1)] = T_reshape[(((ax4_1 * 40) + (ax3 * 20)) + ax5_1)];\n            }\n          }\n        }\n      }\n    }\n    for (int32_t ax1_2 = 0; ax1_2 < 38; ++ax1_2) {\n      for (int32_t ax2_1 = 0; ax2_1 < 4; ++ax2_1) {\n        for (int32_t ax3_1 = 0; ax3_1 < 20; ++ax3_1) {\n          T_strided_slice[((((ax0 * 3040) + (ax1_2 * 80)) + (ax2_1 * 20)) + ax3_1)] = T_transpose[(((ax1_2 * 80) + (ax2_1 * 20)) + ax3_1)];\n        }\n      }\n    }\n  }\n}\n\n",
        "cuda_code": "extern \"C\" __global__ void __launch_bounds__(24) default_function_kernel(float* __restrict__ T_strided_slice, float* __restrict__ data) {\n  T_strided_slice[((((int)blockIdx.x) * 24) + ((int)threadIdx.x))] = data[(((((((((((int)blockIdx.x) * 3) + (((int)threadIdx.x) >> 3)) % 20) / 10) * 4560) + (((((((int)blockIdx.x) * 6) + (((int)threadIdx.x) >> 2)) % 10) / 5) * 2280)) + ((((((int)blockIdx.x) * 3) + (((int)threadIdx.x) >> 3)) / 20) * 40)) + (((((((int)blockIdx.x) * 3) + (((int)threadIdx.x) >> 3)) % 10) / 5) * 20)) + (((((int)blockIdx.x) * 4) + ((int)threadIdx.x)) % 20))];\n}\n\n",
        "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((15, 19, 2, 20), \"float32\"), T_strided_slice: T.Buffer((3, 38, 4, 20), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0 in T.parallel(3):\n            T_transpose = T.allocate([3040], \"float32\", \"global\")\n            T_reshape = T.allocate([80], \"float32\", \"global\")\n            for ax1, ax2 in T.grid(19, 2):\n                T_reshape_1 = T.Buffer((80,), data=T_reshape)\n                for ax1_1, ax4, ax5 in T.grid(2, 2, 20):\n                    cse_var_1: T.int32 = ax4 * 20\n                    data_1 = T.Buffer((11400,), data=data.data)\n                    T_reshape_1[ax1_1 * 40 + cse_var_1 + ax5] = data_1[ax2 * 4560 + ax1_1 * 2280 + ax0 * 760 + ax1 * 40 + cse_var_1 + ax5]\n                for ax3, ax4, ax5 in T.grid(2, 2, 20):\n                    T_transpose_1 = T.Buffer((3040,), data=T_transpose)\n                    T_transpose_1[ax1 * 160 + ax2 * 80 + ax3 * 40 + ax4 * 20 + ax5] = T_reshape_1[ax4 * 40 + ax3 * 20 + ax5]\n            for ax1, ax2, ax3 in T.grid(38, 4, 20):\n                cse_var_3: T.int32 = ax1 * 80\n                cse_var_2: T.int32 = ax2 * 20\n                T_strided_slice_1 = T.Buffer((9120,), data=T_strided_slice.data)\n                T_transpose_1 = T.Buffer((3040,), data=T_transpose)\n                T_strided_slice_1[ax0 * 3040 + cse_var_3 + cse_var_2 + ax3] = T_transpose_1[cse_var_3 + cse_var_2 + ax3]",
        "op_args": [
            15,
            19,
            2,
            20
        ],
        "input_shape": [
            [
                15,
                19,
                2,
                20
            ]
        ],
        "output_shape": [
            [
                3,
                38,
                4,
                20
            ]
        ]
    },
    {
        "op_name": "global_pool_max",
        "c_code": "void default_function_kernel(float* adaptive_pool_max, float* data) {\n  #pragma omp parallel for\n  for (int32_t ax0_ax1_fused = 0; ax0_ax1_fused < 22; ++ax0_ax1_fused) {\n    adaptive_pool_max[ax0_ax1_fused] = -3.402823e+38f;\n    for (int32_t rv0 = 0; rv0 < 4; ++rv0) {\n      adaptive_pool_max[ax0_ax1_fused] = max(adaptive_pool_max[ax0_ax1_fused], data[((ax0_ax1_fused * 4) + rv0)]);\n    }\n  }\n}\n\n",
        "cuda_code": "extern \"C\" __global__ void __launch_bounds__(22) default_function_kernel(float* __restrict__ adaptive_pool_max, float* __restrict__ data) {\n  adaptive_pool_max[((int)threadIdx.x)] = -3.402823e+38f;\n  for (int rv0 = 0; rv0 < 4; ++rv0) {\n    adaptive_pool_max[((int)threadIdx.x)] = max(adaptive_pool_max[((int)threadIdx.x)], data[((((int)threadIdx.x) * 4) + rv0)]);\n  }\n}\n\n",
        "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((11, 2, 4, 1), \"float32\"), adaptive_pool_max: T.Buffer((11, 2, 1, 1), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0_ax1_fused in T.parallel(22):\n            adaptive_pool_max_1 = T.Buffer((22,), data=adaptive_pool_max.data)\n            adaptive_pool_max_1[ax0_ax1_fused] = T.float32(-3.4028234663852886e+38)\n            for rv0 in range(4):\n                data_1 = T.Buffer((88,), data=data.data)\n                adaptive_pool_max_1[ax0_ax1_fused] = T.max(adaptive_pool_max_1[ax0_ax1_fused], data_1[ax0_ax1_fused * 4 + rv0])",
        "op_args": [
            11,
            2,
            4,
            1
        ],
        "input_shape": [
            [
                11,
                2,
                4,
                1
            ]
        ],
        "output_shape": [
            [
                11,
                2,
                1,
                1
            ]
        ]
    },
    {
        "op_name": "asinh",
        "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused = 0; i0_i1_fused_i2_fused < 240; ++i0_i1_fused_i2_fused) {\n    for (int32_t i3 = 0; i3 < 19; ++i3) {\n      compute[((i0_i1_fused_i2_fused * 19) + i3)] = asinhf(data[((i0_i1_fused_i2_fused * 19) + i3)]);\n    }\n  }\n}\n\n",
        "cuda_code": "extern \"C\" __global__ void __launch_bounds__(20) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 20) + ((int)threadIdx.x))] = asinhf(data[((((int)blockIdx.x) * 20) + ((int)threadIdx.x))]);\n}\n\n",
        "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((4, 4, 15, 19), \"float32\"), compute: T.Buffer((4, 4, 15, 19), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused_i2_fused in T.parallel(240):\n            for i3 in range(19):\n                cse_var_1: T.int32 = i0_i1_fused_i2_fused * 19 + i3\n                compute_1 = T.Buffer((4560,), data=compute.data)\n                data_1 = T.Buffer((4560,), data=data.data)\n                compute_1[cse_var_1] = T.asinh(data_1[cse_var_1])",
        "op_args": [
            4,
            4,
            15,
            19
        ],
        "input_shape": [
            [
                4,
                4,
                15,
                19
            ]
        ],
        "output_shape": [
            [
                4,
                4,
                15,
                19
            ]
        ]
    },
    {
        "op_name": "global_pool_avg",
        "c_code": "void default_function_kernel(float* adaptive_pool_avg, float* data) {\n  #pragma omp parallel for\n  for (int32_t ax0 = 0; ax0 < 5; ++ax0) {\n    float adaptive_pool_sum[1];\n    for (int32_t ax1 = 0; ax1 < 8; ++ax1) {\n      adaptive_pool_sum[0] = 0.000000e+00f;\n      for (int32_t rv0 = 0; rv0 < 15; ++rv0) {\n        for (int32_t rv1 = 0; rv1 < 15; ++rv1) {\n          adaptive_pool_sum[0] = (adaptive_pool_sum[0] + data[((((ax0 * 1800) + (ax1 * 225)) + (rv0 * 15)) + rv1)]);\n        }\n      }\n      adaptive_pool_avg[((ax0 * 8) + ax1)] = (adaptive_pool_sum[0] * 4.444444e-03f);\n    }\n  }\n}\n\n",
        "cuda_code": "extern \"C\" __global__ void __launch_bounds__(20) default_function_kernel_1(float* __restrict__ adaptive_pool_avg, float* __restrict__ adaptive_pool_sum) {\n  adaptive_pool_avg[((((int)blockIdx.x) * 20) + ((int)threadIdx.x))] = (adaptive_pool_sum[((((int)blockIdx.x) * 20) + ((int)threadIdx.x))] * 4.444444e-03f);\n}\n\nextern \"C\" __global__ void __launch_bounds__(20) default_function_kernel(float* __restrict__ adaptive_pool_sum, float* __restrict__ data) {\n  adaptive_pool_sum[((((int)blockIdx.x) * 20) + ((int)threadIdx.x))] = 0.000000e+00f;\n  for (int rv0 = 0; rv0 < 15; ++rv0) {\n    for (int rv1 = 0; rv1 < 15; ++rv1) {\n      adaptive_pool_sum[((((int)blockIdx.x) * 20) + ((int)threadIdx.x))] = (adaptive_pool_sum[((((int)blockIdx.x) * 20) + ((int)threadIdx.x))] + data[((((((int)blockIdx.x) * 4500) + (((int)threadIdx.x) * 225)) + (rv0 * 15)) + rv1)]);\n    }\n  }\n}\n\n",
        "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((5, 8, 15, 15), \"float32\"), adaptive_pool_avg: T.Buffer((5, 8, 1, 1), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0 in T.parallel(5):\n            adaptive_pool_sum = T.allocate([1], \"float32\", \"global\")\n            for ax1 in range(8):\n                adaptive_pool_sum_1 = T.Buffer((1,), data=adaptive_pool_sum, align=4)\n                adaptive_pool_sum_1[0] = T.float32(0)\n                for rv0, rv1 in T.grid(15, 15):\n                    data_1 = T.Buffer((9000,), data=data.data)\n                    adaptive_pool_sum_1[0] = adaptive_pool_sum_1[0] + data_1[ax0 * 1800 + ax1 * 225 + rv0 * 15 + rv1]\n                adaptive_pool_avg_1 = T.Buffer((40,), data=adaptive_pool_avg.data)\n                adaptive_pool_avg_1[ax0 * 8 + ax1] = adaptive_pool_sum_1[0] * T.float32(0.0044444444444444444)",
        "op_args": [
            5,
            8,
            15,
            15
        ],
        "input_shape": [
            [
                5,
                8,
                15,
                15
            ]
        ],
        "output_shape": [
            [
                5,
                8,
                1,
                1
            ]
        ]
    },
    {
        "op_name": "atanh",
        "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0 = 0; i0 < 18; ++i0) {\n    for (int32_t i1 = 0; i1 < 9; ++i1) {\n      for (int32_t i2 = 0; i2 < 3; ++i2) {\n        for (int32_t i3 = 0; i3 < 11; ++i3) {\n          compute[((((i0 * 297) + (i1 * 33)) + (i2 * 11)) + i3)] = atanhf(data[((((i0 * 297) + (i1 * 33)) + (i2 * 11)) + i3)]);\n        }\n      }\n    }\n  }\n}\n\n",
        "cuda_code": "extern \"C\" __global__ void __launch_bounds__(33) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 33) + ((int)threadIdx.x))] = atanhf(data[((((int)blockIdx.x) * 33) + ((int)threadIdx.x))]);\n}\n\n",
        "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((18, 9, 3, 11), \"float32\"), compute: T.Buffer((18, 9, 3, 11), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0 in T.parallel(18):\n            for i1, i2, i3 in T.grid(9, 3, 11):\n                cse_var_1: T.int32 = i0 * 297 + i1 * 33 + i2 * 11 + i3\n                compute_1 = T.Buffer((5346,), data=compute.data)\n                data_1 = T.Buffer((5346,), data=data.data)\n                compute_1[cse_var_1] = T.atanh(data_1[cse_var_1])",
        "op_args": [
            18,
            9,
            3,
            11
        ],
        "input_shape": [
            [
                18,
                9,
                3,
                11
            ]
        ],
        "output_shape": [
            [
                18,
                9,
                3,
                11
            ]
        ]
    },
    {
        "op_name": "dilate",
        "c_code": "void default_function_kernel(float* DilatedInput, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused_i3_fused = 0; i0_i1_fused_i2_fused_i3_fused < 2464; ++i0_i1_fused_i2_fused_i3_fused) {\n    DilatedInput[i0_i1_fused_i2_fused_i3_fused] = data[i0_i1_fused_i2_fused_i3_fused];\n  }\n}\n\n",
        "cuda_code": "extern \"C\" __global__ void __launch_bounds__(44) default_function_kernel(float* __restrict__ DilatedInput, float* __restrict__ data) {\n  DilatedInput[((((int)blockIdx.x) * 44) + ((int)threadIdx.x))] = data[((((int)blockIdx.x) * 44) + ((int)threadIdx.x))];\n}\n\n",
        "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((2, 11, 16, 7), \"float32\"), DilatedInput: T.Buffer((2, 11, 16, 7), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused_i2_fused_i3_fused in T.parallel(2464):\n            DilatedInput_1 = T.Buffer((2464,), data=DilatedInput.data)\n            data_1 = T.Buffer((2464,), data=data.data)\n            DilatedInput_1[i0_i1_fused_i2_fused_i3_fused] = data_1[i0_i1_fused_i2_fused_i3_fused]",
        "op_args": [
            2,
            11,
            16,
            7
        ],
        "input_shape": [
            [
                2,
                11,
                16,
                7
            ]
        ],
        "output_shape": [
            [
                2,
                11,
                16,
                7
            ]
        ]
    },
    {
        "op_name": "ceil",
        "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused = 0; i0_i1_fused < 88; ++i0_i1_fused) {\n    for (int32_t i3 = 0; i3 < 17; ++i3) {\n      compute[((i0_i1_fused * 17) + i3)] = ceilf(data[((i0_i1_fused * 17) + i3)]);\n    }\n  }\n}\n\n",
        "cuda_code": "extern \"C\" __global__ void __launch_bounds__(32) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  if (((((int)blockIdx.x) * 4) + (((int)threadIdx.x) >> 3)) < 187) {\n    compute[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] = ceilf(data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))]);\n  }\n}\n\n",
        "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((8, 11, 1, 17), \"float32\"), compute: T.Buffer((8, 11, 1, 17), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused in T.parallel(88):\n            for i3 in range(17):\n                cse_var_1: T.int32 = i0_i1_fused * 17 + i3\n                compute_1 = T.Buffer((1496,), data=compute.data)\n                data_1 = T.Buffer((1496,), data=data.data)\n                compute_1[cse_var_1] = T.ceil(data_1[cse_var_1])",
        "op_args": [
            8,
            11,
            1,
            17
        ],
        "input_shape": [
            [
                8,
                11,
                1,
                17
            ]
        ],
        "output_shape": [
            [
                8,
                11,
                1,
                17
            ]
        ]
    },
    {
        "op_name": "flatten",
        "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i = 0; i < 17; ++i) {\n    for (int32_t j = 0; j < 270; ++j) {\n      compute[((i * 270) + j)] = data[((i * 270) + j)];\n    }\n  }\n}\n\n",
        "cuda_code": "extern \"C\" __global__ void __launch_bounds__(30) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 30) + ((int)threadIdx.x))] = data[((((int)blockIdx.x) * 30) + ((int)threadIdx.x))];\n}\n\n",
        "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((17, 3, 9, 10), \"float32\"), compute: T.Buffer((17, 270), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i in T.parallel(17):\n            for j in range(270):\n                cse_var_1: T.int32 = i * 270 + j\n                compute_1 = T.Buffer((4590,), data=compute.data)\n                data_1 = T.Buffer((4590,), data=data.data)\n                compute_1[cse_var_1] = data_1[cse_var_1]",
        "op_args": [
            17,
            3,
            9,
            10
        ],
        "input_shape": [
            [
                17,
                3,
                9,
                10
            ]
        ],
        "output_shape": [
            [
                17,
                270
            ]
        ]
    },
    {
        "op_name": "erf",
        "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused_i3_fused = 0; i0_i1_fused_i2_fused_i3_fused < 312; ++i0_i1_fused_i2_fused_i3_fused) {\n    compute[i0_i1_fused_i2_fused_i3_fused] = erff(data[i0_i1_fused_i2_fused_i3_fused]);\n  }\n}\n\n",
        "cuda_code": "extern \"C\" __global__ void __launch_bounds__(2) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 2) + ((int)threadIdx.x))] = erff(data[((((int)blockIdx.x) * 2) + ((int)threadIdx.x))]);\n}\n\n",
        "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((13, 6, 1, 4), \"float32\"), compute: T.Buffer((13, 6, 1, 4), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused_i2_fused_i3_fused in T.parallel(312):\n            compute_1 = T.Buffer((312,), data=compute.data)\n            data_1 = T.Buffer((312,), data=data.data)\n            compute_1[i0_i1_fused_i2_fused_i3_fused] = T.erf(data_1[i0_i1_fused_i2_fused_i3_fused])",
        "op_args": [
            13,
            6,
            1,
            4
        ],
        "input_shape": [
            [
                13,
                6,
                1,
                4
            ]
        ],
        "output_shape": [
            [
                13,
                6,
                1,
                4
            ]
        ]
    },
    {
        "op_name": "fifo_buffer",
        "c_code": "void default_function_kernel(float* data, float* new_buffer) {\n  #pragma omp parallel for\n  for (int32_t i_j_fused = 0; i_j_fused < 255; ++i_j_fused) {\n    for (int32_t k = 0; k < 7; ++k) {\n      for (int32_t l = 0; l < 18; ++l) {\n        new_buffer[(((i_j_fused * 126) + (k * 18)) + l)] = data[(((i_j_fused * 126) + (k * 18)) + l)];\n      }\n    }\n  }\n}\n\n",
        "cuda_code": "extern \"C\" __global__ void __launch_bounds__(34) default_function_kernel(float* __restrict__ data, float* __restrict__ new_buffer) {\n  new_buffer[((((int)blockIdx.x) * 34) + ((int)threadIdx.x))] = data[((((int)blockIdx.x) * 34) + ((int)threadIdx.x))];\n}\n\n",
        "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((15, 17, 7, 18), \"float32\"), buffer: T.Buffer((15, 17, 7, 18), \"float32\"), new_buffer: T.Buffer((15, 17, 7, 18), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i_j_fused in T.parallel(255):\n            for k, l in T.grid(7, 18):\n                cse_var_1: T.int32 = i_j_fused * 126 + k * 18 + l\n                new_buffer_1 = T.Buffer((32130,), data=new_buffer.data)\n                data_1 = T.Buffer((32130,), data=data.data)\n                new_buffer_1[cse_var_1] = data_1[cse_var_1]",
        "op_args": [
            15,
            17,
            7,
            18
        ],
        "input_shape": [
            [
                15,
                17,
                7,
                18
            ],
            [
                15,
                17,
                7,
                18
            ]
        ],
        "output_shape": [
            [
                15,
                17,
                7,
                18
            ]
        ]
    },
    {
        "op_name": "exp",
        "c_code": "void default_function_kernel(float* compute, float* data) {\n  for (int32_t i1 = 0; i1 < 19; ++i1) {\n    for (int32_t i2 = 0; i2 < 4; ++i2) {\n      for (int32_t i3 = 0; i3 < 10; ++i3) {\n        compute[(((i1 * 40) + (i2 * 10)) + i3)] = expf(data[(((i1 * 40) + (i2 * 10)) + i3)]);\n      }\n    }\n  }\n}\n\n",
        "cuda_code": "extern \"C\" __global__ void __launch_bounds__(20) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 20) + ((int)threadIdx.x))] = __expf(data[((((int)blockIdx.x) * 20) + ((int)threadIdx.x))]);\n}\n\n",
        "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((1, 19, 4, 10), \"float32\"), compute: T.Buffer((1, 19, 4, 10), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i1, i2, i3 in T.grid(19, 4, 10):\n            cse_var_1: T.int32 = i1 * 40 + i2 * 10 + i3\n            compute_1 = T.Buffer((760,), data=compute.data)\n            data_1 = T.Buffer((760,), data=data.data)\n            compute_1[cse_var_1] = T.exp(data_1[cse_var_1])",
        "op_args": [
            1,
            19,
            4,
            10
        ],
        "input_shape": [
            [
                1,
                19,
                4,
                10
            ]
        ],
        "output_shape": [
            [
                1,
                19,
                4,
                10
            ]
        ]
    },
    {
        "op_name": "fast_erf",
        "c_code": "void default_function_kernel(float* T_fast_erf, float* data) {\n  #pragma omp parallel for\n  for (int32_t ax0_ax1_fused_ax2_fused = 0; ax0_ax1_fused_ax2_fused < 648; ++ax0_ax1_fused_ax2_fused) {\n    for (int32_t ax3 = 0; ax3 < 6; ++ax3) {\n      T_fast_erf[((ax0_ax1_fused_ax2_fused * 6) + ax3)] = ((max(min(data[((ax0_ax1_fused_ax2_fused * 6) + ax3)], 4.000000e+00f), -4.000000e+00f) * (((max(min(data[((ax0_ax1_fused_ax2_fused * 6) + ax3)], 4.000000e+00f), -4.000000e+00f) * max(min(data[((ax0_ax1_fused_ax2_fused * 6) + ax3)], 4.000000e+00f), -4.000000e+00f)) * (((max(min(data[((ax0_ax1_fused_ax2_fused * 6) + ax3)], 4.000000e+00f), -4.000000e+00f) * max(min(data[((ax0_ax1_fused_ax2_fused * 6) + ax3)], 4.000000e+00f), -4.000000e+00f)) * (((max(min(data[((ax0_ax1_fused_ax2_fused * 6) + ax3)], 4.000000e+00f), -4.000000e+00f) * max(min(data[((ax0_ax1_fused_ax2_fused * 6) + ax3)], 4.000000e+00f), -4.000000e+00f)) * (((max(min(data[((ax0_ax1_fused_ax2_fused * 6) + ax3)], 4.000000e+00f), -4.000000e+00f) * max(min(data[((ax0_ax1_fused_ax2_fused * 6) + ax3)], 4.000000e+00f), -4.000000e+00f)) * (((max(min(data[((ax0_ax1_fused_ax2_fused * 6) + ax3)], 4.000000e+00f), -4.000000e+00f) * max(min(data[((ax0_ax1_fused_ax2_fused * 6) + ax3)], 4.000000e+00f), -4.000000e+00f)) * (((max(min(data[((ax0_ax1_fused_ax2_fused * 6) + ax3)], 4.000000e+00f), -4.000000e+00f) * max(min(data[((ax0_ax1_fused_ax2_fused * 6) + ax3)], 4.000000e+00f), -4.000000e+00f)) * -2.726142e-10f) + 2.770681e-08f)) + -2.101024e-06f)) + -5.692506e-05f)) + -7.349906e-04f)) + -2.954600e-03f)) + -1.609603e-02f)) / (((max(min(data[((ax0_ax1_fused_ax2_fused * 6) + ax3)], 4.000000e+00f), -4.000000e+00f) * max(min(data[((ax0_ax1_fused_ax2_fused * 6) + ax3)], 4.000000e+00f), -4.000000e+00f)) * (((max(min(data[((ax0_ax1_fused_ax2_fused * 6) + ax3)], 4.000000e+00f), -4.000000e+00f) * max(min(data[((ax0_ax1_fused_ax2_fused * 6) + ax3)], 4.000000e+00f), -4.000000e+00f)) * (((max(min(data[((ax0_ax1_fused_ax2_fused * 6) + ax3)], 4.000000e+00f), -4.000000e+00f) * max(min(data[((ax0_ax1_fused_ax2_fused * 6) + ax3)], 4.000000e+00f), -4.000000e+00f)) * (((max(min(data[((ax0_ax1_fused_ax2_fused * 6) + ax3)], 4.000000e+00f), -4.000000e+00f) * max(min(data[((ax0_ax1_fused_ax2_fused * 6) + ax3)], 4.000000e+00f), -4.000000e+00f)) * -1.456607e-05f) + -2.133740e-04f)) + -1.682827e-03f)) + -7.373329e-03f)) + -1.426474e-02f));\n    }\n  }\n}\n\n",
        "cuda_code": "extern \"C\" __global__ void __launch_bounds__(18) default_function_kernel(float* __restrict__ T_fast_erf, float* __restrict__ data) {\n  T_fast_erf[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))] = ((max(min(data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))], 4.000000e+00f), -4.000000e+00f) * (((max(min(data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))], 4.000000e+00f), -4.000000e+00f) * max(min(data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))], 4.000000e+00f), -4.000000e+00f)) * (((max(min(data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))], 4.000000e+00f), -4.000000e+00f) * max(min(data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))], 4.000000e+00f), -4.000000e+00f)) * (((max(min(data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))], 4.000000e+00f), -4.000000e+00f) * max(min(data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))], 4.000000e+00f), -4.000000e+00f)) * (((max(min(data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))], 4.000000e+00f), -4.000000e+00f) * max(min(data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))], 4.000000e+00f), -4.000000e+00f)) * (((max(min(data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))], 4.000000e+00f), -4.000000e+00f) * max(min(data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))], 4.000000e+00f), -4.000000e+00f)) * (((max(min(data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))], 4.000000e+00f), -4.000000e+00f) * max(min(data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))], 4.000000e+00f), -4.000000e+00f)) * -2.726142e-10f) + 2.770681e-08f)) + -2.101024e-06f)) + -5.692506e-05f)) + -7.349906e-04f)) + -2.954600e-03f)) + -1.609603e-02f)) / (((max(min(data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))], 4.000000e+00f), -4.000000e+00f) * max(min(data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))], 4.000000e+00f), -4.000000e+00f)) * (((max(min(data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))], 4.000000e+00f), -4.000000e+00f) * max(min(data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))], 4.000000e+00f), -4.000000e+00f)) * (((max(min(data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))], 4.000000e+00f), -4.000000e+00f) * max(min(data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))], 4.000000e+00f), -4.000000e+00f)) * (((max(min(data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))], 4.000000e+00f), -4.000000e+00f) * max(min(data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))], 4.000000e+00f), -4.000000e+00f)) * -1.456607e-05f) + -2.133740e-04f)) + -1.682827e-03f)) + -7.373329e-03f)) + -1.426474e-02f));\n}\n\n",
        "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((9, 12, 6, 6), \"float32\"), T_fast_erf: T.Buffer((9, 12, 6, 6), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0_ax1_fused_ax2_fused in T.parallel(648):\n            for ax3 in range(6):\n                cse_var_1: T.int32 = ax0_ax1_fused_ax2_fused * 6 + ax3\n                T_fast_erf_1 = T.Buffer((3888,), data=T_fast_erf.data)\n                data_1 = T.Buffer((3888,), data=data.data)\n                T_fast_erf_1[cse_var_1] = T.max(T.min(data_1[cse_var_1], T.float32(4)), T.float32(-4)) * (T.max(T.min(data_1[cse_var_1], T.float32(4)), T.float32(-4)) * T.max(T.min(data_1[cse_var_1], T.float32(4)), T.float32(-4)) * (T.max(T.min(data_1[cse_var_1], T.float32(4)), T.float32(-4)) * T.max(T.min(data_1[cse_var_1], T.float32(4)), T.float32(-4)) * (T.max(T.min(data_1[cse_var_1], T.float32(4)), T.float32(-4)) * T.max(T.min(data_1[cse_var_1], T.float32(4)), T.float32(-4)) * (T.max(T.min(data_1[cse_var_1], T.float32(4)), T.float32(-4)) * T.max(T.min(data_1[cse_var_1], T.float32(4)), T.float32(-4)) * (T.max(T.min(data_1[cse_var_1], T.float32(4)), T.float32(-4)) * T.max(T.min(data_1[cse_var_1], T.float32(4)), T.float32(-4)) * (T.max(T.min(data_1[cse_var_1], T.float32(4)), T.float32(-4)) * T.max(T.min(data_1[cse_var_1], T.float32(4)), T.float32(-4)) * T.float32(-2.7261423674040941e-10) + T.float32(2.7706814620387377e-08)) + T.float32(-2.101023937939317e-06)) + T.float32(-5.6925062381196767e-05)) + T.float32(-0.00073499063728377223)) + T.float32(-0.0029545999132096767)) + T.float32(-0.016096033155918121)) / (T.max(T.min(data_1[cse_var_1], T.float32(4)), T.float32(-4)) * T.max(T.min(data_1[cse_var_1], T.float32(4)), T.float32(-4)) * (T.max(T.min(data_1[cse_var_1], T.float32(4)), T.float32(-4)) * T.max(T.min(data_1[cse_var_1], T.float32(4)), T.float32(-4)) * (T.max(T.min(data_1[cse_var_1], T.float32(4)), T.float32(-4)) * T.max(T.min(data_1[cse_var_1], T.float32(4)), T.float32(-4)) * (T.max(T.min(data_1[cse_var_1], T.float32(4)), T.float32(-4)) * T.max(T.min(data_1[cse_var_1], T.float32(4)), T.float32(-4)) * T.float32(-1.4566071513399947e-05) + T.float32(-0.00021337404905352741)) + T.float32(-0.001682827016338706)) + T.float32(-0.0073733292520046234)) + T.float32(-0.014264739118516445))",
        "op_args": [
            9,
            12,
            6,
            6
        ],
        "input_shape": [
            [
                9,
                12,
                6,
                6
            ]
        ],
        "output_shape": [
            [
                9,
                12,
                6,
                6
            ]
        ]
    },
    {
        "op_name": "depth_to_space",
        "c_code": "void default_function_kernel(float* data, float* depth_to_space) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused = 0; i0_i1_fused_i2_fused < 504; ++i0_i1_fused_i2_fused) {\n    for (int32_t i3 = 0; i3 < 6; ++i3) {\n      depth_to_space[((i0_i1_fused_i2_fused * 6) + i3)] = data[((((((i0_i1_fused_i2_fused / 36) * 270) + (((i0_i1_fused_i2_fused % 36) % 2) * 108)) + ((i3 % 2) * 54)) + (((i0_i1_fused_i2_fused % 36) / 2) * 3)) + (i3 / 2))];\n    }\n  }\n}\n\n",
        "cuda_code": "extern \"C\" __global__ void __launch_bounds__(54) default_function_kernel(float* __restrict__ data, float* __restrict__ depth_to_space) {\n  depth_to_space[((((int)blockIdx.x) * 54) + ((int)threadIdx.x))] = data[((((((((int)blockIdx.x) >> 2) * 270) + (((((((int)blockIdx.x) & 3) * 9) + (((int)threadIdx.x) / 6)) % 2) * 108)) + (((((int)threadIdx.x) % 6) % 2) * 54)) + (((((((int)blockIdx.x) & 3) * 9) + (((int)threadIdx.x) / 6)) / 2) * 3)) + ((((int)threadIdx.x) % 6) / 2))];\n}\n\n",
        "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((14, 5, 18, 3), \"float32\"), depth_to_space: T.Buffer((14, 1, 36, 6), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused_i2_fused in T.parallel(504):\n            for i3 in range(6):\n                cse_var_1: T.int32 = i0_i1_fused_i2_fused % 36\n                depth_to_space_1 = T.Buffer((3024,), data=depth_to_space.data)\n                data_1 = T.Buffer((3780,), data=data.data)\n                depth_to_space_1[i0_i1_fused_i2_fused * 6 + i3] = data_1[i0_i1_fused_i2_fused // 36 * 270 + T.truncmod(cse_var_1, 2) * 108 + T.truncmod(i3, 2) * 54 + T.Div(cse_var_1, 2) * 3 + T.Div(i3, 2)]",
        "op_args": [
            14,
            5,
            18,
            3
        ],
        "input_shape": [
            [
                14,
                5,
                18,
                3
            ]
        ],
        "output_shape": [
            [
                14,
                1,
                36,
                6
            ]
        ]
    },
    {
        "op_name": "fast_exp",
        "c_code": "void default_function_kernel(float* T_fast_exp, float* data) {\n  #pragma omp parallel for\n  for (int32_t ax0 = 0; ax0 < 15; ++ax0) {\n    for (int32_t ax1 = 0; ax1 < 19; ++ax1) {\n      for (int32_t ax2 = 0; ax2 < 2; ++ax2) {\n        for (int32_t ax3 = 0; ax3 < 16; ++ax3) {\n            int32_t v_ = ((int32_t)(floorf(((max(min(data[((((ax0 * 608) + (ax1 * 32)) + (ax2 * 16)) + ax3)], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) + 1.270000e+02f)) << 23;\n          T_fast_exp[((((ax0 * 608) + (ax1 * 32)) + (ax2 * 16)) + ax3)] = max(((*(float *)(&(v_))) * ((((((((((((((1.987569e-04f * (max(min(data[((((ax0 * 608) + (ax1 * 32)) + (ax2 * 16)) + ax3)], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[((((ax0 * 608) + (ax1 * 32)) + (ax2 * 16)) + ax3)], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.398200e-03f) * (max(min(data[((((ax0 * 608) + (ax1 * 32)) + (ax2 * 16)) + ax3)], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[((((ax0 * 608) + (ax1 * 32)) + (ax2 * 16)) + ax3)], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 8.333452e-03f) * (max(min(data[((((ax0 * 608) + (ax1 * 32)) + (ax2 * 16)) + ax3)], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[((((ax0 * 608) + (ax1 * 32)) + (ax2 * 16)) + ax3)], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 4.166580e-02f) * (max(min(data[((((ax0 * 608) + (ax1 * 32)) + (ax2 * 16)) + ax3)], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[((((ax0 * 608) + (ax1 * 32)) + (ax2 * 16)) + ax3)], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.666667e-01f) * (max(min(data[((((ax0 * 608) + (ax1 * 32)) + (ax2 * 16)) + ax3)], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[((((ax0 * 608) + (ax1 * 32)) + (ax2 * 16)) + ax3)], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 5.000000e-01f) * (max(min(data[((((ax0 * 608) + (ax1 * 32)) + (ax2 * 16)) + ax3)], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[((((ax0 * 608) + (ax1 * 32)) + (ax2 * 16)) + ax3)], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) * (max(min(data[((((ax0 * 608) + (ax1 * 32)) + (ax2 * 16)) + ax3)], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[((((ax0 * 608) + (ax1 * 32)) + (ax2 * 16)) + ax3)], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + (max(min(data[((((ax0 * 608) + (ax1 * 32)) + (ax2 * 16)) + ax3)], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[((((ax0 * 608) + (ax1 * 32)) + (ax2 * 16)) + ax3)], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.000000e+00f)), data[((((ax0 * 608) + (ax1 * 32)) + (ax2 * 16)) + ax3)]);\n        }\n      }\n    }\n  }\n}\n\n",
        "cuda_code": "extern \"C\" __global__ void __launch_bounds__(24) default_function_kernel(float* __restrict__ T_fast_exp, float* __restrict__ data) {\n    int v_ = ((int)(floorf(((max(min(data[((((int)blockIdx.x) * 24) + ((int)threadIdx.x))], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) + 1.270000e+02f)) << 23;\n  T_fast_exp[((((int)blockIdx.x) * 24) + ((int)threadIdx.x))] = max(((*(float *)(&(v_))) * ((((((((((((((1.987569e-04f * (max(min(data[((((int)blockIdx.x) * 24) + ((int)threadIdx.x))], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[((((int)blockIdx.x) * 24) + ((int)threadIdx.x))], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.398200e-03f) * (max(min(data[((((int)blockIdx.x) * 24) + ((int)threadIdx.x))], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[((((int)blockIdx.x) * 24) + ((int)threadIdx.x))], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 8.333452e-03f) * (max(min(data[((((int)blockIdx.x) * 24) + ((int)threadIdx.x))], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[((((int)blockIdx.x) * 24) + ((int)threadIdx.x))], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 4.166580e-02f) * (max(min(data[((((int)blockIdx.x) * 24) + ((int)threadIdx.x))], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[((((int)blockIdx.x) * 24) + ((int)threadIdx.x))], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.666667e-01f) * (max(min(data[((((int)blockIdx.x) * 24) + ((int)threadIdx.x))], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[((((int)blockIdx.x) * 24) + ((int)threadIdx.x))], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 5.000000e-01f) * (max(min(data[((((int)blockIdx.x) * 24) + ((int)threadIdx.x))], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[((((int)blockIdx.x) * 24) + ((int)threadIdx.x))], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) * (max(min(data[((((int)blockIdx.x) * 24) + ((int)threadIdx.x))], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[((((int)blockIdx.x) * 24) + ((int)threadIdx.x))], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + (max(min(data[((((int)blockIdx.x) * 24) + ((int)threadIdx.x))], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[((((int)blockIdx.x) * 24) + ((int)threadIdx.x))], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.000000e+00f)), data[((((int)blockIdx.x) * 24) + ((int)threadIdx.x))]);\n}\n\n",
        "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((15, 19, 2, 16), \"float32\"), T_fast_exp: T.Buffer((15, 19, 2, 16), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0 in T.parallel(15):\n            for ax1, ax2, ax3 in T.grid(19, 2, 16):\n                cse_var_1: T.int32 = ax0 * 608 + ax1 * 32 + ax2 * 16 + ax3\n                T_fast_exp_1 = T.Buffer((9120,), data=T_fast_exp.data)\n                data_1 = T.Buffer((9120,), data=data.data)\n                T_fast_exp_1[cse_var_1] = T.max(T.reinterpret(\"float32\", T.shift_left(T.Cast(\"int32\", T.floor(T.max(T.min(data_1[cse_var_1], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) + T.float32(127)), 23)) * ((((((T.float32(0.00019875691214110702) * (T.max(T.min(data_1[cse_var_1], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.0013981999363750219)) * (T.max(T.min(data_1[cse_var_1], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.008333452045917511)) * (T.max(T.min(data_1[cse_var_1], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.041665796190500259)) * (T.max(T.min(data_1[cse_var_1], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.1666666567325592)) * (T.max(T.min(data_1[cse_var_1], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.5)) * (T.max(T.min(data_1[cse_var_1], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) * (T.max(T.min(data_1[cse_var_1], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + (T.max(T.min(data_1[cse_var_1], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(1)), data_1[cse_var_1])",
        "op_args": [
            15,
            19,
            2,
            16
        ],
        "input_shape": [
            [
                15,
                19,
                2,
                16
            ]
        ],
        "output_shape": [
            [
                15,
                19,
                2,
                16
            ]
        ]
    },
    {
        "op_name": "fast_tanh",
        "c_code": "void default_function_kernel(float* T_fast_tanh, float* data) {\n  #pragma omp parallel for\n  for (int32_t ax0_ax1_fused = 0; ax0_ax1_fused < 252; ++ax0_ax1_fused) {\n    for (int32_t ax2 = 0; ax2 < 2; ++ax2) {\n      for (int32_t ax3 = 0; ax3 < 12; ++ax3) {\n        T_fast_tanh[(((ax0_ax1_fused * 24) + (ax2 * 12)) + ax3)] = ((max(-9.000000e+00f, min(9.000000e+00f, data[(((ax0_ax1_fused * 24) + (ax2 * 12)) + ax3)])) * (((max(-9.000000e+00f, min(9.000000e+00f, data[(((ax0_ax1_fused * 24) + (ax2 * 12)) + ax3)])) * max(-9.000000e+00f, min(9.000000e+00f, data[(((ax0_ax1_fused * 24) + (ax2 * 12)) + ax3)]))) * (((max(-9.000000e+00f, min(9.000000e+00f, data[(((ax0_ax1_fused * 24) + (ax2 * 12)) + ax3)])) * max(-9.000000e+00f, min(9.000000e+00f, data[(((ax0_ax1_fused * 24) + (ax2 * 12)) + ax3)]))) * (((max(-9.000000e+00f, min(9.000000e+00f, data[(((ax0_ax1_fused * 24) + (ax2 * 12)) + ax3)])) * max(-9.000000e+00f, min(9.000000e+00f, data[(((ax0_ax1_fused * 24) + (ax2 * 12)) + ax3)]))) * (((max(-9.000000e+00f, min(9.000000e+00f, data[(((ax0_ax1_fused * 24) + (ax2 * 12)) + ax3)])) * max(-9.000000e+00f, min(9.000000e+00f, data[(((ax0_ax1_fused * 24) + (ax2 * 12)) + ax3)]))) * (((max(-9.000000e+00f, min(9.000000e+00f, data[(((ax0_ax1_fused * 24) + (ax2 * 12)) + ax3)])) * max(-9.000000e+00f, min(9.000000e+00f, data[(((ax0_ax1_fused * 24) + (ax2 * 12)) + ax3)]))) * (((max(-9.000000e+00f, min(9.000000e+00f, data[(((ax0_ax1_fused * 24) + (ax2 * 12)) + ax3)])) * max(-9.000000e+00f, min(9.000000e+00f, data[(((ax0_ax1_fused * 24) + (ax2 * 12)) + ax3)]))) * -2.760768e-16f) + 2.000188e-13f)) + -8.604672e-11f)) + 5.122297e-08f)) + 1.485722e-05f)) + 6.372619e-04f)) + 4.893525e-03f)) / (((max(-9.000000e+00f, min(9.000000e+00f, data[(((ax0_ax1_fused * 24) + (ax2 * 12)) + ax3)])) * max(-9.000000e+00f, min(9.000000e+00f, data[(((ax0_ax1_fused * 24) + (ax2 * 12)) + ax3)]))) * (((max(-9.000000e+00f, min(9.000000e+00f, data[(((ax0_ax1_fused * 24) + (ax2 * 12)) + ax3)])) * max(-9.000000e+00f, min(9.000000e+00f, data[(((ax0_ax1_fused * 24) + (ax2 * 12)) + ax3)]))) * (((max(-9.000000e+00f, min(9.000000e+00f, data[(((ax0_ax1_fused * 24) + (ax2 * 12)) + ax3)])) * max(-9.000000e+00f, min(9.000000e+00f, data[(((ax0_ax1_fused * 24) + (ax2 * 12)) + ax3)]))) * 1.198258e-06f) + 1.185347e-04f)) + 2.268435e-03f)) + 4.893525e-03f));\n      }\n    }\n  }\n}\n\n",
        "cuda_code": "extern \"C\" __global__ void __launch_bounds__(18) default_function_kernel(float* __restrict__ T_fast_tanh, float* __restrict__ data) {\n  T_fast_tanh[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))] = ((max(-9.000000e+00f, min(9.000000e+00f, data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))])) * (((max(-9.000000e+00f, min(9.000000e+00f, data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))])) * max(-9.000000e+00f, min(9.000000e+00f, data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))]))) * (((max(-9.000000e+00f, min(9.000000e+00f, data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))])) * max(-9.000000e+00f, min(9.000000e+00f, data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))]))) * (((max(-9.000000e+00f, min(9.000000e+00f, data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))])) * max(-9.000000e+00f, min(9.000000e+00f, data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))]))) * (((max(-9.000000e+00f, min(9.000000e+00f, data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))])) * max(-9.000000e+00f, min(9.000000e+00f, data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))]))) * (((max(-9.000000e+00f, min(9.000000e+00f, data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))])) * max(-9.000000e+00f, min(9.000000e+00f, data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))]))) * (((max(-9.000000e+00f, min(9.000000e+00f, data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))])) * max(-9.000000e+00f, min(9.000000e+00f, data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))]))) * -2.760768e-16f) + 2.000188e-13f)) + -8.604672e-11f)) + 5.122297e-08f)) + 1.485722e-05f)) + 6.372619e-04f)) + 4.893525e-03f)) / (((max(-9.000000e+00f, min(9.000000e+00f, data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))])) * max(-9.000000e+00f, min(9.000000e+00f, data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))]))) * (((max(-9.000000e+00f, min(9.000000e+00f, data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))])) * max(-9.000000e+00f, min(9.000000e+00f, data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))]))) * (((max(-9.000000e+00f, min(9.000000e+00f, data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))])) * max(-9.000000e+00f, min(9.000000e+00f, data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))]))) * 1.198258e-06f) + 1.185347e-04f)) + 2.268435e-03f)) + 4.893525e-03f));\n}\n\n",
        "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((18, 14, 2, 12), \"float32\"), T_fast_tanh: T.Buffer((18, 14, 2, 12), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0_ax1_fused in T.parallel(252):\n            for ax2, ax3 in T.grid(2, 12):\n                cse_var_1: T.int32 = ax0_ax1_fused * 24 + ax2 * 12 + ax3\n                T_fast_tanh_1 = T.Buffer((6048,), data=T_fast_tanh.data)\n                data_1 = T.Buffer((6048,), data=data.data)\n                T_fast_tanh_1[cse_var_1] = T.max(T.float32(-9), T.min(T.float32(9), data_1[cse_var_1])) * (T.max(T.float32(-9), T.min(T.float32(9), data_1[cse_var_1])) * T.max(T.float32(-9), T.min(T.float32(9), data_1[cse_var_1])) * (T.max(T.float32(-9), T.min(T.float32(9), data_1[cse_var_1])) * T.max(T.float32(-9), T.min(T.float32(9), data_1[cse_var_1])) * (T.max(T.float32(-9), T.min(T.float32(9), data_1[cse_var_1])) * T.max(T.float32(-9), T.min(T.float32(9), data_1[cse_var_1])) * (T.max(T.float32(-9), T.min(T.float32(9), data_1[cse_var_1])) * T.max(T.float32(-9), T.min(T.float32(9), data_1[cse_var_1])) * (T.max(T.float32(-9), T.min(T.float32(9), data_1[cse_var_1])) * T.max(T.float32(-9), T.min(T.float32(9), data_1[cse_var_1])) * (T.max(T.float32(-9), T.min(T.float32(9), data_1[cse_var_1])) * T.max(T.float32(-9), T.min(T.float32(9), data_1[cse_var_1])) * T.float32(-2.76076847742355e-16) + T.float32(2.0001879048247699e-13)) + T.float32(-8.60467152213735e-11)) + T.float32(5.1222970903711401e-08)) + T.float32(1.4857223571797901e-05)) + T.float32(0.00063726192887543596)) + T.float32(0.0048935245589178597)) / (T.max(T.float32(-9), T.min(T.float32(9), data_1[cse_var_1])) * T.max(T.float32(-9), T.min(T.float32(9), data_1[cse_var_1])) * (T.max(T.float32(-9), T.min(T.float32(9), data_1[cse_var_1])) * T.max(T.float32(-9), T.min(T.float32(9), data_1[cse_var_1])) * (T.max(T.float32(-9), T.min(T.float32(9), data_1[cse_var_1])) * T.max(T.float32(-9), T.min(T.float32(9), data_1[cse_var_1])) * T.float32(1.1982583946670199e-06) + T.float32(0.000118534705686654)) + T.float32(0.0022684346324390002)) + T.float32(0.0048935251855438504))",
        "op_args": [
            18,
            14,
            2,
            12
        ],
        "input_shape": [
            [
                18,
                14,
                2,
                12
            ]
        ],
        "output_shape": [
            [
                18,
                14,
                2,
                12
            ]
        ]
    },
    {
        "op_name": "flip",
        "c_code": "void default_function_kernel(float* T_reverse_sequence, float* data) {\n  #pragma omp parallel for\n  for (int32_t ax0_ax1_fused = 0; ax0_ax1_fused < 8; ++ax0_ax1_fused) {\n    for (int32_t ax2 = 0; ax2 < 13; ++ax2) {\n      for (int32_t ax3 = 0; ax3 < 4; ++ax3) {\n        T_reverse_sequence[(((ax0_ax1_fused * 52) + (ax2 * 4)) + ax3)] = data[((((((ax0_ax1_fused & 1) * 52) + (ax2 * 4)) + ax3) + 312) - ((ax0_ax1_fused >> 1) * 104))];\n      }\n    }\n  }\n}\n\n",
        "cuda_code": "extern \"C\" __global__ void __launch_bounds__(13) default_function_kernel(float* __restrict__ T_reverse_sequence, float* __restrict__ data) {\n  T_reverse_sequence[((((int)blockIdx.x) * 13) + ((int)threadIdx.x))] = data[(((((((int)blockIdx.x) & 7) * 13) + ((int)threadIdx.x)) + 312) - ((((int)blockIdx.x) >> 3) * 104))];\n}\n\n",
        "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((4, 2, 13, 4), \"float32\"), T_reverse_sequence: T.Buffer((4, 2, 13, 4), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0_ax1_fused in T.parallel(8):\n            for ax2, ax3 in T.grid(13, 4):\n                cse_var_1: T.int32 = ax2 * 4\n                T_reverse_sequence_1 = T.Buffer((416,), data=T_reverse_sequence.data)\n                data_1 = T.Buffer((416,), data=data.data)\n                T_reverse_sequence_1[ax0_ax1_fused * 52 + cse_var_1 + ax3] = data_1[ax0_ax1_fused % 2 * 52 + cse_var_1 + ax3 + 312 - ax0_ax1_fused // 2 * 104]",
        "op_args": [
            4,
            2,
            13,
            4
        ],
        "input_shape": [
            [
                4,
                2,
                13,
                4
            ]
        ],
        "output_shape": [
            [
                4,
                2,
                13,
                4
            ]
        ]
    },
    {
        "op_name": "floor",
        "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused = 0; i0_i1_fused_i2_fused < 594; ++i0_i1_fused_i2_fused) {\n    for (int32_t i3 = 0; i3 < 10; ++i3) {\n      compute[((i0_i1_fused_i2_fused * 10) + i3)] = floorf(data[((i0_i1_fused_i2_fused * 10) + i3)]);\n    }\n  }\n}\n\n",
        "cuda_code": "extern \"C\" __global__ void __launch_bounds__(15) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 15) + ((int)threadIdx.x))] = floorf(data[((((int)blockIdx.x) * 15) + ((int)threadIdx.x))]);\n}\n\n",
        "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((3, 18, 11, 10), \"float32\"), compute: T.Buffer((3, 18, 11, 10), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused_i2_fused in T.parallel(594):\n            for i3 in range(10):\n                cse_var_1: T.int32 = i0_i1_fused_i2_fused * 10 + i3\n                compute_1 = T.Buffer((5940,), data=compute.data)\n                data_1 = T.Buffer((5940,), data=data.data)\n                compute_1[cse_var_1] = T.floor(data_1[cse_var_1])",
        "op_args": [
            3,
            18,
            11,
            10
        ],
        "input_shape": [
            [
                3,
                18,
                11,
                10
            ]
        ],
        "output_shape": [
            [
                3,
                18,
                11,
                10
            ]
        ]
    },
    {
        "op_name": "isnan",
        "c_code": "void default_function_kernel(int8_t* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused = 0; i0_i1_fused < 112; ++i0_i1_fused) {\n    for (int32_t i2 = 0; i2 < 19; ++i2) {\n      for (int32_t i3_s = 0; i3_s < 5; ++i3_s) {\n        compute[(((i0_i1_fused * 95) + (i2 * 5)) + i3_s)] = ((int8_t)(data[(((i0_i1_fused * 95) + (i2 * 5)) + i3_s)] != data[(((i0_i1_fused * 95) + (i2 * 5)) + i3_s)]));\n      }\n    }\n  }\n}\n\n",
        "cuda_code": "extern \"C\" __global__ void __launch_bounds__(32) default_function_kernel(signed char* __restrict__ compute, float* __restrict__ data) {\n  if (((((int)blockIdx.x) * 2) + (((int)threadIdx.x) >> 4)) < 665) {\n    compute[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] = ((signed char)(data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] != data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))]));\n  }\n}\n\n",
        "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((14, 8, 19, 5), \"float32\"), compute: T.Buffer((14, 8, 19, 5), \"bool\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused in T.parallel(112):\n            for i2, i3_s in T.grid(19, 5):\n                cse_var_1: T.int32 = i0_i1_fused * 95 + i2 * 5 + i3_s\n                compute_1 = T.Buffer((10640,), \"int8\", data=compute.data)\n                data_1 = T.Buffer((10640,), data=data.data)\n                compute_1[cse_var_1] = T.Cast(\"int8\", T.isnan(data_1[cse_var_1]))",
        "op_args": [
            14,
            8,
            19,
            5
        ],
        "input_shape": [
            [
                14,
                8,
                19,
                5
            ]
        ],
        "output_shape": [
            [
                14,
                8,
                19,
                5
            ]
        ]
    },
    {
        "op_name": "log",
        "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0 = 0; i0 < 3; ++i0) {\n    for (int32_t i1 = 0; i1 < 18; ++i1) {\n      for (int32_t i2 = 0; i2 < 6; ++i2) {\n        for (int32_t i3 = 0; i3 < 17; ++i3) {\n          compute[((((i0 * 1836) + (i1 * 102)) + (i2 * 17)) + i3)] = logf(data[((((i0 * 1836) + (i1 * 102)) + (i2 * 17)) + i3)]);\n        }\n      }\n    }\n  }\n}\n\n",
        "cuda_code": "extern \"C\" __global__ void __launch_bounds__(51) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 51) + ((int)threadIdx.x))] = __logf(data[((((int)blockIdx.x) * 51) + ((int)threadIdx.x))]);\n}\n\n",
        "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((3, 18, 6, 17), \"float32\"), compute: T.Buffer((3, 18, 6, 17), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0 in T.parallel(3):\n            for i1, i2, i3 in T.grid(18, 6, 17):\n                cse_var_1: T.int32 = i0 * 1836 + i1 * 102 + i2 * 17 + i3\n                compute_1 = T.Buffer((5508,), data=compute.data)\n                data_1 = T.Buffer((5508,), data=data.data)\n                compute_1[cse_var_1] = T.log(data_1[cse_var_1])",
        "op_args": [
            3,
            18,
            6,
            17
        ],
        "input_shape": [
            [
                3,
                18,
                6,
                17
            ]
        ],
        "output_shape": [
            [
                3,
                18,
                6,
                17
            ]
        ]
    },
    {
        "op_name": "log10",
        "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused = 0; i0_i1_fused < 42; ++i0_i1_fused) {\n    for (int32_t i2 = 0; i2 < 3; ++i2) {\n      for (int32_t i3 = 0; i3 < 6; ++i3) {\n        compute[(((i0_i1_fused * 18) + (i2 * 6)) + i3)] = log10f(data[(((i0_i1_fused * 18) + (i2 * 6)) + i3)]);\n      }\n    }\n  }\n}\n\n",
        "cuda_code": "extern \"C\" __global__ void __launch_bounds__(54) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 54) + ((int)threadIdx.x))] = __log10f(data[((((int)blockIdx.x) * 54) + ((int)threadIdx.x))]);\n}\n\n",
        "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((7, 6, 3, 6), \"float32\"), compute: T.Buffer((7, 6, 3, 6), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused in T.parallel(42):\n            for i2, i3 in T.grid(3, 6):\n                cse_var_1: T.int32 = i0_i1_fused * 18 + i2 * 6 + i3\n                compute_1 = T.Buffer((756,), data=compute.data)\n                data_1 = T.Buffer((756,), data=data.data)\n                compute_1[cse_var_1] = T.log10(data_1[cse_var_1])",
        "op_args": [
            7,
            6,
            3,
            6
        ],
        "input_shape": [
            [
                7,
                6,
                3,
                6
            ]
        ],
        "output_shape": [
            [
                7,
                6,
                3,
                6
            ]
        ]
    },
    {
        "op_name": "log2",
        "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0 = 0; i0 < 11; ++i0) {\n    for (int32_t i1 = 0; i1 < 8; ++i1) {\n      for (int32_t i3 = 0; i3 < 13; ++i3) {\n        compute[(((i0 * 104) + (i1 * 13)) + i3)] = log2f(data[(((i0 * 104) + (i1 * 13)) + i3)]);\n      }\n    }\n  }\n}\n\n",
        "cuda_code": "extern \"C\" __global__ void __launch_bounds__(32) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  if (((((int)blockIdx.x) * 4) + (((int)threadIdx.x) >> 3)) < 143) {\n    compute[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] = __log2f(data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))]);\n  }\n}\n\n",
        "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((11, 8, 1, 13), \"float32\"), compute: T.Buffer((11, 8, 1, 13), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0 in T.parallel(11):\n            for i1, i3 in T.grid(8, 13):\n                cse_var_1: T.int32 = i0 * 104 + i1 * 13 + i3\n                compute_1 = T.Buffer((1144,), data=compute.data)\n                data_1 = T.Buffer((1144,), data=data.data)\n                compute_1[cse_var_1] = T.log2(data_1[cse_var_1])",
        "op_args": [
            11,
            8,
            1,
            13
        ],
        "input_shape": [
            [
                11,
                8,
                1,
                13
            ]
        ],
        "output_shape": [
            [
                11,
                8,
                1,
                13
            ]
        ]
    },
    {
        "op_name": "max",
        "c_code": "void default_function_kernel(float* data, float* data_red) {\n  float data_red_rf[22];\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_inner_init = 0; k0_k1_fused_k2_fused_k3_fused_inner_init < 22; ++k0_k1_fused_k2_fused_k3_fused_inner_init) {\n    data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner_init] = -3.402823e+38f;\n  }\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_outer = 0; k0_k1_fused_k2_fused_k3_fused_outer < 330; ++k0_k1_fused_k2_fused_k3_fused_outer) {\n    for (int32_t k0_k1_fused_k2_fused_k3_fused_inner = 0; k0_k1_fused_k2_fused_k3_fused_inner < 22; ++k0_k1_fused_k2_fused_k3_fused_inner) {\n      data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner] = max(data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner], data[((k0_k1_fused_k2_fused_k3_fused_outer * 22) + k0_k1_fused_k2_fused_k3_fused_inner)]);\n    }\n  }\n  data_red[0] = -3.402823e+38f;\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_inner_v = 0; k0_k1_fused_k2_fused_k3_fused_inner_v < 22; ++k0_k1_fused_k2_fused_k3_fused_inner_v) {\n    data_red[0] = max(data_red[0], data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner_v]);\n  }\n}\n\n",
        "cuda_code": "extern \"C\" __global__ void default_function_kernel(float* __restrict__ data, float* __restrict__ data_red) {\n  data_red[0] = -3.402823e+38f;\n  for (int k0 = 0; k0 < 12; ++k0) {\n    for (int k1 = 0; k1 < 5; ++k1) {\n      for (int k2 = 0; k2 < 11; ++k2) {\n        for (int k3 = 0; k3 < 11; ++k3) {\n          data_red[0] = max(data_red[0], data[((((k0 * 605) + (k1 * 121)) + (k2 * 11)) + k3)]);\n        }\n      }\n    }\n  }\n}\n\n",
        "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((12, 5, 11, 11), \"float32\"), data_red: T.Buffer((), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        data_red_rf = T.allocate([22], \"float32\", \"global\")\n        data_red_rf_1 = T.Buffer((22,), data=data_red_rf)\n        for k0_k1_fused_k2_fused_k3_fused_inner_init in range(22):\n            data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner_init] = T.float32(-3.4028234663852886e+38)\n        for k0_k1_fused_k2_fused_k3_fused_outer, k0_k1_fused_k2_fused_k3_fused_inner in T.grid(330, 22):\n            data_1 = T.Buffer((7260,), data=data.data)\n            data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner] = T.max(data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner], data_1[k0_k1_fused_k2_fused_k3_fused_outer * 22 + k0_k1_fused_k2_fused_k3_fused_inner])\n        data_red_1 = T.Buffer((1,), data=data_red.data)\n        data_red_1[0] = T.float32(-3.4028234663852886e+38)\n        for k0_k1_fused_k2_fused_k3_fused_inner_v in range(22):\n            data_red_1[0] = T.max(data_red_1[0], data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner_v])",
        "op_args": [
            12,
            5,
            11,
            11
        ],
        "input_shape": [
            [
                12,
                5,
                11,
                11
            ]
        ],
        "output_shape": [
            []
        ]
    },
    {
        "op_name": "min",
        "c_code": "void default_function_kernel(float* data, float* data_red) {\n  float data_red_rf[14];\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_inner_init = 0; k0_k1_fused_k2_fused_k3_fused_inner_init < 14; ++k0_k1_fused_k2_fused_k3_fused_inner_init) {\n    data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner_init] = 3.402823e+38f;\n  }\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_outer = 0; k0_k1_fused_k2_fused_k3_fused_outer < 144; ++k0_k1_fused_k2_fused_k3_fused_outer) {\n    for (int32_t k0_k1_fused_k2_fused_k3_fused_inner = 0; k0_k1_fused_k2_fused_k3_fused_inner < 14; ++k0_k1_fused_k2_fused_k3_fused_inner) {\n      data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner] = min(data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner], data[((k0_k1_fused_k2_fused_k3_fused_outer * 14) + k0_k1_fused_k2_fused_k3_fused_inner)]);\n    }\n  }\n  data_red[0] = 3.402823e+38f;\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_inner_v = 0; k0_k1_fused_k2_fused_k3_fused_inner_v < 14; ++k0_k1_fused_k2_fused_k3_fused_inner_v) {\n    data_red[0] = min(data_red[0], data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner_v]);\n  }\n}\n\n",
        "cuda_code": "extern \"C\" __global__ void default_function_kernel(float* __restrict__ data, float* __restrict__ data_red) {\n  data_red[0] = 3.402823e+38f;\n  for (int k0 = 0; k0 < 6; ++k0) {\n    for (int k1 = 0; k1 < 3; ++k1) {\n      for (int k2 = 0; k2 < 16; ++k2) {\n        for (int k3 = 0; k3 < 7; ++k3) {\n          data_red[0] = min(data_red[0], data[((((k0 * 336) + (k1 * 112)) + (k2 * 7)) + k3)]);\n        }\n      }\n    }\n  }\n}\n\n",
        "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((6, 3, 16, 7), \"float32\"), data_red: T.Buffer((), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        data_red_rf = T.allocate([14], \"float32\", \"global\")\n        data_red_rf_1 = T.Buffer((14,), data=data_red_rf, align=32)\n        for k0_k1_fused_k2_fused_k3_fused_inner_init in range(14):\n            data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner_init] = T.float32(3.4028234663852886e+38)\n        for k0_k1_fused_k2_fused_k3_fused_outer, k0_k1_fused_k2_fused_k3_fused_inner in T.grid(144, 14):\n            data_1 = T.Buffer((2016,), data=data.data)\n            data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner] = T.min(data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner], data_1[k0_k1_fused_k2_fused_k3_fused_outer * 14 + k0_k1_fused_k2_fused_k3_fused_inner])\n        data_red_1 = T.Buffer((1,), data=data_red.data)\n        data_red_1[0] = T.float32(3.4028234663852886e+38)\n        for k0_k1_fused_k2_fused_k3_fused_inner_v in range(14):\n            data_red_1[0] = T.min(data_red_1[0], data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner_v])",
        "op_args": [
            6,
            3,
            16,
            7
        ],
        "input_shape": [
            [
                6,
                3,
                16,
                7
            ]
        ],
        "output_shape": [
            []
        ]
    },
    {
        "op_name": "leaky_relu",
        "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused_i3_fused = 0; i0_i1_fused_i2_fused_i3_fused < 2592; ++i0_i1_fused_i2_fused_i3_fused) {\n    compute[i0_i1_fused_i2_fused_i3_fused] = ((0.000000e+00f < data[i0_i1_fused_i2_fused_i3_fused]) ? data[i0_i1_fused_i2_fused_i3_fused] : (data[i0_i1_fused_i2_fused_i3_fused] * 5.000000e-01f));\n  }\n}\n\n",
        "cuda_code": "extern \"C\" __global__ void __launch_bounds__(24) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 24) + ((int)threadIdx.x))] = ((0.000000e+00f < data[((((int)blockIdx.x) * 24) + ((int)threadIdx.x))]) ? data[((((int)blockIdx.x) * 24) + ((int)threadIdx.x))] : (data[((((int)blockIdx.x) * 24) + ((int)threadIdx.x))] * 5.000000e-01f));\n}\n\n",
        "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((3, 12, 18, 4), \"float32\"), compute: T.Buffer((3, 12, 18, 4), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused_i2_fused_i3_fused in T.parallel(2592):\n            compute_1 = T.Buffer((2592,), data=compute.data)\n            data_1 = T.Buffer((2592,), data=data.data)\n            compute_1[i0_i1_fused_i2_fused_i3_fused] = T.if_then_else(T.float32(0) < data_1[i0_i1_fused_i2_fused_i3_fused], data_1[i0_i1_fused_i2_fused_i3_fused], data_1[i0_i1_fused_i2_fused_i3_fused] * T.float32(0.5))",
        "op_args": [
            3,
            12,
            18,
            4
        ],
        "input_shape": [
            [
                3,
                12,
                18,
                4
            ]
        ],
        "output_shape": [
            [
                3,
                12,
                18,
                4
            ]
        ]
    },
    {
        "op_name": "log_softmax",
        "c_code": "void default_function_kernel(float* compute, float* data) {\n  float T_softmax_maxelem[495];\n  float compute_1[1];\n  for (int32_t i0 = 0; i0 < 15; ++i0) {\n    for (int32_t i1 = 0; i1 < 11; ++i1) {\n      for (int32_t i2 = 0; i2 < 3; ++i2) {\n        T_softmax_maxelem[(((i0 * 33) + (i1 * 3)) + i2)] = -3.402823e+38f;\n        for (int32_t k = 0; k < 4; ++k) {\n          T_softmax_maxelem[(((i0 * 33) + (i1 * 3)) + i2)] = max(T_softmax_maxelem[(((i0 * 33) + (i1 * 3)) + i2)], data[((((i0 * 132) + (i1 * 12)) + (i2 * 4)) + k)]);\n        }\n      }\n    }\n  }\n  for (int32_t i0_outer_outer_inner = 0; i0_outer_outer_inner < 5; ++i0_outer_outer_inner) {\n    for (int32_t i3_outer_outer_inner = 0; i3_outer_outer_inner < 4; ++i3_outer_outer_inner) {\n      for (int32_t i0_outer_inner = 0; i0_outer_inner < 3; ++i0_outer_inner) {\n        for (int32_t i1_outer_inner = 0; i1_outer_inner < 11; ++i1_outer_inner) {\n          for (int32_t i2_outer_inner = 0; i2_outer_inner < 3; ++i2_outer_inner) {\n            compute_1[0] = 0.000000e+00f;\n            for (int32_t k_1 = 0; k_1 < 4; ++k_1) {\n              compute_1[0] = (compute_1[0] + expf((data[(((((i0_outer_outer_inner * 396) + (i0_outer_inner * 132)) + (i1_outer_inner * 12)) + (i2_outer_inner * 4)) + k_1)] - T_softmax_maxelem[((((i0_outer_outer_inner * 99) + (i0_outer_inner * 33)) + (i1_outer_inner * 3)) + i2_outer_inner)])));\n            }\n            compute[(((((i0_outer_outer_inner * 396) + (i0_outer_inner * 132)) + (i1_outer_inner * 12)) + (i2_outer_inner * 4)) + i3_outer_outer_inner)] = ((data[(((((i0_outer_outer_inner * 396) + (i0_outer_inner * 132)) + (i1_outer_inner * 12)) + (i2_outer_inner * 4)) + i3_outer_outer_inner)] - T_softmax_maxelem[((((i0_outer_outer_inner * 99) + (i0_outer_inner * 33)) + (i1_outer_inner * 3)) + i2_outer_inner)]) - logf(compute_1[0]));\n          }\n        }\n      }\n    }\n  }\n}\n\n",
        "cuda_code": "extern \"C\" __global__ void __launch_bounds__(2) default_function_kernel_1(float* __restrict__ T_softmax_maxelem, float* __restrict__ compute, float* __restrict__ data) {\n  if (((((int)blockIdx.x) * 2) + ((int)threadIdx.x)) < 495) {\n    compute[((((int)blockIdx.x) * 2) + ((int)threadIdx.x))] = 0.000000e+00f;\n  }\n  for (int k = 0; k < 4; ++k) {\n    if (((((int)blockIdx.x) * 2) + ((int)threadIdx.x)) < 495) {\n      compute[((((int)blockIdx.x) * 2) + ((int)threadIdx.x))] = (compute[((((int)blockIdx.x) * 2) + ((int)threadIdx.x))] + __expf((data[(((((int)blockIdx.x) * 8) + (((int)threadIdx.x) * 4)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 2) + ((int)threadIdx.x))])));\n    }\n  }\n}\n\nextern \"C\" __global__ void __launch_bounds__(32) default_function_kernel_2(float* __restrict__ T_softmax_maxelem, float* __restrict__ compute, float* __restrict__ compute_1, float* __restrict__ data) {\n  if (((((int)blockIdx.x) * 8) + (((int)threadIdx.x) >> 2)) < 495) {\n    compute[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] = ((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[((((int)blockIdx.x) * 8) + (((int)threadIdx.x) >> 2))]) - __logf(compute_1[((((int)blockIdx.x) * 8) + (((int)threadIdx.x) >> 2))]));\n  }\n}\n\nextern \"C\" __global__ void __launch_bounds__(8) default_function_kernel(float* __restrict__ T_softmax_maxelem, float* __restrict__ data) {\n  if (((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) < 495) {\n    T_softmax_maxelem[((((int)blockIdx.x) * 8) + ((int)threadIdx.x))] = -3.402823e+38f;\n  }\n  for (int k = 0; k < 4; ++k) {\n    if (((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) < 495) {\n      T_softmax_maxelem[((((int)blockIdx.x) * 8) + ((int)threadIdx.x))] = max(T_softmax_maxelem[((((int)blockIdx.x) * 8) + ((int)threadIdx.x))], data[(((((int)blockIdx.x) * 32) + (((int)threadIdx.x) * 4)) + k)]);\n    }\n  }\n}\n\n",
        "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((15, 11, 3, 4), \"float32\"), compute: T.Buffer((15, 11, 3, 4), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        T_softmax_maxelem = T.allocate([495], \"float32\", \"global\")\n        compute_1 = T.allocate([1], \"float32\", \"global\")\n        T_softmax_maxelem_1 = T.Buffer((495,), data=T_softmax_maxelem)\n        data_1 = T.Buffer((1980,), data=data.data)\n        for i0, i1, i2 in T.grid(15, 11, 3):\n            T_softmax_maxelem_1[i0 * 33 + i1 * 3 + i2] = T.float32(-3.4028234663852886e+38)\n            for k in range(4):\n                cse_var_1: T.int32 = i0 * 33 + i1 * 3 + i2\n                T_softmax_maxelem_1[cse_var_1] = T.max(T_softmax_maxelem_1[cse_var_1], data_1[i0 * 132 + i1 * 12 + i2 * 4 + k])\n        for i0_outer_outer_inner, i3_outer_outer_inner, i0_outer_inner, i1_outer_inner, i2_outer_inner in T.grid(5, 4, 3, 11, 3):\n            cse_var_2: T.int32 = i0_outer_outer_inner * 396 + i0_outer_inner * 132 + i1_outer_inner * 12 + i2_outer_inner * 4 + i3_outer_outer_inner\n            compute_2 = T.Buffer((1,), data=compute_1, align=4)\n            compute_2[0] = T.float32(0)\n            for k in range(4):\n                compute_2[0] = compute_2[0] + T.exp(data_1[i0_outer_outer_inner * 396 + i0_outer_inner * 132 + i1_outer_inner * 12 + i2_outer_inner * 4 + k] - T_softmax_maxelem_1[i0_outer_outer_inner * 99 + i0_outer_inner * 33 + i1_outer_inner * 3 + i2_outer_inner])\n            compute_3 = T.Buffer((1980,), data=compute.data)\n            compute_3[cse_var_2] = data_1[cse_var_2] - T_softmax_maxelem_1[i0_outer_outer_inner * 99 + i0_outer_inner * 33 + i1_outer_inner * 3 + i2_outer_inner] - T.log(compute_2[0])",
        "op_args": [
            15,
            11,
            3,
            4
        ],
        "input_shape": [
            [
                15,
                11,
                3,
                4
            ]
        ],
        "output_shape": [
            [
                15,
                11,
                3,
                4
            ]
        ]
    },
    {
        "op_name": "negative",
        "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0 = 0; i0 < 4; ++i0) {\n    for (int32_t i1 = 0; i1 < 9; ++i1) {\n      for (int32_t i2 = 0; i2 < 6; ++i2) {\n        for (int32_t i3 = 0; i3 < 10; ++i3) {\n          compute[((((i0 * 540) + (i1 * 60)) + (i2 * 10)) + i3)] = (data[((((i0 * 540) + (i1 * 60)) + (i2 * 10)) + i3)] * -1.000000e+00f);\n        }\n      }\n    }\n  }\n}\n\n",
        "cuda_code": "extern \"C\" __global__ void __launch_bounds__(8) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 8) + ((int)threadIdx.x))] = (data[((((int)blockIdx.x) * 8) + ((int)threadIdx.x))] * -1.000000e+00f);\n}\n\n",
        "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((4, 9, 6, 10), \"float32\"), compute: T.Buffer((4, 9, 6, 10), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0 in T.parallel(4):\n            for i1, i2, i3 in T.grid(9, 6, 10):\n                cse_var_1: T.int32 = i0 * 540 + i1 * 60 + i2 * 10 + i3\n                compute_1 = T.Buffer((2160,), data=compute.data)\n                data_1 = T.Buffer((2160,), data=data.data)\n                compute_1[cse_var_1] = data_1[cse_var_1] * T.float32(-1)",
        "op_args": [
            4,
            9,
            6,
            10
        ],
        "input_shape": [
            [
                4,
                9,
                6,
                10
            ]
        ],
        "output_shape": [
            [
                4,
                9,
                6,
                10
            ]
        ]
    },
    {
        "op_name": "lrn",
        "c_code": "void default_function_kernel(float* T_divide, float* data) {\n  #pragma omp parallel for\n  for (int32_t ax0_ax1_fused_ax2_fused = 0; ax0_ax1_fused_ax2_fused < 1560; ++ax0_ax1_fused_ax2_fused) {\n    float tensor[1];\n    for (int32_t ax3 = 0; ax3 < 9; ++ax3) {\n      tensor[0] = 0.000000e+00f;\n      tensor[0] = (tensor[0] + (data[((ax0_ax1_fused_ax2_fused * 9) + ax3)] * data[((ax0_ax1_fused_ax2_fused * 9) + ax3)]));\n      T_divide[((ax0_ax1_fused_ax2_fused * 9) + ax3)] = (data[((ax0_ax1_fused_ax2_fused * 9) + ax3)] / powf((2.000000e+00f + (1.000000e-04f * tensor[0])), 7.500000e-01f));\n    }\n  }\n}\n\n",
        "cuda_code": "extern \"C\" __global__ void __launch_bounds__(26) default_function_kernel_1(float* __restrict__ T_divide, float* __restrict__ data, float* __restrict__ tensor) {\n  T_divide[((((int)blockIdx.x) * 26) + ((int)threadIdx.x))] = (data[((((int)blockIdx.x) * 26) + ((int)threadIdx.x))] / powf((2.000000e+00f + (1.000000e-04f * tensor[((((int)blockIdx.x) * 26) + ((int)threadIdx.x))])), 7.500000e-01f));\n}\n\nextern \"C\" __global__ void __launch_bounds__(64) default_function_kernel(float* __restrict__ data, float* __restrict__ tensor) {\n  if (((((int)blockIdx.x) * 8) + (((int)threadIdx.x) >> 3)) < 1755) {\n    tensor[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))] = 0.000000e+00f;\n  }\n  if (((((int)blockIdx.x) * 8) + (((int)threadIdx.x) >> 3)) < 1755) {\n    tensor[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))] = (tensor[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))] + (data[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))] * data[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))]));\n  }\n}\n\n",
        "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((12, 10, 13, 9), \"float32\"), T_divide: T.Buffer((12, 10, 13, 9), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0_ax1_fused_ax2_fused in T.parallel(1560):\n            tensor = T.allocate([1], \"float32\", \"global\")\n            for ax3 in range(9):\n                cse_var_1: T.int32 = ax0_ax1_fused_ax2_fused * 9 + ax3\n                tensor_1 = T.Buffer((1,), data=tensor, align=4)\n                tensor_1[0] = T.float32(0)\n                data_1 = T.Buffer((14040,), data=data.data)\n                tensor_1[0] = tensor_1[0] + data_1[cse_var_1] * data_1[cse_var_1]\n                T_divide_1 = T.Buffer((14040,), data=T_divide.data)\n                T_divide_1[cse_var_1] = data_1[cse_var_1] / T.pow(T.float32(2) + T.float32(9.9999997473787516e-05) * tensor_1[0], T.float32(0.75))",
        "op_args": [
            12,
            10,
            13,
            9
        ],
        "input_shape": [
            [
                12,
                10,
                13,
                9
            ]
        ],
        "output_shape": [
            [
                12,
                10,
                13,
                9
            ]
        ]
    },
    {
        "op_name": "prod",
        "c_code": "void default_function_kernel(float* data, float* data_red) {\n  float data_red_rf[21];\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_inner_init = 0; k0_k1_fused_k2_fused_k3_fused_inner_init < 21; ++k0_k1_fused_k2_fused_k3_fused_inner_init) {\n    data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner_init] = 1.000000e+00f;\n  }\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_outer = 0; k0_k1_fused_k2_fused_k3_fused_outer < 300; ++k0_k1_fused_k2_fused_k3_fused_outer) {\n    for (int32_t k0_k1_fused_k2_fused_k3_fused_inner = 0; k0_k1_fused_k2_fused_k3_fused_inner < 21; ++k0_k1_fused_k2_fused_k3_fused_inner) {\n      data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner] = (data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner] * data[((k0_k1_fused_k2_fused_k3_fused_outer * 21) + k0_k1_fused_k2_fused_k3_fused_inner)]);\n    }\n  }\n  data_red[0] = 1.000000e+00f;\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_inner_v = 0; k0_k1_fused_k2_fused_k3_fused_inner_v < 21; ++k0_k1_fused_k2_fused_k3_fused_inner_v) {\n    data_red[0] = (data_red[0] * data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner_v]);\n  }\n}\n\n",
        "cuda_code": "extern \"C\" __global__ void default_function_kernel(float* __restrict__ data, float* __restrict__ data_red) {\n  data_red[0] = 1.000000e+00f;\n  for (int k0 = 0; k0 < 15; ++k0) {\n    for (int k1 = 0; k1 < 20; ++k1) {\n      for (int k2 = 0; k2 < 3; ++k2) {\n        for (int k3 = 0; k3 < 7; ++k3) {\n          data_red[0] = (data_red[0] * data[((((k0 * 420) + (k1 * 21)) + (k2 * 7)) + k3)]);\n        }\n      }\n    }\n  }\n}\n\n",
        "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((15, 20, 3, 7), \"float32\"), data_red: T.Buffer((), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        data_red_rf = T.allocate([21], \"float32\", \"global\")\n        data_red_rf_1 = T.Buffer((21,), data=data_red_rf)\n        for k0_k1_fused_k2_fused_k3_fused_inner_init in range(21):\n            data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner_init] = T.float32(1)\n        for k0_k1_fused_k2_fused_k3_fused_outer, k0_k1_fused_k2_fused_k3_fused_inner in T.grid(300, 21):\n            data_1 = T.Buffer((6300,), data=data.data)\n            data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner] = data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner] * data_1[k0_k1_fused_k2_fused_k3_fused_outer * 21 + k0_k1_fused_k2_fused_k3_fused_inner]\n        data_red_1 = T.Buffer((1,), data=data_red.data)\n        data_red_1[0] = T.float32(1)\n        for k0_k1_fused_k2_fused_k3_fused_inner_v in range(21):\n            data_red_1[0] = data_red_1[0] * data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner_v]",
        "op_args": [
            15,
            20,
            3,
            7
        ],
        "input_shape": [
            [
                15,
                20,
                3,
                7
            ]
        ],
        "output_shape": [
            []
        ]
    },
    {
        "op_name": "mirror_pad",
        "c_code": "void default_function_kernel(float* MirrorPadInput, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0 = 0; i0 < 5; ++i0) {\n    for (int32_t i1 = 0; i1 < 9; ++i1) {\n      MirrorPadInput[((i0 * 9) + i1)] = data[((((3 <= i0) ? (4 - i0) : ((i0 < 1) ? (0 - i0) : (i0 - 1))) * 6) + ((i1 == 8) ? (13 - i1) : ((i1 < 2) ? (1 - i1) : (i1 - 2))))];\n    }\n  }\n}\n\n",
        "cuda_code": "extern \"C\" __global__ void __launch_bounds__(11) default_function_kernel(float* __restrict__ MirrorPadInput, float* __restrict__ data) {\n  if (((((int)blockIdx.x) * 11) + ((int)threadIdx.x)) < 45) {\n    MirrorPadInput[((((int)blockIdx.x) * 11) + ((int)threadIdx.x))] = data[((((27 <= ((((int)blockIdx.x) * 11) + ((int)threadIdx.x))) ? (4 - (((((int)blockIdx.x) * 11) + ((int)threadIdx.x)) / 9)) : ((((((int)blockIdx.x) * 11) + ((int)threadIdx.x)) < 9) ? 0 : ((((((int)blockIdx.x) * 11) + ((int)threadIdx.x)) / 9) - 1))) * 6) + (((((((int)blockIdx.x) * 2) + ((int)threadIdx.x)) % 9) == 8) ? (13 - (((((int)blockIdx.x) * 2) + ((int)threadIdx.x)) % 9)) : (((((((int)blockIdx.x) * 2) + ((int)threadIdx.x)) % 9) < 2) ? (1 - (((((int)blockIdx.x) * 2) + ((int)threadIdx.x)) % 9)) : ((((((int)blockIdx.x) * 2) + ((int)threadIdx.x)) % 9) - 2))))];\n  }\n}\n\n",
        "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((2, 6), \"float32\"), MirrorPadInput: T.Buffer((5, 9), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0 in T.parallel(5):\n            for i1 in range(9):\n                MirrorPadInput_1 = T.Buffer((45,), data=MirrorPadInput.data)\n                data_1 = T.Buffer((12,), data=data.data)\n                MirrorPadInput_1[i0 * 9 + i1] = data_1[T.if_then_else(3 <= i0, 4 - i0, T.if_then_else(i0 < 1, 0 - i0, i0 - 1)) * 6 + T.if_then_else(i1 == 8, 13 - i1, T.if_then_else(i1 < 2, 1 - i1, i1 - 2))]",
        "op_args": [
            14,
            16,
            2,
            6
        ],
        "input_shape": [
            [
                2,
                6
            ]
        ],
        "output_shape": [
            [
                5,
                9
            ]
        ]
    },
    {
        "op_name": "round",
        "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0 = 0; i0 < 17; ++i0) {\n    for (int32_t i2 = 0; i2 < 2; ++i2) {\n      for (int32_t i3 = 0; i3 < 11; ++i3) {\n        compute[(((i0 * 22) + (i2 * 11)) + i3)] = roundf(data[(((i0 * 22) + (i2 * 11)) + i3)]);\n      }\n    }\n  }\n}\n\n",
        "cuda_code": "extern \"C\" __global__ void __launch_bounds__(3) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  if (((((int)blockIdx.x) * 3) + ((int)threadIdx.x)) < 374) {\n    compute[((((int)blockIdx.x) * 3) + ((int)threadIdx.x))] = roundf(data[((((int)blockIdx.x) * 3) + ((int)threadIdx.x))]);\n  }\n}\n\n",
        "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((17, 1, 2, 11), \"float32\"), compute: T.Buffer((17, 1, 2, 11), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0 in T.parallel(17):\n            for i2, i3 in T.grid(2, 11):\n                cse_var_1: T.int32 = i0 * 22 + i2 * 11 + i3\n                compute_1 = T.Buffer((374,), data=compute.data)\n                data_1 = T.Buffer((374,), data=data.data)\n                compute_1[cse_var_1] = T.round(data_1[cse_var_1])",
        "op_args": [
            17,
            1,
            2,
            11
        ],
        "input_shape": [
            [
                17,
                1,
                2,
                11
            ]
        ],
        "output_shape": [
            [
                17,
                1,
                2,
                11
            ]
        ]
    },
    {
        "op_name": "pool1d",
        "c_code": "void default_function_kernel(float* data, float* pool_max) {\n  #pragma omp parallel for\n  for (int32_t ax0 = 0; ax0 < 19; ++ax0) {\n    float pad_temp[13];\n    for (int32_t ax2_s = 0; ax2_s < 13; ++ax2_s) {\n      pad_temp[ax2_s] = (((1 <= ax2_s) && (ax2_s < 12)) ? data[(((ax0 * 11) + ax2_s) - 1)] : -3.402823e+38f);\n    }\n    for (int32_t ax2 = 0; ax2 < 6; ++ax2) {\n      pool_max[((ax0 * 6) + ax2)] = -3.402823e+38f;\n      for (int32_t rv0 = 0; rv0 < 3; ++rv0) {\n        pool_max[((ax0 * 6) + ax2)] = max(pool_max[((ax0 * 6) + ax2)], pad_temp[((ax2 * 2) + rv0)]);\n      }\n    }\n  }\n}\n\n",
        "cuda_code": "extern \"C\" __global__ void __launch_bounds__(7) default_function_kernel(float* __restrict__ data, float* __restrict__ pool_max) {\n  if (((((int)blockIdx.x) * 7) + ((int)threadIdx.x)) < 114) {\n    pool_max[((((int)blockIdx.x) * 7) + ((int)threadIdx.x))] = -3.402823e+38f;\n  }\n  for (int rv0 = 0; rv0 < 3; ++rv0) {\n    if (((((int)blockIdx.x) * 7) + ((int)threadIdx.x)) < 114) {\n      pool_max[((((int)blockIdx.x) * 7) + ((int)threadIdx.x))] = max(pool_max[((((int)blockIdx.x) * 7) + ((int)threadIdx.x))], (((1 <= ((((((int)blockIdx.x) + ((int)threadIdx.x)) % 6) * 2) + rv0)) && (((rv0 >> 1) + ((((int)blockIdx.x) + ((int)threadIdx.x)) % 6)) < 6)) ? data[(((((((((int)blockIdx.x) * 7) + ((int)threadIdx.x)) / 6) * 11) + (((((int)blockIdx.x) + ((int)threadIdx.x)) % 6) * 2)) + rv0) - 1)] : -3.402823e+38f));\n    }\n  }\n}\n\n",
        "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((19, 1, 11), \"float32\"), pool_max: T.Buffer((19, 1, 6), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0 in T.parallel(19):\n            pad_temp = T.allocate([13], \"float32\", \"global\")\n            pad_temp_1 = T.Buffer((13,), data=pad_temp, align=32)\n            for ax2_s in range(13):\n                data_1 = T.Buffer((209,), data=data.data)\n                pad_temp_1[ax2_s] = T.if_then_else(1 <= ax2_s and ax2_s < 12, data_1[ax0 * 11 + ax2_s - 1], T.float32(-3.4028234663852886e+38))\n            for ax2 in range(6):\n                pool_max_1 = T.Buffer((114,), data=pool_max.data)\n                pool_max_1[ax0 * 6 + ax2] = T.float32(-3.4028234663852886e+38)\n                for rv0 in range(3):\n                    cse_var_1: T.int32 = ax0 * 6 + ax2\n                    pool_max_1[cse_var_1] = T.max(pool_max_1[cse_var_1], pad_temp_1[ax2 * 2 + rv0])",
        "op_args": [
            19,
            1,
            5,
            11
        ],
        "input_shape": [
            [
                19,
                1,
                11
            ]
        ],
        "output_shape": [
            [
                19,
                1,
                6
            ]
        ]
    },
    {
        "op_name": "shape",
        "c_code": "void default_function_kernel(int32_t* T_shape) {\n  #pragma omp parallel for\n  for (int32_t ax0 = 0; ax0 < 4; ++ax0) {\n    T_shape[ax0] = ((ax0 == 3) ? 11 : ((ax0 == 2) ? 1 : ((ax0 == 1) ? 5 : 14)));\n  }\n}\n\n",
        "cuda_code": "extern \"C\" __global__ void __launch_bounds__(4) default_function_kernel(int* __restrict__ T_shape) {\n  T_shape[((int)threadIdx.x)] = ((((int)threadIdx.x) == 3) ? 11 : ((((int)threadIdx.x) == 2) ? 1 : ((((int)threadIdx.x) == 1) ? 5 : 14)));\n}\n\n",
        "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((14, 5, 1, 11), \"float32\"), T_shape: T.Buffer((4,), \"int32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0 in T.parallel(4):\n            T_shape[ax0] = T.if_then_else(ax0 == 3, 11, T.if_then_else(ax0 == 2, 1, T.if_then_else(ax0 == 1, 5, 14)))",
        "op_args": [
            14,
            5,
            1,
            11
        ],
        "input_shape": [
            [
                14,
                5,
                1,
                11
            ]
        ],
        "output_shape": [
            [
                4
            ]
        ]
    },
    {
        "op_name": "pool2d",
        "c_code": "void default_function_kernel(float* data, float* pool_max) {\n  #pragma omp parallel for\n  for (int32_t ax0 = 0; ax0 < 11; ++ax0) {\n    float pad_temp[247];\n    for (int32_t ax1 = 0; ax1 < 3; ++ax1) {\n      for (int32_t ax2 = 0; ax2 < 19; ++ax2) {\n        for (int32_t ax3_s = 0; ax3_s < 13; ++ax3_s) {\n          pad_temp[((ax2 * 13) + ax3_s)] = (((1 <= ax2) && (1 <= ax3_s)) ? data[(((((ax0 * 648) + (ax1 * 216)) + (ax2 * 12)) + ax3_s) - 13)] : -3.402823e+38f);\n        }\n      }\n      for (int32_t ax2_1 = 0; ax2_1 < 9; ++ax2_1) {\n        for (int32_t ax3 = 0; ax3 < 6; ++ax3) {\n          pool_max[((((ax0 * 162) + (ax1 * 54)) + (ax2_1 * 6)) + ax3)] = -3.402823e+38f;\n          for (int32_t rv0 = 0; rv0 < 3; ++rv0) {\n            for (int32_t rv1 = 0; rv1 < 3; ++rv1) {\n              pool_max[((((ax0 * 162) + (ax1 * 54)) + (ax2_1 * 6)) + ax3)] = max(pool_max[((((ax0 * 162) + (ax1 * 54)) + (ax2_1 * 6)) + ax3)], pad_temp[((((ax2_1 * 26) + (rv0 * 13)) + (ax3 * 2)) + rv1)]);\n            }\n          }\n        }\n      }\n    }\n  }\n}\n\n",
        "cuda_code": "extern \"C\" __global__ void __launch_bounds__(6) default_function_kernel(float* __restrict__ data, float* __restrict__ pool_max) {\n  pool_max[((((int)blockIdx.x) * 6) + ((int)threadIdx.x))] = -3.402823e+38f;\n  for (int rv0 = 0; rv0 < 3; ++rv0) {\n    for (int rv1 = 0; rv1 < 3; ++rv1) {\n      pool_max[((((int)blockIdx.x) * 6) + ((int)threadIdx.x))] = max(pool_max[((((int)blockIdx.x) * 6) + ((int)threadIdx.x))], (((1 <= (((((int)blockIdx.x) % 9) * 2) + rv0)) && (1 <= ((((int)threadIdx.x) * 2) + rv1))) ? data[(((((((int)blockIdx.x) * 24) + (rv0 * 12)) + (((int)threadIdx.x) * 2)) + rv1) - 13)] : -3.402823e+38f));\n    }\n  }\n}\n\n",
        "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((11, 3, 18, 12), \"float32\"), pool_max: T.Buffer((11, 3, 9, 6), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0 in T.parallel(11):\n            pad_temp = T.allocate([247], \"float32\", \"global\")\n            for ax1 in range(3):\n                pad_temp_1 = T.Buffer((247,), data=pad_temp)\n                for ax2, ax3_s in T.grid(19, 13):\n                    data_1 = T.Buffer((7128,), data=data.data)\n                    pad_temp_1[ax2 * 13 + ax3_s] = T.if_then_else(1 <= ax2 and 1 <= ax3_s, data_1[ax0 * 648 + ax1 * 216 + ax2 * 12 + ax3_s - 13], T.float32(-3.4028234663852886e+38))\n                for ax2, ax3 in T.grid(9, 6):\n                    pool_max_1 = T.Buffer((1782,), data=pool_max.data)\n                    pool_max_1[ax0 * 162 + ax1 * 54 + ax2 * 6 + ax3] = T.float32(-3.4028234663852886e+38)\n                    for rv0, rv1 in T.grid(3, 3):\n                        cse_var_1: T.int32 = ax0 * 162 + ax1 * 54 + ax2 * 6 + ax3\n                        pool_max_1[cse_var_1] = T.max(pool_max_1[cse_var_1], pad_temp_1[ax2 * 26 + rv0 * 13 + ax3 * 2 + rv1])",
        "op_args": [
            11,
            3,
            18,
            4
        ],
        "input_shape": [
            [
                11,
                3,
                18,
                12
            ]
        ],
        "output_shape": [
            [
                11,
                3,
                9,
                6
            ]
        ]
    },
    {
        "op_name": "sigmoid",
        "c_code": "void default_function_kernel(float* compute, float* data) {\n  for (int32_t i1 = 0; i1 < 7; ++i1) {\n    for (int32_t i2 = 0; i2 < 17; ++i2) {\n      for (int32_t i3 = 0; i3 < 4; ++i3) {\n        compute[(((i1 * 68) + (i2 * 4)) + i3)] = (1.000000e+00f / (1.000000e+00f + expf((0.000000e+00f - data[(((i1 * 68) + (i2 * 4)) + i3)]))));\n      }\n    }\n  }\n}\n\n",
        "cuda_code": "extern \"C\" __global__ void __launch_bounds__(7) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 7) + ((int)threadIdx.x))] = (1.000000e+00f / (1.000000e+00f + __expf((0.000000e+00f - data[((((int)blockIdx.x) * 7) + ((int)threadIdx.x))]))));\n}\n\n",
        "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((1, 7, 17, 4), \"float32\"), compute: T.Buffer((1, 7, 17, 4), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i1, i2, i3 in T.grid(7, 17, 4):\n            cse_var_1: T.int32 = i1 * 68 + i2 * 4 + i3\n            compute_1 = T.Buffer((476,), data=compute.data)\n            data_1 = T.Buffer((476,), data=data.data)\n            compute_1[cse_var_1] = T.sigmoid(data_1[cse_var_1])",
        "op_args": [
            1,
            7,
            17,
            4
        ],
        "input_shape": [
            [
                1,
                7,
                17,
                4
            ]
        ],
        "output_shape": [
            [
                1,
                7,
                17,
                4
            ]
        ]
    },
    {
        "op_name": "pool3d",
        "c_code": "void default_function_kernel(float* data, float* pool_max) {\n  #pragma omp parallel for\n  for (int32_t ax0_ax1_fused = 0; ax0_ax1_fused < 170; ++ax0_ax1_fused) {\n    float pad_temp[27];\n    for (int32_t ax2 = 0; ax2 < 4; ++ax2) {\n      for (int32_t ax3 = 0; ax3 < 4; ++ax3) {\n        for (int32_t ax4 = 0; ax4 < 8; ++ax4) {\n          for (int32_t ax2_1 = 0; ax2_1 < 3; ++ax2_1) {\n            for (int32_t ax3_1 = 0; ax3_1 < 3; ++ax3_1) {\n              for (int32_t ax4_s = 0; ax4_s < 3; ++ax4_s) {\n                pad_temp[(((ax2_1 * 9) + (ax3_1 * 3)) + ax4_s)] = (((((1 <= ((ax2 * 2) + ax2_1)) && (((ax2_1 >> 1) + ax2) < 4)) && (1 <= ((ax3 * 2) + ax3_1))) && (1 <= ((ax4 * 2) + ax4_s))) ? data[((((((((ax0_ax1_fused * 896) + (ax2 * 256)) + (ax2_1 * 128)) + (ax3 * 32)) + (ax3_1 * 16)) + (ax4 * 2)) + ax4_s) - 145)] : -3.402823e+38f);\n              }\n            }\n          }\n          pool_max[((((ax0_ax1_fused * 128) + (ax2 * 32)) + (ax3 * 8)) + ax4)] = -3.402823e+38f;\n          for (int32_t rv0 = 0; rv0 < 3; ++rv0) {\n            for (int32_t rv1 = 0; rv1 < 3; ++rv1) {\n              for (int32_t rv2 = 0; rv2 < 3; ++rv2) {\n                pool_max[((((ax0_ax1_fused * 128) + (ax2 * 32)) + (ax3 * 8)) + ax4)] = max(pool_max[((((ax0_ax1_fused * 128) + (ax2 * 32)) + (ax3 * 8)) + ax4)], pad_temp[(((rv0 * 9) + (rv1 * 3)) + rv2)]);\n              }\n            }\n          }\n        }\n      }\n    }\n  }\n}\n\n",
        "cuda_code": "extern \"C\" __global__ void __launch_bounds__(64) default_function_kernel(float* __restrict__ data, float* __restrict__ pool_max) {\n  pool_max[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))] = -3.402823e+38f;\n  for (int rv0 = 0; rv0 < 3; ++rv0) {\n    for (int rv1 = 0; rv1 < 3; ++rv1) {\n      for (int rv2 = 0; rv2 < 3; ++rv2) {\n        pool_max[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))] = max(pool_max[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))], (((((1 <= ((((((int)blockIdx.x) & 1) * 4) + ((((int)threadIdx.x) >> 5) * 2)) + rv0)) && (((((((int)threadIdx.x) >> 5) + (rv0 >> 1)) >> 1) + (((int)blockIdx.x) & 1)) < 2)) && (1 <= ((((((int)threadIdx.x) & 31) >> 3) * 2) + rv1))) && (1 <= (((((int)threadIdx.x) & 7) * 2) + rv2))) ? data[((((((((((((int)blockIdx.x) >> 1) * 896) + ((((int)blockIdx.x) & 1) * 512)) + ((((int)threadIdx.x) >> 5) * 256)) + (rv0 * 128)) + (((((int)threadIdx.x) & 31) >> 3) * 32)) + (rv1 * 16)) + ((((int)threadIdx.x) & 7) * 2)) + rv2) - 145)] : -3.402823e+38f));\n      }\n    }\n  }\n}\n\n",
        "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((10, 17, 7, 8, 16), \"float32\"), pool_max: T.Buffer((10, 17, 4, 4, 8), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0_ax1_fused in T.parallel(170):\n            pad_temp = T.allocate([27], \"float32\", \"global\")\n            for ax2, ax3, ax4 in T.grid(4, 4, 8):\n                pad_temp_1 = T.Buffer((27,), data=pad_temp)\n                for ax2_1, ax3_1, ax4_s in T.grid(3, 3, 3):\n                    cse_var_1: T.int32 = ax4 * 2\n                    data_1 = T.Buffer((152320,), data=data.data)\n                    pad_temp_1[ax2_1 * 9 + ax3_1 * 3 + ax4_s] = T.if_then_else(1 <= ax2 * 2 + ax2_1 and ax2_1 // 2 + ax2 < 4 and 1 <= ax3 * 2 + ax3_1 and 1 <= cse_var_1 + ax4_s, data_1[ax0_ax1_fused * 896 + ax2 * 256 + ax2_1 * 128 + ax3 * 32 + ax3_1 * 16 + cse_var_1 + ax4_s - 145], T.float32(-3.4028234663852886e+38))\n                pool_max_1 = T.Buffer((21760,), data=pool_max.data)\n                pool_max_1[ax0_ax1_fused * 128 + ax2 * 32 + ax3 * 8 + ax4] = T.float32(-3.4028234663852886e+38)\n                for rv0, rv1, rv2 in T.grid(3, 3, 3):\n                    cse_var_2: T.int32 = ax0_ax1_fused * 128 + ax2 * 32 + ax3 * 8 + ax4\n                    pool_max_1[cse_var_2] = T.max(pool_max_1[cse_var_2], pad_temp_1[rv0 * 9 + rv1 * 3 + rv2])",
        "op_args": [
            10,
            17,
            7,
            8
        ],
        "input_shape": [
            [
                10,
                17,
                7,
                8,
                16
            ]
        ],
        "output_shape": [
            [
                10,
                17,
                4,
                4,
                8
            ]
        ]
    },
    {
        "op_name": "sign",
        "c_code": "void default_function_kernel(float* T_sign, float* data) {\n  #pragma omp parallel for\n  for (int32_t ax0_ax1_fused_ax2_fused_ax3_fused = 0; ax0_ax1_fused_ax2_fused_ax3_fused < 1248; ++ax0_ax1_fused_ax2_fused_ax3_fused) {\n    T_sign[ax0_ax1_fused_ax2_fused_ax3_fused] = ((0.000000e+00f < data[ax0_ax1_fused_ax2_fused_ax3_fused]) ? 1.000000e+00f : ((data[ax0_ax1_fused_ax2_fused_ax3_fused] < 0.000000e+00f) ? -1.000000e+00f : 0.000000e+00f));\n  }\n}\n\n",
        "cuda_code": "extern \"C\" __global__ void __launch_bounds__(16) default_function_kernel(float* __restrict__ T_sign, float* __restrict__ data) {\n  T_sign[((((int)blockIdx.x) * 16) + ((int)threadIdx.x))] = ((0.000000e+00f < data[((((int)blockIdx.x) * 16) + ((int)threadIdx.x))]) ? 1.000000e+00f : ((data[((((int)blockIdx.x) * 16) + ((int)threadIdx.x))] < 0.000000e+00f) ? -1.000000e+00f : 0.000000e+00f));\n}\n\n",
        "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((16, 2, 13, 3), \"float32\"), T_sign: T.Buffer((16, 2, 13, 3), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0_ax1_fused_ax2_fused_ax3_fused in T.parallel(1248):\n            T_sign_1 = T.Buffer((1248,), data=T_sign.data)\n            data_1 = T.Buffer((1248,), data=data.data)\n            T_sign_1[ax0_ax1_fused_ax2_fused_ax3_fused] = T.if_then_else(T.float32(0) < data_1[ax0_ax1_fused_ax2_fused_ax3_fused], T.float32(1), T.Select(data_1[ax0_ax1_fused_ax2_fused_ax3_fused] < T.float32(0), T.float32(-1), T.float32(0)))",
        "op_args": [
            16,
            2,
            13,
            3
        ],
        "input_shape": [
            [
                16,
                2,
                13,
                3
            ]
        ],
        "output_shape": [
            [
                16,
                2,
                13,
                3
            ]
        ]
    },
    {
        "op_name": "relu",
        "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused_i3_fused = 0; i0_i1_fused_i2_fused_i3_fused < 6930; ++i0_i1_fused_i2_fused_i3_fused) {\n    compute[i0_i1_fused_i2_fused_i3_fused] = max(data[i0_i1_fused_i2_fused_i3_fused], 0.000000e+00f);\n  }\n}\n\n",
        "cuda_code": "extern \"C\" __global__ void __launch_bounds__(63) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 63) + ((int)threadIdx.x))] = max(data[((((int)blockIdx.x) * 63) + ((int)threadIdx.x))], 0.000000e+00f);\n}\n\n",
        "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((15, 14, 3, 11), \"float32\"), compute: T.Buffer((15, 14, 3, 11), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused_i2_fused_i3_fused in T.parallel(6930):\n            compute_1 = T.Buffer((6930,), data=compute.data)\n            data_1 = T.Buffer((6930,), data=data.data)\n            compute_1[i0_i1_fused_i2_fused_i3_fused] = T.max(data_1[i0_i1_fused_i2_fused_i3_fused], T.float32(0))",
        "op_args": [
            15,
            14,
            3,
            11
        ],
        "input_shape": [
            [
                15,
                14,
                3,
                11
            ]
        ],
        "output_shape": [
            [
                15,
                14,
                3,
                11
            ]
        ]
    },
    {
        "op_name": "sqrt",
        "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0 = 0; i0 < 7; ++i0) {\n    for (int32_t i1 = 0; i1 < 20; ++i1) {\n      for (int32_t i2 = 0; i2 < 9; ++i2) {\n        compute[(((i0 * 180) + (i1 * 9)) + i2)] = sqrtf(data[(((i0 * 180) + (i1 * 9)) + i2)]);\n      }\n    }\n  }\n}\n\n",
        "cuda_code": "extern \"C\" __global__ void __launch_bounds__(36) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 36) + ((int)threadIdx.x))] = sqrtf(data[((((int)blockIdx.x) * 36) + ((int)threadIdx.x))]);\n}\n\n",
        "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((7, 20, 9, 1), \"float32\"), compute: T.Buffer((7, 20, 9, 1), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0 in T.parallel(7):\n            for i1, i2 in T.grid(20, 9):\n                cse_var_1: T.int32 = i0 * 180 + i1 * 9 + i2\n                compute_1 = T.Buffer((1260,), data=compute.data)\n                data_1 = T.Buffer((1260,), data=data.data)\n                compute_1[cse_var_1] = T.sqrt(data_1[cse_var_1])",
        "op_args": [
            7,
            20,
            9,
            1
        ],
        "input_shape": [
            [
                7,
                20,
                9,
                1
            ]
        ],
        "output_shape": [
            [
                7,
                20,
                9,
                1
            ]
        ]
    },
    {
        "op_name": "scale_shift_nchw",
        "c_code": "void default_function_kernel(float* Scale, float* ScaleShift, float* Shift, float* data) {\n  #pragma omp parallel for\n  for (int32_t b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_b_outer_inner_fused_c_outer_inner_fused_i_outer_inner_fused = 0; b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_b_outer_inner_fused_c_outer_inner_fused_i_outer_inner_fused < 1482; ++b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_b_outer_inner_fused_c_outer_inner_fused_i_outer_inner_fused) {\n    for (int32_t b_inner = 0; b_inner < 5; ++b_inner) {\n      for (int32_t i_inner = 0; i_inner < 6; ++i_inner) {\n        ScaleShift[((((((b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_b_outer_inner_fused_c_outer_inner_fused_i_outer_inner_fused / 741) * 22230) + (b_inner * 4446)) + (((b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_b_outer_inner_fused_c_outer_inner_fused_i_outer_inner_fused % 741) / 19) * 114)) + (i_inner * 19)) + (b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_b_outer_inner_fused_c_outer_inner_fused_i_outer_inner_fused % 19))] = ((data[((((((b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_b_outer_inner_fused_c_outer_inner_fused_i_outer_inner_fused / 741) * 22230) + (b_inner * 4446)) + (((b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_b_outer_inner_fused_c_outer_inner_fused_i_outer_inner_fused % 741) / 19) * 114)) + (i_inner * 19)) + (b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_b_outer_inner_fused_c_outer_inner_fused_i_outer_inner_fused % 19))] * Scale[((b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_b_outer_inner_fused_c_outer_inner_fused_i_outer_inner_fused % 741) / 57)]) + Shift[((b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_b_outer_inner_fused_c_outer_inner_fused_i_outer_inner_fused % 741) / 57)]);\n      }\n    }\n  }\n}\n\n",
        "cuda_code": "extern \"C\" __global__ void __launch_bounds__(32) default_function_kernel(float* __restrict__ Scale, float* __restrict__ ScaleShift, float* __restrict__ Shift, float* __restrict__ data) {\n  if (((((int)blockIdx.x) * 8) + (((int)threadIdx.x) >> 2)) < 11115) {\n    ScaleShift[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] = ((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] * Scale[((((((int)blockIdx.x) * 16) + (((int)threadIdx.x) >> 1)) % 2223) / 171)]) + Shift[((((((int)blockIdx.x) * 16) + (((int)threadIdx.x) >> 1)) % 2223) / 171)]);\n  }\n}\n\n",
        "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((10, 13, 18, 19), \"float32\"), Scale: T.Buffer((13,), \"float32\"), Shift: T.Buffer((13,), \"float32\"), ScaleShift: T.Buffer((10, 13, 18, 19), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_b_outer_inner_fused_c_outer_inner_fused_i_outer_inner_fused in T.parallel(1482):\n            for b_inner, i_inner in T.grid(5, 6):\n                cse_var_3: T.int32 = b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_b_outer_inner_fused_c_outer_inner_fused_i_outer_inner_fused % 741\n                cse_var_2: T.int32 = cse_var_3 // 57\n                cse_var_1: T.int32 = b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_b_outer_inner_fused_c_outer_inner_fused_i_outer_inner_fused // 741 * 22230 + b_inner * 4446 + cse_var_3 // 19 * 114 + i_inner * 19 + b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_b_outer_inner_fused_c_outer_inner_fused_i_outer_inner_fused % 19\n                ScaleShift_1 = T.Buffer((44460,), data=ScaleShift.data)\n                data_1 = T.Buffer((44460,), data=data.data)\n                ScaleShift_1[cse_var_1] = data_1[cse_var_1] * Scale[cse_var_2] + Shift[cse_var_2]",
        "op_args": [
            10,
            13,
            18,
            19
        ],
        "input_shape": [
            [
                10,
                13,
                18,
                19
            ],
            [
                13
            ],
            [
                13
            ]
        ],
        "output_shape": [
            [
                10,
                13,
                18,
                19
            ]
        ]
    },
    {
        "op_name": "tan",
        "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0 = 0; i0 < 13; ++i0) {\n    for (int32_t i1 = 0; i1 < 6; ++i1) {\n      for (int32_t i2 = 0; i2 < 11; ++i2) {\n        for (int32_t i3 = 0; i3 < 20; ++i3) {\n          compute[((((i0 * 1320) + (i1 * 220)) + (i2 * 20)) + i3)] = tanf(data[((((i0 * 1320) + (i1 * 220)) + (i2 * 20)) + i3)]);\n        }\n      }\n    }\n  }\n}\n\n",
        "cuda_code": "extern \"C\" __global__ void __launch_bounds__(55) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 55) + ((int)threadIdx.x))] = tanf(data[((((int)blockIdx.x) * 55) + ((int)threadIdx.x))]);\n}\n\n",
        "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((13, 6, 11, 20), \"float32\"), compute: T.Buffer((13, 6, 11, 20), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0 in T.parallel(13):\n            for i1, i2, i3 in T.grid(6, 11, 20):\n                cse_var_1: T.int32 = i0 * 1320 + i1 * 220 + i2 * 20 + i3\n                compute_1 = T.Buffer((17160,), data=compute.data)\n                data_1 = T.Buffer((17160,), data=data.data)\n                compute_1[cse_var_1] = T.tan(data_1[cse_var_1])",
        "op_args": [
            13,
            6,
            11,
            20
        ],
        "input_shape": [
            [
                13,
                6,
                11,
                20
            ]
        ],
        "output_shape": [
            [
                13,
                6,
                11,
                20
            ]
        ]
    },
    {
        "op_name": "prelu",
        "c_code": "void default_function_kernel(float* Scale, float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused_i3_fused = 0; i0_i1_fused_i2_fused_i3_fused < 46512; ++i0_i1_fused_i2_fused_i3_fused) {\n    compute[i0_i1_fused_i2_fused_i3_fused] = ((0.000000e+00f < data[i0_i1_fused_i2_fused_i3_fused]) ? data[i0_i1_fused_i2_fused_i3_fused] : (data[i0_i1_fused_i2_fused_i3_fused] * Scale[(i0_i1_fused_i2_fused_i3_fused % 19)]));\n  }\n}\n\n",
        "cuda_code": "extern \"C\" __global__ void __launch_bounds__(38) default_function_kernel(float* __restrict__ Scale, float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 38) + ((int)threadIdx.x))] = ((0.000000e+00f < data[((((int)blockIdx.x) * 38) + ((int)threadIdx.x))]) ? data[((((int)blockIdx.x) * 38) + ((int)threadIdx.x))] : (data[((((int)blockIdx.x) * 38) + ((int)threadIdx.x))] * Scale[(((int)threadIdx.x) % 19)]));\n}\n\n",
        "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((9, 17, 16, 19), \"float32\"), Scale: T.Buffer((19,), \"float32\"), compute: T.Buffer((9, 17, 16, 19), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused_i2_fused_i3_fused in T.parallel(46512):\n            compute_1 = T.Buffer((46512,), data=compute.data)\n            data_1 = T.Buffer((46512,), data=data.data)\n            compute_1[i0_i1_fused_i2_fused_i3_fused] = T.if_then_else(T.float32(0) < data_1[i0_i1_fused_i2_fused_i3_fused], data_1[i0_i1_fused_i2_fused_i3_fused], data_1[i0_i1_fused_i2_fused_i3_fused] * Scale[i0_i1_fused_i2_fused_i3_fused % 19])",
        "op_args": [
            9,
            17,
            16,
            19
        ],
        "input_shape": [
            [
                9,
                17,
                16,
                19
            ],
            [
                19
            ]
        ],
        "output_shape": [
            [
                9,
                17,
                16,
                19
            ]
        ]
    },
    {
        "op_name": "tanh",
        "c_code": "void default_function_kernel(float* compute, float* data) {\n  for (int32_t i1 = 0; i1 < 20; ++i1) {\n    for (int32_t i2 = 0; i2 < 14; ++i2) {\n      for (int32_t i3 = 0; i3 < 13; ++i3) {\n        compute[(((i1 * 182) + (i2 * 13)) + i3)] = tanhf(data[(((i1 * 182) + (i2 * 13)) + i3)]);\n      }\n    }\n  }\n}\n\n",
        "cuda_code": "extern \"C\" __global__ void __launch_bounds__(28) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 28) + ((int)threadIdx.x))] = tanhf(data[((((int)blockIdx.x) * 28) + ((int)threadIdx.x))]);\n}\n\n",
        "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((1, 20, 14, 13), \"float32\"), compute: T.Buffer((1, 20, 14, 13), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i1, i2, i3 in T.grid(20, 14, 13):\n            cse_var_1: T.int32 = i1 * 182 + i2 * 13 + i3\n            compute_1 = T.Buffer((3640,), data=compute.data)\n            data_1 = T.Buffer((3640,), data=data.data)\n            compute_1[cse_var_1] = T.tanh(data_1[cse_var_1])",
        "op_args": [
            1,
            20,
            14,
            13
        ],
        "input_shape": [
            [
                1,
                20,
                14,
                13
            ]
        ],
        "output_shape": [
            [
                1,
                20,
                14,
                13
            ]
        ]
    },
    {
        "op_name": "scale_shift_nchwc",
        "c_code": "void default_function_kernel(float* Scale, float* ScaleShift, float* Shift, float* data) {\n  #pragma omp parallel for\n  for (int32_t b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused = 0; b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused < 196; ++b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused) {\n    for (int32_t cb_outer_inner = 0; cb_outer_inner < 7; ++cb_outer_inner) {\n      for (int32_t i_inner = 0; i_inner < 16; ++i_inner) {\n        ScaleShift[((((((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused / 28) * 3136) + ((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused & 1) * 1568)) + (i_inner * 98)) + (((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused % 28) >> 1) * 7)) + cb_outer_inner)] = ((data[((((((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused / 28) * 3136) + ((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused & 1) * 1568)) + (i_inner * 98)) + (((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused % 28) >> 1) * 7)) + cb_outer_inner)] * Scale[(((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused & 1) * 7) + cb_outer_inner)]) + Shift[(((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused & 1) * 7) + cb_outer_inner)]);\n      }\n    }\n  }\n}\n\n",
        "cuda_code": "extern \"C\" __global__ void __launch_bounds__(64) default_function_kernel(float* __restrict__ Scale, float* __restrict__ ScaleShift, float* __restrict__ Shift, float* __restrict__ data) {\n  ScaleShift[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))] = ((data[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))] * Scale[((((((((int)blockIdx.x) % 49) * 2) + (((int)threadIdx.x) >> 5)) / 49) * 7) + ((((int)blockIdx.x) + ((int)threadIdx.x)) % 7))]) + Shift[((((((((int)blockIdx.x) % 49) * 2) + (((int)threadIdx.x) >> 5)) / 49) * 7) + ((((int)blockIdx.x) + ((int)threadIdx.x)) % 7))]);\n}\n\n",
        "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((7, 2, 16, 14, 7), \"float32\"), Scale: T.Buffer((2, 7), \"float32\"), Shift: T.Buffer((2, 7), \"float32\"), ScaleShift: T.Buffer((7, 2, 16, 14, 7), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused in T.parallel(196):\n            for cb_outer_inner, i_inner in T.grid(7, 16):\n                cse_var_3: T.int32 = b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused % 2\n                cse_var_2: T.int32 = cse_var_3 * 7 + cb_outer_inner\n                cse_var_1: T.int32 = b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused // 28 * 3136 + cse_var_3 * 1568 + i_inner * 98 + b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused % 28 // 2 * 7 + cb_outer_inner\n                ScaleShift_1 = T.Buffer((21952,), data=ScaleShift.data)\n                data_1 = T.Buffer((21952,), data=data.data)\n                Scale_1 = T.Buffer((14,), data=Scale.data)\n                Shift_1 = T.Buffer((14,), data=Shift.data)\n                ScaleShift_1[cse_var_1] = data_1[cse_var_1] * Scale_1[cse_var_2] + Shift_1[cse_var_2]",
        "op_args": [
            7,
            7,
            16,
            14
        ],
        "input_shape": [
            [
                7,
                2,
                16,
                14,
                7
            ],
            [
                2,
                7
            ],
            [
                2,
                7
            ]
        ],
        "output_shape": [
            [
                7,
                2,
                16,
                14,
                7
            ]
        ]
    },
    {
        "op_name": "matmul",
        "c_code": "void default_function_kernel(float* T_matmul, float* left_matrix, float* right_matrix) {\n  for (int32_t ax1_outer_outer_outer = 0; ax1_outer_outer_outer < 2; ++ax1_outer_outer_outer) {\n    for (int32_t ax0_inner_init = 0; ax0_inner_init < 2; ++ax0_inner_init) {\n      T_matmul[((ax0_inner_init * 2) + ax1_outer_outer_outer)] = 0.000000e+00f;\n    }\n    for (int32_t k_inner = 0; k_inner < 2; ++k_inner) {\n      for (int32_t ax0_inner = 0; ax0_inner < 2; ++ax0_inner) {\n        T_matmul[((ax0_inner * 2) + ax1_outer_outer_outer)] = (T_matmul[((ax0_inner * 2) + ax1_outer_outer_outer)] + (left_matrix[((ax0_inner * 2) + k_inner)] * right_matrix[((k_inner * 2) + ax1_outer_outer_outer)]));\n      }\n    }\n  }\n}\n\n",
        "cuda_code": "extern \"C\" __global__ void __launch_bounds__(2) default_function_kernel(float* __restrict__ T_matmul, float* __restrict__ left_matrix, float* __restrict__ right_matrix) {\n  float T_matmul_local[2];\n  __shared__ float left_matrix_shared[4];\n  __shared__ float right_matrix_shared[4];\n  T_matmul_local[0] = 0.000000e+00f;\n  T_matmul_local[1] = 0.000000e+00f;\n  for (int ax0_ax1_fused_outer_outer = 0; ax0_ax1_fused_outer_outer < 2; ++ax0_ax1_fused_outer_outer) {\n    left_matrix_shared[((ax0_ax1_fused_outer_outer * 2) + ((int)threadIdx.x))] = left_matrix[((ax0_ax1_fused_outer_outer * 2) + ((int)threadIdx.x))];\n  }\n  for (int ax0_ax1_fused_outer_outer_1 = 0; ax0_ax1_fused_outer_outer_1 < 2; ++ax0_ax1_fused_outer_outer_1) {\n    right_matrix_shared[((ax0_ax1_fused_outer_outer_1 * 2) + ((int)threadIdx.x))] = right_matrix[((ax0_ax1_fused_outer_outer_1 * 2) + ((int)threadIdx.x))];\n  }\n  __syncthreads();\n  for (int k_inner = 0; k_inner < 2; ++k_inner) {\n    T_matmul_local[0] = (T_matmul_local[0] + (left_matrix_shared[((((int)threadIdx.x) * 2) + k_inner)] * right_matrix_shared[(k_inner * 2)]));\n    T_matmul_local[1] = (T_matmul_local[1] + (left_matrix_shared[((((int)threadIdx.x) * 2) + k_inner)] * right_matrix_shared[((k_inner * 2) + 1)]));\n  }\n  T_matmul[(((int)threadIdx.x) * 2)] = T_matmul_local[0];\n  T_matmul[((((int)threadIdx.x) * 2) + 1)] = T_matmul_local[1];\n}\n\n",
        "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(left_matrix: T.Buffer((2, 2), \"float32\"), right_matrix: T.Buffer((2, 2), \"float32\"), T_matmul: T.Buffer((2, 2), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax1_outer_outer_outer in range(2):\n            T_matmul_1 = T.Buffer((4,), data=T_matmul.data)\n            for ax0_inner_init in range(2):\n                T_matmul_1[ax0_inner_init * 2 + ax1_outer_outer_outer] = T.float32(0)\n            for k_inner, ax0_inner in T.grid(2, 2):\n                cse_var_2: T.int32 = ax0_inner * 2\n                cse_var_1: T.int32 = cse_var_2 + ax1_outer_outer_outer\n                left_matrix_1 = T.Buffer((4,), data=left_matrix.data)\n                right_matrix_1 = T.Buffer((4,), data=right_matrix.data)\n                T_matmul_1[cse_var_1] = T_matmul_1[cse_var_1] + left_matrix_1[cse_var_2 + k_inner] * right_matrix_1[k_inner * 2 + ax1_outer_outer_outer]",
        "op_args": [
            7,
            2,
            2,
            2
        ],
        "input_shape": [
            [
                2,
                2
            ],
            [
                2,
                2
            ]
        ],
        "output_shape": [
            [
                2,
                2
            ]
        ]
    },
    {
        "op_name": "softmax",
        "c_code": "void default_function_kernel(float* T_softmax_norm, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0 = 0; i0 < 17; ++i0) {\n    float T_softmax_maxelem[4];\n    float T_softmax_expsum[4];\n    for (int32_t i1 = 0; i1 < 4; ++i1) {\n      for (int32_t i2 = 0; i2 < 4; ++i2) {\n        T_softmax_maxelem[i2] = -3.402823e+38f;\n        T_softmax_maxelem[i2] = max(T_softmax_maxelem[i2], data[(((i0 * 16) + (i1 * 4)) + i2)]);\n      }\n      for (int32_t i2_1 = 0; i2_1 < 4; ++i2_1) {\n        T_softmax_maxelem[i2_1] = expf((data[(((i0 * 16) + (i1 * 4)) + i2_1)] - T_softmax_maxelem[i2_1]));\n      }\n      for (int32_t i2_2 = 0; i2_2 < 4; ++i2_2) {\n        T_softmax_expsum[i2_2] = 0.000000e+00f;\n        T_softmax_expsum[i2_2] = (T_softmax_expsum[i2_2] + T_softmax_maxelem[i2_2]);\n      }\n      for (int32_t i2_3 = 0; i2_3 < 4; ++i2_3) {\n        T_softmax_norm[(((i0 * 16) + (i1 * 4)) + i2_3)] = (T_softmax_maxelem[i2_3] / T_softmax_expsum[i2_3]);\n      }\n    }\n  }\n}\n\n",
        "cuda_code": "extern \"C\" __global__ void __launch_bounds__(32) default_function_kernel(float* __restrict__ T_softmax_maxelem, float* __restrict__ data) {\n  if (((((int)blockIdx.x) * 2) + (((int)threadIdx.x) >> 4)) < 17) {\n    T_softmax_maxelem[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] = -3.402823e+38f;\n  }\n  if (((((int)blockIdx.x) * 2) + (((int)threadIdx.x) >> 4)) < 17) {\n    T_softmax_maxelem[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] = max(T_softmax_maxelem[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))], data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))]);\n  }\n}\n\nextern \"C\" __global__ void __launch_bounds__(64) default_function_kernel_2(float* __restrict__ T_softmax_expsum, float* __restrict__ T_softmax_maxelem, float* __restrict__ T_softmax_norm, float* __restrict__ data) {\n  if (((((int)blockIdx.x) * 4) + (((int)threadIdx.x) >> 4)) < 17) {\n    T_softmax_norm[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))] = (__expf((data[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))] - T_softmax_maxelem[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))])) / T_softmax_expsum[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))]);\n  }\n}\n\nextern \"C\" __global__ void __launch_bounds__(8) default_function_kernel_1(float* __restrict__ T_softmax_expsum, float* __restrict__ T_softmax_maxelem, float* __restrict__ data) {\n  T_softmax_expsum[((((int)blockIdx.x) * 8) + ((int)threadIdx.x))] = 0.000000e+00f;\n  T_softmax_expsum[((((int)blockIdx.x) * 8) + ((int)threadIdx.x))] = (T_softmax_expsum[((((int)blockIdx.x) * 8) + ((int)threadIdx.x))] + __expf((data[((((int)blockIdx.x) * 8) + ((int)threadIdx.x))] - T_softmax_maxelem[((((int)blockIdx.x) * 8) + ((int)threadIdx.x))])));\n}\n\n",
        "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((17, 4, 4, 1), \"float32\"), T_softmax_norm: T.Buffer((17, 4, 4, 1), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0 in T.parallel(17):\n            T_softmax_maxelem = T.allocate([4], \"float32\", \"global\")\n            T_softmax_expsum = T.allocate([4], \"float32\", \"global\")\n            for i1 in range(4):\n                T_softmax_maxelem_1 = T.Buffer((4,), data=T_softmax_maxelem, align=16)\n                data_1 = T.Buffer((272,), data=data.data)\n                for i2 in range(4):\n                    T_softmax_maxelem_1[i2] = T.float32(-3.4028234663852886e+38)\n                    T_softmax_maxelem_1[i2] = T.max(T_softmax_maxelem_1[i2], data_1[i0 * 16 + i1 * 4 + i2])\n                T_softmax_maxelem_2 = T.Buffer((4,), data=T_softmax_maxelem, align=16)\n                for i2 in range(4):\n                    T_softmax_maxelem_2[i2] = T.exp(data_1[i0 * 16 + i1 * 4 + i2] - T_softmax_maxelem_1[i2])\n                T_softmax_expsum_1 = T.Buffer((4,), data=T_softmax_expsum, align=16)\n                for i2 in range(4):\n                    T_softmax_expsum_1[i2] = T.float32(0)\n                    T_softmax_expsum_1[i2] = T_softmax_expsum_1[i2] + T_softmax_maxelem_2[i2]\n                for i2 in range(4):\n                    T_softmax_norm_1 = T.Buffer((272,), data=T_softmax_norm.data)\n                    T_softmax_norm_1[i0 * 16 + i1 * 4 + i2] = T_softmax_maxelem_2[i2] / T_softmax_expsum_1[i2]",
        "op_args": [
            17,
            4,
            4,
            1
        ],
        "input_shape": [
            [
                17,
                4,
                4,
                1
            ]
        ],
        "output_shape": [
            [
                17,
                4,
                4,
                1
            ]
        ]
    },
    {
        "op_name": "combination_op",
        "c_code": "void default_function_kernel(float* T_add, float* data, float* data_1) {\n  #pragma omp parallel for\n  for (int32_t ax0_ax1_fused_ax2_fused = 0; ax0_ax1_fused_ax2_fused < 392; ++ax0_ax1_fused_ax2_fused) {\n    for (int32_t ax3 = 0; ax3 < 16; ++ax3) {\n      T_add[((ax0_ax1_fused_ax2_fused * 16) + ax3)] = (sqrtf(data[((ax0_ax1_fused_ax2_fused * 16) + ax3)]) + cosf(data_1[((ax0_ax1_fused_ax2_fused * 16) + ax3)]));\n    }\n  }\n}\n\n",
        "cuda_code": "extern \"C\" __global__ void __launch_bounds__(32) default_function_kernel(float* __restrict__ T_add, float* __restrict__ data, float* __restrict__ data_1) {\n  T_add[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] = (sqrtf(data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))]) + __cosf(data_1[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))]));\n}\n\n",
        "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((14, 4, 7, 16), \"float32\"), data_1: T.Buffer((14, 4, 7, 16), \"float32\"), T_add: T.Buffer((14, 4, 7, 16), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0_ax1_fused_ax2_fused in T.parallel(392):\n            for ax3 in range(16):\n                cse_var_1: T.int32 = ax0_ax1_fused_ax2_fused * 16 + ax3\n                T_add_1 = T.Buffer((6272,), data=T_add.data)\n                data_2 = T.Buffer((6272,), data=data.data)\n                data_3 = T.Buffer((6272,), data=data_1.data)\n                T_add_1[cse_var_1] = T.sqrt(data_2[cse_var_1]) + T.cos(data_3[cse_var_1])",
        "op_args": [
            14,
            4,
            7,
            16
        ],
        "input_shape": [
            [
                14,
                4,
                7,
                16
            ],
            [
                14,
                4,
                7,
                16
            ]
        ],
        "output_shape": [
            [
                14,
                4,
                7,
                16
            ]
        ]
    },
    {
        "op_name": "multi_out_op",
        "c_code": "void default_function_kernel(float* compute, float* compute_1, float* data, float* data_1) {\n  #pragma omp parallel for\n  for (int32_t i0 = 0; i0 < 4; ++i0) {\n    for (int32_t i1 = 0; i1 < 17; ++i1) {\n      for (int32_t i2 = 0; i2 < 12; ++i2) {\n        for (int32_t i3 = 0; i3 < 17; ++i3) {\n          compute[((((i0 * 3468) + (i1 * 204)) + (i2 * 17)) + i3)] = sqrtf((data[((((i0 * 3468) + (i1 * 204)) + (i2 * 17)) + i3)] + data_1[((((i0 * 3468) + (i1 * 204)) + (i2 * 17)) + i3)]));\n        }\n      }\n    }\n  }\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused = 0; i0_i1_fused < 68; ++i0_i1_fused) {\n    for (int32_t i2_1 = 0; i2_1 < 12; ++i2_1) {\n      for (int32_t i3_1 = 0; i3_1 < 17; ++i3_1) {\n        compute_1[(((i0_i1_fused * 204) + (i2_1 * 17)) + i3_1)] = cosf((data[(((i0_i1_fused * 204) + (i2_1 * 17)) + i3_1)] + data_1[(((i0_i1_fused * 204) + (i2_1 * 17)) + i3_1)]));\n      }\n    }\n  }\n}\n\n",
        "cuda_code": "extern \"C\" __global__ void __launch_bounds__(24) default_function_kernel_1(float* __restrict__ compute, float* __restrict__ data, float* __restrict__ data_1) {\n  compute[((((int)blockIdx.x) * 24) + ((int)threadIdx.x))] = __cosf((data[((((int)blockIdx.x) * 24) + ((int)threadIdx.x))] + data_1[((((int)blockIdx.x) * 24) + ((int)threadIdx.x))]));\n}\n\nextern \"C\" __global__ void __launch_bounds__(6) default_function_kernel(float* __restrict__ compute, float* __restrict__ data, float* __restrict__ data_1) {\n  compute[((((int)blockIdx.x) * 6) + ((int)threadIdx.x))] = sqrtf((data[((((int)blockIdx.x) * 6) + ((int)threadIdx.x))] + data_1[((((int)blockIdx.x) * 6) + ((int)threadIdx.x))]));\n}\n\n",
        "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((4, 17, 12, 17), \"float32\"), data_1: T.Buffer((4, 17, 12, 17), \"float32\"), compute: T.Buffer((4, 17, 12, 17), \"float32\"), compute_1: T.Buffer((4, 17, 12, 17), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        data_2 = T.Buffer((13872,), data=data.data)\n        data_3 = T.Buffer((13872,), data=data_1.data)\n        for i0 in T.parallel(4):\n            for i1, i2, i3 in T.grid(17, 12, 17):\n                cse_var_1: T.int32 = i0 * 3468 + i1 * 204 + i2 * 17 + i3\n                compute_2 = T.Buffer((13872,), data=compute.data)\n                compute_2[cse_var_1] = T.sqrt(data_2[cse_var_1] + data_3[cse_var_1])\n        for i0_i1_fused in T.parallel(68):\n            for i2, i3 in T.grid(12, 17):\n                cse_var_2: T.int32 = i0_i1_fused * 204 + i2 * 17 + i3\n                compute_2 = T.Buffer((13872,), data=compute_1.data)\n                compute_2[cse_var_2] = T.cos(data_2[cse_var_2] + data_3[cse_var_2])",
        "op_args": [
            4,
            17,
            12,
            17
        ],
        "input_shape": [
            [
                4,
                17,
                12,
                17
            ],
            [
                4,
                17,
                12,
                17
            ],
            [
                4,
                17,
                12,
                17
            ]
        ],
        "output_shape": [
            [
                4,
                17,
                12,
                17
            ]
        ]
    },
    {
        "op_name": "softmax_common",
        "c_code": "void default_function_kernel(float* T_softmax_norm, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0 = 0; i0 < 18; ++i0) {\n    float T_softmax_maxelem[168];\n    float T_softmax_expsum[14];\n    for (int32_t i1 = 0; i1 < 12; ++i1) {\n      for (int32_t i2 = 0; i2 < 14; ++i2) {\n        T_softmax_maxelem[((i1 * 14) + i2)] = -3.402823e+38f;\n        for (int32_t k = 0; k < 3; ++k) {\n          T_softmax_maxelem[((i1 * 14) + i2)] = max(T_softmax_maxelem[((i1 * 14) + i2)], data[((((i0 * 504) + (i1 * 42)) + (i2 * 3)) + k)]);\n        }\n      }\n    }\n    for (int32_t i1_1 = 0; i1_1 < 12; ++i1_1) {\n      for (int32_t i2_1 = 0; i2_1 < 14; ++i2_1) {\n        T_softmax_expsum[i2_1] = 0.000000e+00f;\n        for (int32_t k_1 = 0; k_1 < 3; ++k_1) {\n            int32_t v_ = ((int32_t)(floorf(((max(min((data[((((i0 * 504) + (i1_1 * 42)) + (i2_1 * 3)) + k_1)] - T_softmax_maxelem[((i1_1 * 14) + i2_1)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) + 1.270000e+02f)) << 23;\n          T_softmax_expsum[i2_1] = (T_softmax_expsum[i2_1] + max(((*(float *)(&(v_))) * ((((((((((((((1.987569e-04f * (max(min((data[((((i0 * 504) + (i1_1 * 42)) + (i2_1 * 3)) + k_1)] - T_softmax_maxelem[((i1_1 * 14) + i2_1)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((i0 * 504) + (i1_1 * 42)) + (i2_1 * 3)) + k_1)] - T_softmax_maxelem[((i1_1 * 14) + i2_1)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.398200e-03f) * (max(min((data[((((i0 * 504) + (i1_1 * 42)) + (i2_1 * 3)) + k_1)] - T_softmax_maxelem[((i1_1 * 14) + i2_1)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((i0 * 504) + (i1_1 * 42)) + (i2_1 * 3)) + k_1)] - T_softmax_maxelem[((i1_1 * 14) + i2_1)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 8.333452e-03f) * (max(min((data[((((i0 * 504) + (i1_1 * 42)) + (i2_1 * 3)) + k_1)] - T_softmax_maxelem[((i1_1 * 14) + i2_1)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((i0 * 504) + (i1_1 * 42)) + (i2_1 * 3)) + k_1)] - T_softmax_maxelem[((i1_1 * 14) + i2_1)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 4.166580e-02f) * (max(min((data[((((i0 * 504) + (i1_1 * 42)) + (i2_1 * 3)) + k_1)] - T_softmax_maxelem[((i1_1 * 14) + i2_1)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((i0 * 504) + (i1_1 * 42)) + (i2_1 * 3)) + k_1)] - T_softmax_maxelem[((i1_1 * 14) + i2_1)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.666667e-01f) * (max(min((data[((((i0 * 504) + (i1_1 * 42)) + (i2_1 * 3)) + k_1)] - T_softmax_maxelem[((i1_1 * 14) + i2_1)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((i0 * 504) + (i1_1 * 42)) + (i2_1 * 3)) + k_1)] - T_softmax_maxelem[((i1_1 * 14) + i2_1)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 5.000000e-01f) * (max(min((data[((((i0 * 504) + (i1_1 * 42)) + (i2_1 * 3)) + k_1)] - T_softmax_maxelem[((i1_1 * 14) + i2_1)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((i0 * 504) + (i1_1 * 42)) + (i2_1 * 3)) + k_1)] - T_softmax_maxelem[((i1_1 * 14) + i2_1)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) * (max(min((data[((((i0 * 504) + (i1_1 * 42)) + (i2_1 * 3)) + k_1)] - T_softmax_maxelem[((i1_1 * 14) + i2_1)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((i0 * 504) + (i1_1 * 42)) + (i2_1 * 3)) + k_1)] - T_softmax_maxelem[((i1_1 * 14) + i2_1)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + (max(min((data[((((i0 * 504) + (i1_1 * 42)) + (i2_1 * 3)) + k_1)] - T_softmax_maxelem[((i1_1 * 14) + i2_1)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((i0 * 504) + (i1_1 * 42)) + (i2_1 * 3)) + k_1)] - T_softmax_maxelem[((i1_1 * 14) + i2_1)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.000000e+00f)), (data[((((i0 * 504) + (i1_1 * 42)) + (i2_1 * 3)) + k_1)] - T_softmax_maxelem[((i1_1 * 14) + i2_1)])));\n        }\n      }\n      for (int32_t i2_2 = 0; i2_2 < 14; ++i2_2) {\n        for (int32_t i3_s = 0; i3_s < 3; ++i3_s) {\n            int32_t v__1 = ((int32_t)(floorf(((max(min((data[((((i0 * 504) + (i1_1 * 42)) + (i2_2 * 3)) + i3_s)] - T_softmax_maxelem[((i1_1 * 14) + i2_2)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) + 1.270000e+02f)) << 23;\n          T_softmax_norm[((((i0 * 504) + (i1_1 * 42)) + (i2_2 * 3)) + i3_s)] = (max(((*(float *)(&(v__1))) * ((((((((((((((1.987569e-04f * (max(min((data[((((i0 * 504) + (i1_1 * 42)) + (i2_2 * 3)) + i3_s)] - T_softmax_maxelem[((i1_1 * 14) + i2_2)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((i0 * 504) + (i1_1 * 42)) + (i2_2 * 3)) + i3_s)] - T_softmax_maxelem[((i1_1 * 14) + i2_2)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.398200e-03f) * (max(min((data[((((i0 * 504) + (i1_1 * 42)) + (i2_2 * 3)) + i3_s)] - T_softmax_maxelem[((i1_1 * 14) + i2_2)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((i0 * 504) + (i1_1 * 42)) + (i2_2 * 3)) + i3_s)] - T_softmax_maxelem[((i1_1 * 14) + i2_2)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 8.333452e-03f) * (max(min((data[((((i0 * 504) + (i1_1 * 42)) + (i2_2 * 3)) + i3_s)] - T_softmax_maxelem[((i1_1 * 14) + i2_2)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((i0 * 504) + (i1_1 * 42)) + (i2_2 * 3)) + i3_s)] - T_softmax_maxelem[((i1_1 * 14) + i2_2)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 4.166580e-02f) * (max(min((data[((((i0 * 504) + (i1_1 * 42)) + (i2_2 * 3)) + i3_s)] - T_softmax_maxelem[((i1_1 * 14) + i2_2)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((i0 * 504) + (i1_1 * 42)) + (i2_2 * 3)) + i3_s)] - T_softmax_maxelem[((i1_1 * 14) + i2_2)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.666667e-01f) * (max(min((data[((((i0 * 504) + (i1_1 * 42)) + (i2_2 * 3)) + i3_s)] - T_softmax_maxelem[((i1_1 * 14) + i2_2)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((i0 * 504) + (i1_1 * 42)) + (i2_2 * 3)) + i3_s)] - T_softmax_maxelem[((i1_1 * 14) + i2_2)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 5.000000e-01f) * (max(min((data[((((i0 * 504) + (i1_1 * 42)) + (i2_2 * 3)) + i3_s)] - T_softmax_maxelem[((i1_1 * 14) + i2_2)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((i0 * 504) + (i1_1 * 42)) + (i2_2 * 3)) + i3_s)] - T_softmax_maxelem[((i1_1 * 14) + i2_2)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) * (max(min((data[((((i0 * 504) + (i1_1 * 42)) + (i2_2 * 3)) + i3_s)] - T_softmax_maxelem[((i1_1 * 14) + i2_2)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((i0 * 504) + (i1_1 * 42)) + (i2_2 * 3)) + i3_s)] - T_softmax_maxelem[((i1_1 * 14) + i2_2)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + (max(min((data[((((i0 * 504) + (i1_1 * 42)) + (i2_2 * 3)) + i3_s)] - T_softmax_maxelem[((i1_1 * 14) + i2_2)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((i0 * 504) + (i1_1 * 42)) + (i2_2 * 3)) + i3_s)] - T_softmax_maxelem[((i1_1 * 14) + i2_2)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.000000e+00f)), (data[((((i0 * 504) + (i1_1 * 42)) + (i2_2 * 3)) + i3_s)] - T_softmax_maxelem[((i1_1 * 14) + i2_2)])) / T_softmax_expsum[i2_2]);\n        }\n      }\n    }\n  }\n}\n\n",
        "cuda_code": "extern \"C\" __global__ void __launch_bounds__(32) default_function_kernel(float* __restrict__ T_softmax_maxelem, float* __restrict__ data) {\n  if (((((int)blockIdx.x) * 2) + (((int)threadIdx.x) >> 4)) < 189) {\n    T_softmax_maxelem[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] = -3.402823e+38f;\n  }\n  for (int k = 0; k < 3; ++k) {\n    if (((((int)blockIdx.x) * 2) + (((int)threadIdx.x) >> 4)) < 189) {\n      T_softmax_maxelem[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] = max(T_softmax_maxelem[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))], data[(((((int)blockIdx.x) * 96) + (((int)threadIdx.x) * 3)) + k)]);\n    }\n  }\n}\n\nextern \"C\" __global__ void __launch_bounds__(32) default_function_kernel_2(float* __restrict__ T_softmax_expsum, float* __restrict__ T_softmax_maxelem, float* __restrict__ T_softmax_norm, float* __restrict__ data) {\n  if (((((int)blockIdx.x) * 2) + (((int)threadIdx.x) >> 4)) < 567) {\n      int v_ = ((int)(floorf(((max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 3)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) + 1.270000e+02f)) << 23;\n    T_softmax_norm[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] = (max(((*(float *)(&(v_))) * ((((((((((((((1.987569e-04f * (max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 3)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 3)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.398200e-03f) * (max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 3)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 3)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 8.333452e-03f) * (max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 3)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 3)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 4.166580e-02f) * (max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 3)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 3)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.666667e-01f) * (max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 3)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 3)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 5.000000e-01f) * (max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 3)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 3)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) * (max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 3)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 3)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + (max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 3)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 3)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.000000e+00f)), (data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 3)])) / T_softmax_expsum[(((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 3)]);\n  }\n}\n\nextern \"C\" __global__ void __launch_bounds__(4) default_function_kernel_1(float* __restrict__ T_softmax_expsum, float* __restrict__ T_softmax_maxelem, float* __restrict__ data) {\n  T_softmax_expsum[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))] = 0.000000e+00f;\n  for (int k = 0; k < 3; ++k) {\n      int v_ = ((int)(floorf(((max(min((data[(((((int)blockIdx.x) * 12) + (((int)threadIdx.x) * 3)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) + 1.270000e+02f)) << 23;\n    T_softmax_expsum[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))] = (T_softmax_expsum[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))] + max(((*(float *)(&(v_))) * ((((((((((((((1.987569e-04f * (max(min((data[(((((int)blockIdx.x) * 12) + (((int)threadIdx.x) * 3)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((((int)blockIdx.x) * 12) + (((int)threadIdx.x) * 3)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.398200e-03f) * (max(min((data[(((((int)blockIdx.x) * 12) + (((int)threadIdx.x) * 3)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((((int)blockIdx.x) * 12) + (((int)threadIdx.x) * 3)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 8.333452e-03f) * (max(min((data[(((((int)blockIdx.x) * 12) + (((int)threadIdx.x) * 3)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((((int)blockIdx.x) * 12) + (((int)threadIdx.x) * 3)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 4.166580e-02f) * (max(min((data[(((((int)blockIdx.x) * 12) + (((int)threadIdx.x) * 3)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((((int)blockIdx.x) * 12) + (((int)threadIdx.x) * 3)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.666667e-01f) * (max(min((data[(((((int)blockIdx.x) * 12) + (((int)threadIdx.x) * 3)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((((int)blockIdx.x) * 12) + (((int)threadIdx.x) * 3)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 5.000000e-01f) * (max(min((data[(((((int)blockIdx.x) * 12) + (((int)threadIdx.x) * 3)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((((int)blockIdx.x) * 12) + (((int)threadIdx.x) * 3)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) * (max(min((data[(((((int)blockIdx.x) * 12) + (((int)threadIdx.x) * 3)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((((int)blockIdx.x) * 12) + (((int)threadIdx.x) * 3)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + (max(min((data[(((((int)blockIdx.x) * 12) + (((int)threadIdx.x) * 3)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((((int)blockIdx.x) * 12) + (((int)threadIdx.x) * 3)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.000000e+00f)), (data[(((((int)blockIdx.x) * 12) + (((int)threadIdx.x) * 3)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))])));\n  }\n}\n\n",
        "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((18, 12, 14, 3), \"float32\"), T_softmax_norm: T.Buffer((18, 12, 14, 3), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0 in T.parallel(18):\n            T_softmax_maxelem = T.allocate([168], \"float32\", \"global\")\n            T_softmax_expsum = T.allocate([14], \"float32\", \"global\")\n            T_softmax_maxelem_1 = T.Buffer((168,), data=T_softmax_maxelem)\n            data_1 = T.Buffer((9072,), data=data.data)\n            for i1, i2 in T.grid(12, 14):\n                T_softmax_maxelem_1[i1 * 14 + i2] = T.float32(-3.4028234663852886e+38)\n                for k in range(3):\n                    cse_var_1: T.int32 = i1 * 14 + i2\n                    T_softmax_maxelem_1[cse_var_1] = T.max(T_softmax_maxelem_1[cse_var_1], data_1[i0 * 504 + i1 * 42 + i2 * 3 + k])\n            for i1 in range(12):\n                T_softmax_expsum_1 = T.Buffer((14,), data=T_softmax_expsum, align=32)\n                for i2 in range(14):\n                    T_softmax_expsum_1[i2] = T.float32(0)\n                    for k in range(3):\n                        cse_var_3: T.int32 = i1 * 14 + i2\n                        cse_var_2: T.int32 = i0 * 504 + i1 * 42 + i2 * 3 + k\n                        T_softmax_expsum_1[i2] = T_softmax_expsum_1[i2] + T.max(T.reinterpret(\"float32\", T.shift_left(T.Cast(\"int32\", T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[cse_var_3], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) + T.float32(127)), 23)) * ((((((T.float32(0.00019875691214110702) * (T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[cse_var_3], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[cse_var_3], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.0013981999363750219)) * (T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[cse_var_3], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[cse_var_3], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.008333452045917511)) * (T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[cse_var_3], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[cse_var_3], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.041665796190500259)) * (T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[cse_var_3], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[cse_var_3], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.1666666567325592)) * (T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[cse_var_3], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[cse_var_3], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.5)) * (T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[cse_var_3], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[cse_var_3], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) * (T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[cse_var_3], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[cse_var_3], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + (T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[cse_var_3], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[cse_var_3], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(1)), data_1[cse_var_2] - T_softmax_maxelem_1[cse_var_3])\n                for i2, i3_s in T.grid(14, 3):\n                    cse_var_5: T.int32 = i1 * 14 + i2\n                    cse_var_4: T.int32 = i0 * 504 + i1 * 42 + i2 * 3 + i3_s\n                    T_softmax_norm_1 = T.Buffer((9072,), data=T_softmax_norm.data)\n                    T_softmax_norm_1[cse_var_4] = T.max(T.reinterpret(\"float32\", T.shift_left(T.Cast(\"int32\", T.floor(T.max(T.min(data_1[cse_var_4] - T_softmax_maxelem_1[cse_var_5], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) + T.float32(127)), 23)) * ((((((T.float32(0.00019875691214110702) * (T.max(T.min(data_1[cse_var_4] - T_softmax_maxelem_1[cse_var_5], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_4] - T_softmax_maxelem_1[cse_var_5], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.0013981999363750219)) * (T.max(T.min(data_1[cse_var_4] - T_softmax_maxelem_1[cse_var_5], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_4] - T_softmax_maxelem_1[cse_var_5], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.008333452045917511)) * (T.max(T.min(data_1[cse_var_4] - T_softmax_maxelem_1[cse_var_5], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_4] - T_softmax_maxelem_1[cse_var_5], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.041665796190500259)) * (T.max(T.min(data_1[cse_var_4] - T_softmax_maxelem_1[cse_var_5], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_4] - T_softmax_maxelem_1[cse_var_5], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.1666666567325592)) * (T.max(T.min(data_1[cse_var_4] - T_softmax_maxelem_1[cse_var_5], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_4] - T_softmax_maxelem_1[cse_var_5], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.5)) * (T.max(T.min(data_1[cse_var_4] - T_softmax_maxelem_1[cse_var_5], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_4] - T_softmax_maxelem_1[cse_var_5], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) * (T.max(T.min(data_1[cse_var_4] - T_softmax_maxelem_1[cse_var_5], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_4] - T_softmax_maxelem_1[cse_var_5], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + (T.max(T.min(data_1[cse_var_4] - T_softmax_maxelem_1[cse_var_5], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_4] - T_softmax_maxelem_1[cse_var_5], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(1)), data_1[cse_var_4] - T_softmax_maxelem_1[cse_var_5]) / T_softmax_expsum_1[i2]",
        "op_args": [
            18,
            12,
            14,
            3
        ],
        "input_shape": [
            [
                18,
                12,
                14,
                3
            ]
        ],
        "output_shape": [
            [
                18,
                12,
                14,
                3
            ]
        ]
    },
    {
        "op_name": "space_to_depth",
        "c_code": "void default_function_kernel(float* data, float* space_to_depth) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused_i3_fused = 0; i0_i1_fused_i2_fused_i3_fused < 648; ++i0_i1_fused_i2_fused_i3_fused) {\n    space_to_depth[i0_i1_fused_i2_fused_i3_fused] = data[((((((i0_i1_fused_i2_fused_i3_fused / 36) * 36) + ((((i0_i1_fused_i2_fused_i3_fused % 36) / 3) % 3) * 12)) + ((((i0_i1_fused_i2_fused_i3_fused % 36) / 3) / 6) * 6)) + ((i0_i1_fused_i2_fused_i3_fused % 3) * 2)) + ((((i0_i1_fused_i2_fused_i3_fused % 36) / 3) % 6) / 3))];\n  }\n}\n\n",
        "cuda_code": "extern \"C\" __global__ void __launch_bounds__(8) default_function_kernel(float* __restrict__ data, float* __restrict__ space_to_depth) {\n  space_to_depth[((((int)blockIdx.x) * 8) + ((int)threadIdx.x))] = data[((((((((((int)blockIdx.x) * 2) + (((int)threadIdx.x) >> 2)) / 9) * 36) + ((((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) % 36) / 3) % 3) * 12)) + ((((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) % 36) / 3) / 6) * 6)) + ((((((int)blockIdx.x) * 2) + ((int)threadIdx.x)) % 3) * 2)) + ((((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) % 36) / 3) % 6) / 3))];\n}\n\n",
        "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((18, 3, 2, 6), \"float32\"), space_to_depth: T.Buffer((18, 12, 1, 3), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused_i2_fused_i3_fused in T.parallel(648):\n            cse_var_1: T.int32 = i0_i1_fused_i2_fused_i3_fused % 36 // 3\n            space_to_depth_1 = T.Buffer((648,), data=space_to_depth.data)\n            data_1 = T.Buffer((648,), data=data.data)\n            space_to_depth_1[i0_i1_fused_i2_fused_i3_fused] = data_1[i0_i1_fused_i2_fused_i3_fused // 36 * 36 + T.truncmod(cse_var_1, 3) * 12 + T.Div(cse_var_1, 6) * 6 + i0_i1_fused_i2_fused_i3_fused % 3 * 2 + T.Div(T.truncmod(cse_var_1, 6), 3)]",
        "op_args": [
            18,
            3,
            1,
            3
        ],
        "input_shape": [
            [
                18,
                3,
                2,
                6
            ]
        ],
        "output_shape": [
            [
                18,
                12,
                1,
                3
            ]
        ]
    },
    {
        "op_name": "strided_slice",
        "c_code": "void default_function_kernel(float* T_strided_slice, float* a) {\n  for (int32_t ax1 = 0; ax1 < 5; ++ax1) {\n    for (int32_t ax2 = 0; ax2 < 7; ++ax2) {\n      T_strided_slice[((ax1 * 7) + ax2)] = a[(((ax1 * 15) + ax2) + 183)];\n    }\n  }\n}\n\n",
        "cuda_code": "extern \"C\" __global__ void __launch_bounds__(7) default_function_kernel(float* __restrict__ T_strided_slice, float* __restrict__ a) {\n  T_strided_slice[((((int)blockIdx.x) * 7) + ((int)threadIdx.x))] = a[(((((int)blockIdx.x) * 15) + ((int)threadIdx.x)) + 183)];\n}\n\n",
        "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(a: T.Buffer((2, 10, 15), \"float32\"), T_strided_slice: T.Buffer((1, 5, 7), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax1, ax2 in T.grid(5, 7):\n            T_strided_slice_1 = T.Buffer((35,), data=T_strided_slice.data)\n            a_1 = T.Buffer((300,), data=a.data)\n            T_strided_slice_1[ax1 * 7 + ax2] = a_1[ax1 * 15 + ax2 + 183]",
        "op_args": [
            1,
            2,
            10,
            15
        ],
        "input_shape": [
            [
                2,
                10,
                15
            ]
        ],
        "output_shape": [
            [
                1,
                5,
                7
            ]
        ]
    },
    {
        "op_name": "unpack_NCHWc_to_nchw",
        "c_code": "void default_function_kernel(float* output_unpack, float* packed_out) {\n  #pragma omp parallel for\n  for (int32_t n_c_fused_h_fused = 0; n_c_fused_h_fused < 504; ++n_c_fused_h_fused) {\n    for (int32_t w = 0; w < 8; ++w) {\n      output_unpack[((n_c_fused_h_fused * 8) + w)] = packed_out[(((((n_c_fused_h_fused / 24) * 192) + ((n_c_fused_h_fused % 12) * 16)) + (w * 2)) + ((n_c_fused_h_fused % 24) / 12))];\n    }\n  }\n}\n\n",
        "cuda_code": "extern \"C\" __global__ void __launch_bounds__(64) default_function_kernel(float* __restrict__ output_unpack, float* __restrict__ packed_out) {\n  output_unpack[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))] = packed_out[(((((((int)blockIdx.x) / 3) * 192) + ((((((int)blockIdx.x) * 8) + (((int)threadIdx.x) >> 3)) % 12) * 16)) + ((((int)threadIdx.x) & 7) * 2)) + ((((((int)blockIdx.x) % 3) * 2) + (((int)threadIdx.x) >> 5)) / 3))];\n}\n\n",
        "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(packed_out: T.Buffer((3, 7, 12, 8, 2), \"float32\"), output_unpack: T.Buffer((3, 14, 12, 8), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for n_c_fused_h_fused in T.parallel(504):\n            for w in range(8):\n                output_unpack_1 = T.Buffer((4032,), data=output_unpack.data)\n                packed_out_1 = T.Buffer((4032,), data=packed_out.data)\n                output_unpack_1[n_c_fused_h_fused * 8 + w] = packed_out_1[n_c_fused_h_fused // 24 * 192 + n_c_fused_h_fused % 12 * 16 + w * 2 + n_c_fused_h_fused % 24 // 12]",
        "op_args": [
            3,
            7,
            12,
            8
        ],
        "input_shape": [
            [
                3,
                7,
                12,
                8,
                2
            ]
        ],
        "output_shape": [
            [
                3,
                14,
                12,
                8
            ]
        ]
    },
    {
        "op_name": "upsampling",
        "c_code": "void default_function_kernel(float* data, float* resize) {\n  #pragma omp parallel for\n  for (int32_t i0 = 0; i0 < 11; ++i0) {\n    for (int32_t i2 = 0; i2 < 40; ++i2) {\n      for (int32_t i3 = 0; i3 < 36; ++i3) {\n        resize[(((i0 * 1440) + (i2 * 36)) + i3)] = data[(((i0 * 360) + ((i2 / 2) * 18)) + (i3 / 2))];\n      }\n    }\n  }\n}\n\n",
        "cuda_code": "extern \"C\" __global__ void __launch_bounds__(36) default_function_kernel(float* __restrict__ data, float* __restrict__ resize) {\n  resize[((((int)blockIdx.x) * 36) + ((int)threadIdx.x))] = data[((((((int)blockIdx.x) / 40) * 360) + (((((int)blockIdx.x) % 40) / 2) * 18)) + (((int)threadIdx.x) / 2))];\n}\n\n",
        "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((11, 1, 20, 18), \"float32\"), resize: T.Buffer((11, 1, 40, 36), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0 in T.parallel(11):\n            for i2, i3 in T.grid(40, 36):\n                resize_1 = T.Buffer((15840,), data=resize.data)\n                data_1 = T.Buffer((3960,), data=data.data)\n                resize_1[i0 * 1440 + i2 * 36 + i3] = data_1[i0 * 360 + T.Div(i2, 2) * 18 + T.Div(i3, 2)]",
        "op_args": [
            11,
            1,
            10,
            9
        ],
        "input_shape": [
            [
                11,
                1,
                20,
                18
            ]
        ],
        "output_shape": [
            [
                11,
                1,
                40,
                36
            ]
        ]
    },
    {
        "op_name": "rms_norm",
        "c_code": "void default_function_kernel(float* T_cast, float* data, float* weight) {\n  #pragma omp parallel for\n  for (int32_t ax0 = 0; ax0 < 8; ++ax0) {\n    float T_multiply_red[168];\n    for (int32_t ax1 = 0; ax1 < 12; ++ax1) {\n      for (int32_t ax2 = 0; ax2 < 14; ++ax2) {\n        T_multiply_red[((ax1 * 14) + ax2)] = 0.000000e+00f;\n        for (int32_t k1 = 0; k1 < 10; ++k1) {\n          T_multiply_red[((ax1 * 14) + ax2)] = (T_multiply_red[((ax1 * 14) + ax2)] + (data[((((ax0 * 1680) + (k1 * 168)) + (ax1 * 14)) + ax2)] * data[((((ax0 * 1680) + (k1 * 168)) + (ax1 * 14)) + ax2)]));\n        }\n      }\n    }\n    for (int32_t ax1_1 = 0; ax1_1 < 10; ++ax1_1) {\n      for (int32_t ax2_1 = 0; ax2_1 < 12; ++ax2_1) {\n        for (int32_t ax3_s = 0; ax3_s < 14; ++ax3_s) {\n          T_cast[((((ax0 * 1680) + (ax1_1 * 168)) + (ax2_1 * 14)) + ax3_s)] = ((data[((((ax0 * 1680) + (ax1_1 * 168)) + (ax2_1 * 14)) + ax3_s)] * weight[ax1_1]) * (1.000000e+00f / sqrtf(((T_multiply_red[((ax2_1 * 14) + ax3_s)] * 1.000000e-01f) + 1.000000e-05f))));\n        }\n      }\n    }\n  }\n}\n\n",
        "cuda_code": "extern \"C\" __global__ void __launch_bounds__(35) default_function_kernel_1(float* __restrict__ T_cast, float* __restrict__ T_multiply_red, float* __restrict__ data, float* __restrict__ weight) {\n  T_cast[((((int)blockIdx.x) * 35) + ((int)threadIdx.x))] = ((data[((((int)blockIdx.x) * 35) + ((int)threadIdx.x))] * weight[((((((int)blockIdx.x) % 48) * 5) + (((int)threadIdx.x) / 7)) / 24)]) * (1.000000e+00f / sqrtf(((T_multiply_red[(((((int)blockIdx.x) / 48) * 168) + (((((int)blockIdx.x) * 35) + ((int)threadIdx.x)) % 168))] * 1.000000e-01f) + 1.000000e-05f))));\n}\n\nextern \"C\" __global__ void __launch_bounds__(32) default_function_kernel(float* __restrict__ T_multiply_red, float* __restrict__ data) {\n  T_multiply_red[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] = 0.000000e+00f;\n  for (int k1 = 0; k1 < 10; ++k1) {\n    T_multiply_red[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] = (T_multiply_red[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] + (data[((((((((int)blockIdx.x) * 4) + (((int)threadIdx.x) >> 3)) / 21) * 1680) + (k1 * 168)) + (((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) % 168))] * data[((((((((int)blockIdx.x) * 4) + (((int)threadIdx.x) >> 3)) / 21) * 1680) + (k1 * 168)) + (((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) % 168))]));\n  }\n}\n\n",
        "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((8, 10, 12, 14), \"float32\"), weight: T.Buffer((14,), \"float32\"), T_cast: T.Buffer((8, 10, 12, 14), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0 in T.parallel(8):\n            T_multiply_red = T.allocate([168], \"float32\", \"global\")\n            T_multiply_red_1 = T.Buffer((168,), data=T_multiply_red)\n            data_1 = T.Buffer((13440,), data=data.data)\n            for ax1, ax2 in T.grid(12, 14):\n                T_multiply_red_1[ax1 * 14 + ax2] = T.float32(0)\n                for k1 in range(10):\n                    cse_var_3: T.int32 = ax1 * 14\n                    cse_var_2: T.int32 = cse_var_3 + ax2\n                    cse_var_1: T.int32 = ax0 * 1680 + k1 * 168 + cse_var_3 + ax2\n                    T_multiply_red_1[cse_var_2] = T_multiply_red_1[cse_var_2] + data_1[cse_var_1] * data_1[cse_var_1]\n            for ax1, ax2, ax3_s in T.grid(10, 12, 14):\n                cse_var_5: T.int32 = ax2 * 14\n                cse_var_4: T.int32 = ax0 * 1680 + ax1 * 168 + cse_var_5 + ax3_s\n                T_cast_1 = T.Buffer((13440,), data=T_cast.data)\n                T_cast_1[cse_var_4] = data_1[cse_var_4] * weight[ax1] * T.rsqrt(T_multiply_red_1[cse_var_5 + ax3_s] * T.float32(0.10000000000000001) + T.float32(1.0000000000000001e-05))",
        "op_args": [
            8,
            10,
            12,
            14
        ],
        "input_shape": [
            [
                8,
                10,
                12,
                14
            ],
            [
                14
            ]
        ],
        "output_shape": [
            [
                8,
                10,
                12,
                14
            ]
        ]
    }
]